<!DOCTYPE HTML>
<html lang="zh-Hant" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>程序員的自我修養 A Programmer Prepares</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-3169bedd.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-c1221ec0.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">程序員的自我修養 A Programmer Prepares</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="前言-編寫這堆電子垃圾的原因-why-i-write-these-articles--"><a href="#前言-編寫這堆電子垃圾的原因-why-i-write-these-articles--" class="header">前言 編寫這堆電子垃圾的原因 Why I write these articles - </a></h1>
<p>作為一個開發向的IT狗，應該要對一些DevOps技術有實踐上的認知，所以我把自身的經驗寫下來。希望可以有一個整體上的實踐方案以供討論和改進。</p>
<p>雖然我覺得願意看的人不多，看完後願意試的人更少，試完願意分享意見和改進的更希少。如果你是那個少少少少的希有人群，有興趣可以在github提交修正。</p>
<p><a href="https://github.com/macauyeah/AProgrammerPrepares">Github - 程序員的自我修養</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="docker-101"><a class="header" href="#docker-101">Docker 101</a></h1>
<p>雖然Docker面世很久了，但筆者也是最近才摸清Docker一些概念和實務上的用途。趁著還有一些記憶，分享一些筆記。好讓未正式用過的朋友少走一些冤枉路。</p>
<h2 id="docker是輕量vm"><a class="header" href="#docker是輕量vm">Docker是輕量VM?</a></h2>
<p>首先，第一個最大的普遍認知錯誤，就是認為Docker是輕量VM。</p>
<p>但其實它不是VM(更不是輕量VM)，它其實只是Linux上幫忙起Process的背景程式，官方叫作Docker Engine。個人感覺就像是在Host OS Kernal上的一個Playground (Sandbox會不會pro一點?)。我們平時最常使用的，是請Docker Engine根據Docker Image生成Container。而這些Container，因為一些特性，我習慣對非核心用戶解釋為【分身】。</p>
<p>整個生態系統中，最特別的是Container和Container之間，本身是獨立的。它們之間沒有Network, Storge也不會共用。除非你刻意連結起，否則它們理論上不會互相污染。但因為Kernal本身也是直接用Host OS，所以還是有機會被Hack而互相污染。</p>
<h2 id="docker-可以打包萬用linux-applicaiton"><a class="header" href="#docker-可以打包萬用linux-applicaiton">Docker 可以打包萬用Linux Applicaiton?</a></h2>
<p>第二個認知錯誤，就是認為Docker Container有persistent storage，可以看成VM，做一些Statefull application。</p>
<p>最陽春的Persistent storage是存在的，但並不是預期你會用到Production上面。因為Production大家考量的是做Cluster(例如Docker Swarm, K8s, KIND)，隨時增加或刪除多個相同Image來源的Container(分身)，以應付大流量。而經過Cluster的網絡routing mesh，即使同一個IP的Network request，也並不會一定派到同一個Container上。</p>
<h2 id="docker-run"><a class="header" href="#docker-run">Docker Run?</a></h2>
<p>第三個，不是認知錯誤，而是入坑起點問題。大部份教學，都會教大家怎樣包裝自己的Docker image，然後經docker run，產生container。</p>
<p>但其實一個application，並不是單一container可以包辦的事。例如，一個Wordpress網站，就會分了為兩個不同的Service(服務)來運作 來運作。而同一個Service，在需要的情況下，可以由一個或多個分身(Container)組成。</p>
<p>回到Wordpress的例子，應該看由成以下各部份組成的系統</p>
<ul>
<li>一個資料庫的Service，靠一個Container作為資料儲存。</li>
<li>一個Web Service，靠一個或多個Php (Apache) Container來應對使用者Http Request。</li>
<li>經Docker Network把上面兩個Service連在一起。而且Web Service會對外開放Port，但資料庫就只會對內開放Port。</li>
</ul>
<p>而一般的docker run，需要自行把上述所有事情串連起來。需要學習的command多，也很難感受整體的架構。個人覺得，在testing / development 環境下，容易上手的入門方式應該是docker compose。它可以同時行起多個Service/Container，提供同一個內部Network，把串連的動作簡化。更重要的是，docker compose主要是靠yaml file來做設定。讓新用戶可以更容易地重現別人做的好設定。</p>
<h2 id="為何要做成docker-container---容器化"><a class="header" href="#為何要做成docker-container---容器化">為何要做成Docker (Container - 容器化)</a></h2>
<ol>
<li>
<p>做到隔離效果</p>
<p>傳統上，同一機器安裝不同的 lib / dependency ，可能出現衝突。在 docker 的環境下，不同 container 之間可以隔離開，除了是網路之間出現引用關係的衝突外，動態庫的衝突就沒有見過。一般處理好 Persistent Volume 的考量，單機下是沒有什麼問題的。</p>
</li>
<li>
<p>遷移的過程比較簡單</p>
<p>傳統上，要把程式從一台機器搬到另一台機器，要預先安裝好相關的 lib / dependency 。但使用 docker / container 後，只要 docker 版本相容就好。docker image 本身，就已包括所有的 lib / dependency 。另一個常見的傳統問題，就是 Linux 檔案的擁有權問題，特殊情況下，新機同一個 user 的 ID 編號也不一樣，可能要手動恢復權限。如果是 container 的 bind mount 檔案，只要使用 tar command （<code>tar --same-owner -xvf file.tar</code>）保留權限解壓就好。</p>
</li>
<li>
<p>垂直水平擴容</p>
<p>因為有隔離及遷移方便的優勢，原本的機器達到上限，可以隨時換到其他機器上，修改對應的用戶入口就可以了（或更改DNS，可以更無縫連接）。一台機器不夠，亦可以多台機器一起來。即使不使用 docker swarm / k8s 方案，有傳統的 proxy gateway 再加單機的 docker ，就可以做到分流的效果。</p>
<p>當然使用 docker swarm / k8s 才是正解，可以更簡化 proxy gateway 的設定。而傳統的分佈式問題，例如 Share Storage 等，其實就沒有簡化到，但也沒有增加難度。所以大家若考慮擴容的問題，更適合考慮使用 Container 的方案。</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="把command-line-的程式打包成docker-image"><a class="header" href="#把command-line-的程式打包成docker-image">把command line 的程式打包成Docker Image</a></h1>
<p>平時我們用別人的Docker image，都以網絡服務為主，也就是，他們的image通常以常駐，打開某個網絡端口(UDP/TCP Port)提供服務。</p>
<p>但像nodejs, java等，其實是一些command line程式。它們其實可以一次性地執行後，回傳結果。</p>
<p>這次我們就以一個mdbook程式為例子，介紹打包的流程。</p>
<p>第一件事，在Docker image中，安裝或編譯binary</p>
<pre><code># Dockerfile
FROM ubuntu:22.04

RUN apt-get update &amp;&amp; apt-get install cargo -y &amp;&amp; cargo install mdbook

ENV PATH="${PATH}:/root/.cargo/bin"

VOLUME /opt/mdbookdata
WORKDIR /opt/mdbookdata
ENTRYPOINT ["mdbook"]
</code></pre>
<p>打包成image，給他一個名字，例如mdbook:beta</p>
<pre><code class="language-bash">sudo docker build -t mdbook:beta ./
</code></pre>
<p>在Dockerfile中，我選擇使用 <em><strong>ENTRYPOINT</strong></em> 的 <em><strong>exec</strong></em> 格式，因為我需要後期在 <em><strong>docker run</strong></em> 動態加入參數。</p>
<p>例如，要把參數 <em><strong>–version</strong></em> 傳入container，讓mdbook就可以看到該參數。</p>
<pre><code class="language-bash">sudo docker run --rm -it -v $(pwd):/opt/mdbookdata mdbook:beta --version
</code></pre>
<p>但在docker image中，它是使用root來執行。如果你直接執行build，那麼它的輸出資料夾 <em><strong>book/</strong></em> 的擁有人就會變成了root。你要用指定 <code>--user $(id -u):$(id -g)</code> 來指定執行者。</p>
<pre><code class="language-bash">sudo docker run --user $(id -u):$(id -g) --rm -it -v $(pwd):/opt/mdbookdata mdbook:beta build
</code></pre>
<p>還有，如果不想每次都打這麼長的指令，你可以在 <code>~/.bashrc</code> 中做別名(alias)。</p>
<pre><code class="language-bash"># edit ~/.bashrc
alias mdbook='sudo docker run --user $(id -u):$(id -g) --rm -it -v $(pwd):/opt/mdbookdata mdbook:beta $1'
</code></pre>
<p>這樣就可以簡化執行指令。</p>
<pre><code class="language-bash"># let .bashrc take effect without logout login
source ~/.bashrc
# run command through alias
mdbook --version
# it support multiple arguments
mdbook build --dest-dir ./dest
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="docker-上戰場---docker-swarm"><a class="header" href="#docker-上戰場---docker-swarm">Docker 上戰場 - Docker Swarm</a></h1>
<p>大部份在大公司工作的朋友，在公開的應用情景中，應該都會直接選擇公有雲 (Public Cloud) 的 Kubernetes 作為 投產環境 (Production)。但對於澳門的中、小微企，要找一個附合個人資料保護法的公有雲，可真難。想要簡單地靠自己架設本地 Kubernetes ，也不是一件易事。退而求其次，想要快速擁有一個群集 (Cluster) ，Docker Swarm 是一個最直觀的選擇。</p>
<p>在介紹 Swarm mode 的之前，我們先聊一聊可以有哪些選擇，也就是怎樣管理你的App還是有不同的選擇。雖然筆者對於 Docker Swarm Mode 的資歷尚淺，但由於後期更動的難點越來越多，筆者很想早一點討論其中不同操作的差異。</p>
<h2 id="docker-swarm"><a class="header" href="#docker-swarm">Docker Swarm</a></h2>
<p>Docker Swarm Mode其實是 Docker 提供的一個群集 (Cluster)環境。在其中運行的 Docker Image，都可以比較方便地隨時分身到不同的node(節點)上，對於提高負載或可用性，都是一個不錯的解決。</p>
<p>只要該 Image 跑起的Container是 無狀態的 - Stateless(前後兩次執行的結果互不相干涉)，或者是把狀能儲存 - Stateful的部份(有干涉的部份)外包到第三方(例如儲存空間使用NFS，或記憶體暫存改為Key-Value Database)，就可以方便地運作在Docker Swarm mode上。</p>
<h2 id="部署docker-swarm的選項-把app轉成swarm-mode-還是把底層程式變成swarm-mode"><a class="header" href="#部署docker-swarm的選項-把app轉成swarm-mode-還是把底層程式變成swarm-mode">部署Docker Swarm的選項： 把App轉成Swarm mode 還是把底層程式變成Swarm mode?</a></h2>
<p>Docker Swarm可以把Image變成分身Container，但並沒有硬性改變傳統App操作方式。大部份App在執行時，都需要另一個底層程式的支緩。例如</p>
<ul>
<li>Php Web App，需要底層php fpm + nginx或apache</li>
<li>Java Web App，就需要java + Tomcat</li>
</ul>
<p>所以在發佈App時，可以選擇把</p>
<ul>
<li>App直接打包成Image</li>
<li>只把底層程式打包在Image中(例如Tomcat)，再用Docker Volume的方式讓Container可以起動App。</li>
</ul>
<h3 id="兩者有何差別"><a class="header" href="#兩者有何差別">兩者有何差別?</a></h3>
<p>就信心層面上，一定是把App直接打包成Image實際一點。因為這樣可以極大地減少測試環境和正式環境的差異而出現的問題。筆者一開始也不完全讚成，但也越來越傾向這種做法。</p>
<p>在解釋筆者為何有這個結論前，先條列式地對比一下兩種差別。</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">事項</th><th style="text-align: left">打包App成為Image</th><th style="text-align: left">打包底層程式成為Image</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">打包複雜度</td><td style="text-align: left">需要把App用到的一些環境變數引入設定Image的 <code>entrypoint</code> 中，方便配合不同的環境可以改變App的行為。<br>打包次數根據App數量有關。<br>比較靈活，但比較需要學習和試錯。</td><td style="text-align: left">底層程式統一設定環境變數，其中所有App都會使用類似或相同的設定，設定方式跟傳統方式無異。<br>打包次數根據底層程式數量有關。<br>一般有官方發佈的版本。<br>比較死版，但要試錯的成本較低</td></tr>
<tr><td style="text-align: left">發佈流程</td><td style="text-align: left">打包App成Image。再靠Docker Swarm設定Image有多少分身。多個Image的協調，靠著Swarm完成。</td><td style="text-align: left">原來的底層程式已存在於Docker Swarm中，只需把新建或更新了的App放入不同分身的儲存空間，讓底層程式動態跑起App。但若底層程式也要需要因應App數量而改變，有機會底層程式也需要重新打包。</td></tr>
<tr><td style="text-align: left">管理複雜度</td><td style="text-align: left">每個App都是獨立的，代表有任何更新也是獨立更新。<br>在微服務的協作環境中，需要管理員從Image層面為每個App設定網絡(network)或開放端口(Port)。但每個App可以設定不同的分身數量，靈活性一定比只打包底層程式要高。</td><td style="text-align: left">使用同一個底層程式Image的App都會使用同一個網路和端口設定。<br>在微服務的協作環境中，管理員要應付的設定數量一定比打包App要少。<br>但由於是Conatiner分身是針對底層程式，所以若然某個App有不同需求，就要重新設定另一套底層程式。</td></tr>
<tr><td style="text-align: left">資源消耗</td><td style="text-align: left">每個App獨立，代表資料消耗也是獨立的。總消耗就是倍數增長。但可以經Docker限定每個Image的使用量</td><td style="text-align: left">因為底層程式共用，多少有可以省略的地方。資源限制沿用底層程式的傳統邏輯。</td></tr>
</tbody>
</table>
</div>
<p>上述幾個點，最後其實都是複雜度和靈活度的取捨。雖然打包App的工序更多，但提供的靈活性也更多。如果考慮要從傳統模式中過渡，方便與完全不懂Docker的同事協作，就首選打包底層程式。如果考慮可重複性和信心保證，還是打包App比較直接，要複制一個環境到另一個環境，也比較易測試。</p>
<p>打包底層程式的做法不是大問題，不過一定要考慮的是多個App之間是怎樣建構、多點佈署該如何實現，設定檔的備份又該如何做。因為Image內沒有太多關於佈署的設定，想偷賴也不行。若設定檔、多個App都底層程式都一起打包到同一個Image中，這其實是一個多Service的小系統。除非多個App很緊密連接，不然不推薦這種做法。因為每個App有更新，都會讓所有App重啟，就會對實際使用帶來很大的不便。</p>
<h3 id="到底如何選"><a class="header" href="#到底如何選">到底如何選？</a></h3>
<p>如果大家上正式的Docker課程，Docker導師通常會推薦為每個App打包成獨立Image，因為底層程式的Overhead(釋譯成上頭成本？)通常不大，例如底層程式是Tomcat、Apache、Nignx這類網頁伺服器，重量級的開銷並不是因為多幾個Web Engine的分身造成，通常都是因為業務本身。但如果你講的底層程式是資料庫等的大型程式，才可能會有明顯的差異。</p>
<p>實務上的建議，就是必需考慮自身的經驗，到底那個方案自己比較有把握。獨立打包App，在正式環境也需要考慮跟蹤問題的情況，多個不同App要溝通，需要了解Container網絡。如果打包底層程式，所有App都可以當成是本機下運行，會讓你更有信心追蹤問題，也是一個很好的出發點。到了有需要彈性改變不同App的分身數量，才轉向獨立打包的做法。</p>
<p>筆者最初也是走打包底層程式的方向，到了自己有信心試用Docker Swarm，才走向獨立打包的做法。筆者親身經驗，因為到了Docker Swarm，網段會變得暴增，這跟公司現有的內部網絡相衝的機會就會變多。在Swarm建立初時，筆者並沒有意識到這件事，所以當初排查問題，也花了一些時間才知道要向網段衝突上著手。</p>
<p>另一個出自Docker導師實務上的建議，就是正式環境中不要做用Docker compose，應該使用Docker Swarm。那怕Swarm只有一個節點，也應該用Swarm，導師的主要理據是Swarm有Rolling Update （滾動更新）的機制。同一個node也可以有多個分身，每個分身輪流更新，就不會出現大中斷的情況。筆者就自身經驗，Tomcat可以同時容納一個App的多個版本，Nginx也有Failover（故障轉移）等，如果你很熟悉這些功能，就不一定要需要靠Swarm去提供。也就是可以按自己步調去慢慢改變。</p>
<h1 id="cicd系統的參與"><a class="header" href="#cicd系統的參與">CI/CD系統的參與</a></h1>
<p>CI/CD 全稱是continuous integration (CI) 和 continuous delivery (CD)，字面上代表的持續地集成和發佈，實體上就是某台伺服器自動發佈APP。因為使用到Docker Cluster，不論前述什麼選擇，都會有多個node(節點)的出現。要發佈App，總不能一個個node逐個登入設定。所以我們需要一些CI/CD工具，把這個過程都自動化。</p>
<p>在筆者的認知上，CI/CD系統，由兩個部份組成，一個是取得Source Code(程式原始碼)的過程，一個是編譯或發佈Source Code的過程。Gitlab，Github，BitBucket等大型的代碼庫供應商，它們天生為了保存Source Code而提供服務的。不少CI/CD系統都可以跟它們整合，它們提供了存取Source Code的部份，剩下你只要能提供編譯或發佈的伺服器就好。</p>
<p>如果作為小型開發團隊，很少會有意願去自己花錢養一個編譯或發佈的伺服器。(極端地，如果我就是一人團隊，我用自己電腦編譯和發佈就好，伺服器能做的，我自己也能做。)好消息的是，Github提供了一個叫Github Action的CI/CD系統，即使你沒有自己的編譯專用的伺服器，Github Action也可以用Docker Image，提供一個臨時的編譯程序，用完就刪掉。詳細功能還請各位先查看官方教學，筆者也暫時只能零星使用經驗，無法給出有意思的架構。</p>
<p>如果對智慧財產權有高度重視，Source Code不能存放在公開的伺服器，那麼Gitlab Enterprise Edtion則是一個好選擇。運用Gitlab ee，你可以用自己的機器，造一個純本地的庫存伺服器。更強的是，它內建也有CI/CD系統，只要你有間置的伺服器，就可以作為編譯使用。筆者也是從這個方向著手，架設了自己的Gitlab Runner(Gitlab CI/CD系統)。在這裏，就分享一下與Docker Swarm整合的概念。</p>
<p>對於前述兩種選擇，GitLab Runner都可以做得到</p>
<ul>
<li>底層程式打包成Image並運行在Swarm mode上，每次發佈的是App Binary(執行檔或核心檔案)。</li>
<li>把App直接打包成Image，並運行在Swarm mode上，每次發佈的是App Image。</li>
</ul>
<h2 id="cicd---打包底層程式成為image"><a class="header" href="#cicd---打包底層程式成為image">CI/CD - 打包底層程式成為Image</a></h2>
<p>在這個選擇下，其實就跟傳統自動化發佈的做法類似，只是發佈時，要多個node報行更新指令。如果你使用的底層程式原本就有支援多版本並行，這樣更新時就不用太操心rollback(回滾?)等操作。若系統不支援多版本並行，為求簡化，若遇到要rollback的情況，重跑過去舊的CI/CD操作也是一個做法。當然，我們也可以經過一些備份的操作，來保存被代替的程式，若在發佈過程中出問題，也可以手動重來，不過整件事就越來越複雜。</p>
<p>筆者發佈的基本思路是</p>
<ul>
<li>使用docker image，編譯和打包App Binary。
<ul>
<li>使docker image做編譯的好處是，你可以比較放心地假設每次編譯時，你的編譯環境都是乾淨的。</li>
</ul>
</li>
<li>傳送上述的結果至生產環境可以取用的地方。</li>
<li>跳入生產環境執行更新指令</li>
</ul>
<pre><code class="language-yml"># file .gitlab-ci.yml
# need Docker executor, the gitlab runner agent need docker permission
stages:
  - deploy

maven-deploy:
  image: maven:3-eclipse-temurin-17
  stage: deploy
  script:
    - "mvn clean compile package -Pprod -Dmaven.test.skip=true"
    # ${ID_RSA} is a rsa private key file location, it can skip password input during ssh or scp operation. 
    # you need to pre-config production serevr auth before exec this script
    - "chmod og= ${ID_RSA}"
    - "scp -i ${ID_RSA} -o StrictHostKeyChecking=no app.war YOUR_ACCOUNT@PRODUCTION_SERVER_1:./"
    - "ssh -i ${ID_RSA} -o StrictHostKeyChecking=no YOUR_ACCOUNT@PRODUCTION_SERVER_1 UPDATE_COMMAND"
    - "scp -i ${ID_RSA} -o StrictHostKeyChecking=no app.war YOUR_ACCOUNT@PRODUCTION_SERVER_2:./"
    - "ssh -i ${ID_RSA} -o StrictHostKeyChecking=no YOUR_ACCOUNT@PRODUCTION_SERVER_2 UPDATE_COMMAND"
</code></pre>
<p>這裏有些隱藏的管理成本，如果你生產環境中有多個node，最後那幾行指令就要多抄幾次。</p>
<h2 id="cicd---打包app成為image"><a class="header" href="#cicd---打包app成為image">CI/CD - 打包App成為Image</a></h2>
<p>在這個選擇下，對比傳統自動化發佈的做法，現在要多做一步，就是要包裝自己的Image。不過好處是docker swarm有提供監測工具，在發佈過程每個分身會逐個更新，前一個分身更新成功後才會到下一個分身更新。而且
rollback等的操作，你可以靠docker做到。即是要手動rollback，也可以透過更正docker tags來達到，所以整體上來說沒有比傳統的麻煩。</p>
<p>筆者發佈的基本思路是</p>
<ul>
<li>編譯App Binary。</li>
<li>打包成docker image。</li>
<li>經docker上傳image。</li>
<li>跳入生產環境執行更新指令。</li>
</ul>
<pre><code class="language-yml"># file .gitlab-ci.yml
# need Shell executor, the gitlab runner agent also need docker permission
stages:
  - deploy

docker-deploy:
  stage: deploy
  script:
    - "mvn clean compile package -Pprod -Dmaven.test.skip=true"
    - "docker image build -t YOUR_IMAGE_PRIVATE_REPO ./"
    - "docker image push YOUR_IMAGE_PRIVATE_REPO"
    # ${ID_RSA} is a rsa private key file location, it can skip password input during ssh or scp operation. 
    # you need to pre-config production serevr auth before exec this script
    - "chmod og= ${ID_RSA}"
    - "ssh -i ${ID_RSA} -o StrictHostKeyChecking=no YOUR_ACCOUNT@PRODUCTION_SERVER SWARM_UPDATE_COMMAND"
</code></pre>
<p>對比傳統自動化發佈的做法，最後的更新指令，只要執行一次就可以。當然，原本在Docker Swarm中要管理的事還是要好好管理。</p>
<h2 id="cicd---備註事項"><a class="header" href="#cicd---備註事項">CI/CD - 備註事項</a></h2>
<p>雖然CI/CD可以幫忙簡化更新的過程，但實際操作會比上述的例子複雜一些。因為通常對非技術型的外界用戶來說，一個Web App會包含很多不同的功能。上述的例仔，在實際情況下可能需要拆解成很多微服務來進行。所以對管理上還是有相當的挑戰。</p>
<h1 id="draft"><a class="header" href="#draft">DRAFT</a></h1>
<h2 id="cicd-其實要分開"><a class="header" href="#cicd-其實要分開">CI/CD 其實要分開</a></h2>
<p>CI是編譯 binary/docker image 的運程，CD是發佈的過程。編譯與發佈，並不一定對等實現。多次編譯，可以最後才會發佈一次。發佈也有分不同環境，發佈到測試場，還是投産？測試場與投産的也會存在版本差異，通常新一個版本還在測試，投産則用前一個版本。</p>
<p>如果有清楚的版本號，CI會産生一個帶版本號的binary或image，CD則選擇不同的版本號配不同的config。如果要更準確地rollback ，CD還要有自己的版本號。為了靈活CD，減少CI的次數。</p>
<p>目前script base可以 default branch event - build image (CI)， tag event deploy (（)CD)。 build image 時留一個有 commit hash 的docker tag ，之後 git tag 就根據當時的 commit hash 找回原本的image / binary，進行 docker stack deploy 的指令。這樣可以減少tag時需要執行的build 指令。不過CD如何以，就要以另一個repo儲起不同env的config。同一個repo儲config，也會出現改config後要重build的情況。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線"><a class="header" href="#swarm-mode-上線">Swarm mode 上線</a></h1>
<p>之前一直都討論Image 的打包形式，現在聊聊部署上線時的一些指令。</p>
<h2 id="組成群集"><a class="header" href="#組成群集">組成群集</a></h2>
<p>以前各家不同的軟件，想要起一個群集，要左攪右攪，又要重啟。而<code>docker swarm</code>真的很簡單，只要各機中有 docker ，再在各機中順序打指令就好。</p>
<p>node 1 使用<code>docker swarm init</code> <code>docker swarm join-token manager</code></p>
<pre><code class="language-bash"># node 1
&gt; docker swarm init
&gt; docker swarm join-token manager
To add a manager to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-xxxxxxxxxxxxxxxxxxxxxxx xxx.xxx.xxx.xxx:2377

</code></pre>
<p>其餘的管理員節點就根據上述的提示，使用 <code>docker swarm join --token SWMTKN-1-xxxxxxxxxxxxxxxxxxxxxxx xxx.xxx.xxx.xxx:2377</code> 就好。只要總數的管理員節點有奇數個就可以了（包括當初的node 1）。即是1、3、5等都可以。這是因為在容錯的情況下，必需由管理節點作出多數決，才能容易地知道判斷是哪些節點出現問題。</p>
<p>如果不為容錯，只想增加可工作的機器，那麼我們只需要增加工作節點。我們可以在任何管理員節點生成<code>docker swarm join-token worker</code></p>
<pre><code class="language-bash">&gt; docker swarm join-token worker 
To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-yyyyyyyyyyyyyyyyyyyyyyy yyy.yyy.yyy.yyy:2377 
</code></pre>
<p>若想要檢查各個節點的工作狀態，在管理員節點上執行 <code>docker node ls</code> 看到了。</p>
<pre><code class="language-bash">docker node ls
ID                            HOSTNAME      STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
xxxxxxxxxxxxxxxxxxxxxxxxx *   node1hostname   Ready     Active         Leader           28.5.1
yyyyyyyyyyyyyyyyyyyyyyyyy *   node2hostname   Ready     Active         Reachable        28.5.1
</code></pre>
<h2 id="docker-service"><a class="header" href="#docker-service">Docker Service</a></h2>
<p>swarm mode 主要通過“docker service“ 指令去產生一堆可以在不同節點上運行的container。為了更加形象地講，我把container稱為Image的分身。</p>
<p><code>docker service create</code> 跟 <code>docker container run</code> 的感覺很像，兩者都可以指定image</p>
<pre><code class="language-bash"># swarm mode
$ docker service create --name nginx_s nginx

# container mode
$ docker container run -d --name nginx_c nginx
</code></pre>
<p>兩者的差別在於docker service 可以指定多少個分身，可以隨時加減數目，而且如果你有多過一台機器，分身就會在不同的機器上遊走。而docker container就是只對本機有操作，也不會散播到其他機器。</p>
<pre><code class="language-bash"># swarm mode
$ docker service create --replicas=2 --name nginx_s nginx
$ docker service ls

ID             NAME      MODE         REPLICAS   IMAGE          PORTS
uro4rwy6nelh   nginx_s   replicated   2/2        nginx:latest

$ docker service update --replicas=5 nginx_s
$ docker service ls

ID             NAME      MODE         REPLICAS   IMAGE          PORTS
uro4rwy6nelh   nginx_s   replicated   5/5        nginx:latest

# container mode
$ docker container run -d --name nginx_c1 nginx
$ docker container run -d --name nginx_c2 nginx
$ docker container run -d --name nginx_c3 nginx
$ docker container run -d --name nginx_c4 nginx
$ docker container run -d --name nginx_c5 nginx
$ docker container ls
CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS         PORTS     NAMES
c45771f06612   nginx     "/docker-entrypoint.…"   7 seconds ago    Up 6 seconds   80/tcp    nginx_c5
a587a718da3a   nginx     "/docker-entrypoint.…"   9 seconds ago    Up 9 seconds   80/tcp    nginx_c4
079f206f8645   nginx     "/docker-entrypoint.…"   9 seconds ago    Up 9 seconds   80/tcp    nginx_c3
e10dc525fd22   nginx     "/docker-entrypoint.…"   10 seconds ago   Up 9 seconds   80/tcp    nginx_c2
dcaa2b4bb3de   nginx     "/docker-entrypoint.…"   10 seconds ago   Up 9 seconds   80/tcp    nginx_c1
</code></pre>
<p>在建立網段時也差不多，service需要的是overlay network，而container用一般network就可以。</p>
<pre><code># swarm mode
$ docker network create --driver overlay nginx_s_gateway
$ docker service update --network-add name=nginx_s_gateway,alias=gateway nginx_s
$ docker service ps nginx_s
ID             NAME            IMAGE          NODE         DESIRED STATE   CURRENT STATE             ERROR     PORTS
fxqtheyvr914   nginx_s.1       nginx:latest   dockertest   Running         Running 33 seconds ago
u0pvj1leoizw    \_ nginx_s.1   nginx:latest   dockertest   Shutdown        Shutdown 33 seconds ago
q7arumjlxduv   nginx_s.2       nginx:latest   dockertest   Running         Running 36 seconds ago
kurlwqfmopbg    \_ nginx_s.2   nginx:latest   dockertest   Shutdown        Shutdown 37 seconds ago
zd0zlkhxafv0   nginx_s.3       nginx:latest   dockertest   Running         Running 40 seconds ago
3kapr00fs6pt    \_ nginx_s.3   nginx:latest   dockertest   Shutdown        Shutdown 40 seconds ago
5o4afd3whygo   nginx_s.4       nginx:latest   dockertest   Running         Running 35 seconds ago
oxocropolbo8    \_ nginx_s.4   nginx:latest   dockertest   Shutdown        Shutdown 35 seconds ago
x5y94jf3ok51   nginx_s.5       nginx:latest   dockertest   Running         Running 38 seconds ago
cgld3au0w1i9    \_ nginx_s.5   nginx:latest   dockertest   Shutdown        Shutdown 39 seconds ago

# container mode
$ docker network create nginx_c_gateway
$ docker network connect --alias gateway nginx_c_gateway nginx_c1
$ docker network connect --alias gateway nginx_c_gateway nginx_c2
$ docker network connect --alias gateway nginx_c_gateway nginx_c3
$ docker network connect --alias gateway nginx_c_gateway nginx_c4
$ docker network connect --alias gateway nginx_c_gateway nginx_c5
</code></pre>
<p>不過比較大的差異是service會停了原有的分身，重開新的分身去加入網段。所以上面的docker service ps nginx_s執行結果，就有一半是停掉的。</p>
<p>類似地，docker service也不能單獨地停掉分身，頂多只能調整 <code>--replicas=NUMBER</code> ，來控制分身數量。而單機則可以經過 <code>docker container stop</code> 來暫停分身。</p>
<h2 id="docker-stack"><a class="header" href="#docker-stack">Docker Stack</a></h2>
<p>同樣地，在單機管理container時，可以通過內建的docker compose指令配搭docker-compose.yaml檔案，管理多個有協作關係的container。Swarm mode也可以通過docker stack去管理yaml檔案中的多個有協作關係的service。</p>
<p>因為docker compose已支援v3及Compose Specification標準；但docker stack暫時只能支援到v3格式，所以說yaml檔案不能完全照搬。但指令上行為是差不多的。</p>
<pre><code class="language-bash">docker stack deploy -c setting.yaml stack-name
docker stack rm stack-name

docker compose -f setting.yaml up -d
docker compose down
</code></pre>
<p>docker stack也跟docker service類似，沒有隨時叫停的功能，而docker compose 就可以暫時叫停分身<code>docker compose -f setting.yaml stop</code>。</p>
<h3 id="docker-stack-yaml"><a class="header" href="#docker-stack-yaml">Docker Stack yaml</a></h3>
<p>以下就是一個可以重複文章前述 nginx service 的 yaml 檔範例，它跟原本的 compose 的格式差不多，但多了 deploy 的分支。以 yaml 的方式來編寫，可以更直觀地看出部署的更新設定，例如滾動更新，主機限制等。</p>
<pre><code class="language-yaml">services:
  s:
    image: nginx
    # ports:
    #   - 80:80
    deploy:
      replicas: 5
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role==manager
</code></pre>
<p>如同 docker compose 一樣，它會自動偵測設定檔有沒有更新，而決定是否要更新 container 。即使有多個 service，它也會只更新有加入或變動的部份。指令如下</p>
<pre><code class="language-bash">docker stack deploy -c setting.yaml nginx
</code></pre>
<p>但它也跟 docker compose 一樣， yaml 檔中有東西消失了，對應該service 就會變成孤兒。孤兒 service 還會運行，而且不會被刪除。除非我們執行刪除指令</p>
<pre><code class="language-bash">docker service rm SERVICE_NAME
# 或者刪除整個 stack 
docker service rm STACK_NAME
</code></pre>
<h2 id="docker-service-rollback"><a class="header" href="#docker-service-rollback">Docker Service Rollback</a></h2>
<p>詳見<a href="#swarm-mode-上線---3--rollback-回滾">SwarmModeRollback.md</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線---2"><a class="header" href="#swarm-mode-上線---2">Swarm mode 上線 - 2</a></h1>
<p>系統上線一段日後，總會遇到有需要更改的時候，我們一般要用的程式，可以經過Docker Image包裝，變得無痛。但Docker Swarm本身要有改動，就不是那麼的直白。</p>
<p>以筆者的經驗，若果Swarm mode的各位node都原地升級版本，其實都不難。但若果那些最基本的設定，例如node1的IP換了，那基本上等於要整個Swarm mode砍掉從來。</p>
<p>筆者最近就需要將整個Docker Swarm中多個node都一起轉IP。原本以為關掉改主機IP，Docker Swarm可以隨時重起。但問題是，在改IP過程中，其他Node2、Node3發現Node1的不見了，若然Node2、Node3經過cold start，它們的Docker daemon根本行不起來。若然要在這一刻硬來，就需要整個Docker daemon重設。這比當初以為的只刪除Docker Swarm要來得恐怖。</p>
<p>比較好一點的做法，應該是在改IP之前，先把Swarm mode中各個stack (service, network, volume)手動移除，然後把Swarm mode解除。</p>
<p>在Docker相關事項都變成可以獨立運作後，再做主機的更新</p>
<pre><code class="language-bash"># delete stack and leave swarm in node 3, node 2, node 1
# don't shutdown docker in node 2,3 if node 1 is not available
docker stack ls
docker stack rm YOUR_STACK_NAME

# to be confirm if any dingling network, service is still there.
# not sure how stack handling re-deploy problem when something removed from yaml file
docker network ls
docker network rm YOUR_STACK_NETWORK

docker service ls
docker service rm YOUR_STACK_SERVICE

docker volume ls
docker volume rm YOUR_STACK_VOLUME

docker swarm leave --force

## begin host changes
## finish host changes, re-create cluster

# in node 1, init new swarm with new ip
docker swarm init --advertise-addr YOUR_NEW_NODE1_IP
# in node 1, get new manager token
docker swarm join-token manager
# in node 2 and node 3, join node 1 with new token
docker swarm join --token XXXXX YOUR_NEW_NODE1_IP:2377
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線---3--rollback-回滾"><a class="header" href="#swarm-mode-上線---3--rollback-回滾">Swarm mode 上線 - 3 | Rollback 回滾</a></h1>
<p>Docker Swarm提供了一個很方便的rollback功能。針對swarm service的config都可以用。官方提供了一些<a href="https://docs.docker.com/engine/reference/commandline/service_rollback/">rollback config</a>的例子。</p>
<p>今天筆者今天就來個自己更常見的例子，rollback image</p>
<p>例設我們使用docker stack和yaml檔來操作docker service。</p>
<pre><code class="language-yaml"># nginx-rollback.yaml
services:
  nginx:
    image: nginx:1.25.2
    ports:
      - 8080:80
    deploy:
      replicas: 2
      update_config:
        delay: 1s
      restart_policy:
        condition: any
</code></pre>
<p>首次建立nginx service, 當前版本會是nginx:1.25.2</p>
<pre><code class="language-bash">&gt; sudo docker stack deploy -c nginx-rollback.yaml nginx-test
### system output
Creating network nginx-test_default
Creating service nginx-test_nginx

&gt; sudo docker service ps nginx-test_nginx
### system output
ID             NAME                 IMAGE          NODE      DESIRED STATE   CURRENT STATE           ERROR     PORTS
kn6o6p45rxtq   nginx-test_nginx.1   nginx:1.25.2   node2     Running         Running 8 minutes ago
x1qa0tmhh8w6   nginx-test_nginx.2   nginx:1.25.2   node1     Running         Running 8 minutes ago
</code></pre>
<p>然後嘗試更新nginx:1.25.3</p>
<pre><code class="language-yaml"># nginx-rollback.yaml
services:
  nginx:
    image: nginx:1.25.3
    ports:
      - 8080:80
    deploy:
      replicas: 2
      update_config:
        delay: 1s
      restart_policy:
        condition: any
</code></pre>
<pre><code class="language-bash">&gt; sudo docker stack deploy -c nginx-rollback.yaml nginx-test
### system output
Updating service nginx-test_nginx (id: nlure4s6ipnzuy4qki66dz8o9)

&gt; sudo docker service ps nginx-test_nginx
### system output
ID             NAME                     IMAGE          NODE      DESIRED STATE   CURRENT STATE             ERROR     PORTS
83m9iyc2xg5q   nginx-test_nginx.1       nginx:1.25.3   node2     Running         Running 3 seconds ago
kn6o6p45rxtq    \_ nginx-test_nginx.1   nginx:1.25.2   node2     Shutdown        Shutdown 7 seconds ago
8a9vidondmyo   nginx-test_nginx.2       nginx:1.25.3   node1     Ready           Preparing 2 seconds ago
x1qa0tmhh8w6    \_ nginx-test_nginx.2   nginx:1.25.2   node1     Shutdown        Running 2 seconds ago
</code></pre>
<p>假設我們發現nginx:1.25.3有些副作用不是我們想要的，可以經docker service rollback回到上次的版本，即是nginx:1.25.2</p>
<pre><code class="language-bash">&gt; sudo docker service rollback nginx-test_nginx
###
nginx-test_nginx
rollback: manually requested rollback
overall progress: rolling back update: 2 out of 2 tasks
1/2: running   [==================================================&gt;]
2/2: running   [==================================================&gt;]
verify: Service converged

&gt; sudo docker service ps nginx-test_nginx
ID             NAME                     IMAGE          NODE      DESIRED STATE   CURRENT STATE                 ERROR     PORTS     
0mm3hzp0aaok   nginx-test_nginx.1       nginx:1.25.2   node2     Running         Running about a minute ago
83m9iyc2xg5q    \_ nginx-test_nginx.1   nginx:1.25.3   node2     Shutdown        Shutdown about a minute ago
kn6o6p45rxtq    \_ nginx-test_nginx.1   nginx:1.25.2   node2     Shutdown        Shutdown 10 minutes ago
cb1pdqw0bmyx   nginx-test_nginx.2       nginx:1.25.2   node1     Running         Running about a minute ago
8a9vidondmyo    \_ nginx-test_nginx.2   nginx:1.25.3   node1     Shutdown        Shutdown about a minute ago
x1qa0tmhh8w6    \_ nginx-test_nginx.2   nginx:1.25.2   node1     Shutdown        Shutdown 10 minutes ago
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線-4--ip-設定"><a class="header" href="#swarm-mode-上線-4--ip-設定">Swarm mode 上線 4 | IP 設定</a></h1>
<h2 id="單機模式-ip設定"><a class="header" href="#單機模式-ip設定">單機模式 IP設定</a></h2>
<p>平常我們自己做測試，網絡功能通常用預設的就好。但當我們的Docker Container需要存取在區域網內的其他資源，避晚IP網段相衝是必需要的事。</p>
<p>大部份情況下，單機Docker使用的預設IP段會是</p>
<ul>
<li>172.17.0.0/16</li>
<li>172.18.0.0/16</li>
<li>…</li>
</ul>
<p>若然現在區域網中，有一段172.18.0.0/24，大家不想Docker踩到其中，可以修改設定檔，加入預設的default-address-pools，以後它就只會從指定的區段使用。</p>
<pre><code class="language-json"># vim /etc/docker/daemon.json
{
  "default-address-pools": [
    {
      "base": "172.17.0.0/16",
      "size": 24
    },
    {
      "base": "172.19.0.0/16",
      "size": 24
    },
    {
      "base": "172.20.0.0/16",
      "size": 24
    }
  ]
}
</code></pre>
<p>其中base，是docker可以操作的總區域，size指的是Docker要自行分段的話，每段的大小是多少，上述的例子，就代表未來可能有以下Docker 網段。</p>
<ul>
<li>172.17.0.0/24</li>
<li>172.17.1.0/24</li>
<li>…</li>
<li>172.17.255.0/24</li>
<li>172.19.0.0/24</li>
<li>172.19.1.0/24</li>
<li>…</li>
<li>172.19.255.0/24</li>
<li>172.20.0.0/24</li>
<li>172.20.1.0/24</li>
<li>…</li>
<li>172.20.255.0/24</li>
</ul>
<p>修改完設定後，重啟Docker就會生效。當然，重啟前，先刪除所有不在預設範圍的所有Container。</p>
<h2 id="swarm模式-ip設定"><a class="header" href="#swarm模式-ip設定">Swarm模式 IP設定</a></h2>
<p>Swarm模式，與單機差不多，它需要在初始化Swarm就要定義，而且它不能與單機的網段有重疊。單機會預設使用Private IPv4 Class B，Swarm則是預設使用Private IPv4 Class A段，所以我們若就更改，就使用10.x.x.x吧。</p>
<pre><code class="language-sh">docker swarm init --default-addr-pool 10.1.0.0/16 --default-addr-pool-mask-length 24
</code></pre>
<p>經上述例子初始化的 ingress 網段，將會是 10.1.0.0/24，隨後每個stack 則會是</p>
<ul>
<li>10.1.1.0/24</li>
<li>10.1.2.0/24</li>
<li>10.1.3.0/24</li>
</ul>
<h2 id="重置swarm"><a class="header" href="#重置swarm">重置Swarm</a></h2>
<p>跟單機的情況類似，如果已建立Swarm後才修改網段，還是要整個刪掉重來。</p>
<p>每個節點都要執行以下指令。</p>
<pre><code class="language-bash">docker swarm leave --force
</code></pre>
<p>實測swarm leave這個指令也會把所有運行中的stack刪掉。</p>
<p>各節點重新建立swarm</p>
<pre><code class="language-bash"># in node 1, init new swarm with new ip
docker swarm init --default-addr-pool 10.1.0.0/16 --default-addr-pool-mask-length 24
# in node 1, get new manager token
docker swarm join-token manager
# in node 2 and node 3, join node 1 with new token
docker swarm join --token XXXXX YOUR_NEW_NODE1_IP:2377
</code></pre>
<h2 id="雙管齊下"><a class="header" href="#雙管齊下">雙管齊下</a></h2>
<p>如果大家同想要修定單機及Swarm的網段，還要留意有一個特別的網段docker_gwbridge。它雖然是Swarm的附帶產物，但它則是受單機的網段控制。也就是，如果大家有需要同時修改單機及Swarm的網段，則需要手動刪除Swarm及docker_gwbridge</p>
<p>在每個節點先刪掉舊有的Swarm及docker_gwbridge，並關掉docker</p>
<pre><code class="language-bash">docker swarm leave --force
docker network rm docker_gwbridge
</code></pre>
<p>在每個節點為docker_gwbridge修改設定，然後重起docker</p>
<pre><code class="language-json"># vim /etc/docker/daemon.json
{
  "default-address-pools": [
    {
      "base": "172.17.0.0/16",
      "size": 24
    }
  ]
}
</code></pre>
<p>然後像前述一樣，重起Swarm。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線-5---host-os-升級流程"><a class="header" href="#swarm-mode-上線-5---host-os-升級流程">Swarm mode 上線 5 - Host OS 升級流程</a></h1>
<p>如果大家一直有跟進安全更新，基本上每個一至兩個月，都會有OS kernel和Docker Engine Update。也許大家習慣還是以不變應萬變，但有些時候還是不可避免地遇到嚴重漏動，需要強制更新。那麼當我們在這個情況時，我們該如何做呢？在開始做之前，我們先測試一下Swarm的容錯率有多高。</p>
<p>官方就宣稱，只要swarm中，manager例下的數目沒有超過半數，就依然可以運行。這個部份，筆者相信大家一早就感受過。但筆者認為，在直正出意外的情況是，少於半數的manager倒下了，但其餘的manager又不幸要重啟，到底又些活著的manager，又可否成功重新啟動？所以下面就來做些測試。</p>
<h2 id="測試1"><a class="header" href="#測試1">測試1</a></h2>
<ul>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage">測試REPO</a></li>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/initDockerCluster.sh">初始化script initDockerCluster.sh</a></li>
</ul>
<p>筆者在原本的教學中，就有一個3個manager node + 2 worker node的範例，我們只要安裝ubuntu OS, packer, 並使用</p>
<pre><code># run setupMultipassWithFixIP.sh will install multipass and config fix ip
./setupMultipassWithFixIP.sh


# install packer, please refer to https://github.com/macauyeah/ubuntuPackerImage/blob/main/README.md
packer init template.pkr.hcl
packer build template.pkr.hcl

# initialize docker cluster in multipass
./initDockerCluster.sh
</code></pre>
<p>在上述的環境中，node21, node22, node23是manager, node24, node25則是worker。在全關的情況下，只要正常啟動兩台manager，worker就可以成功復活。</p>
<h2 id="測試2"><a class="header" href="#測試2">測試2</a></h2>
<ul>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage">測試REPO</a></li>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/initDockerClusterLoopJoin.sh">初始化script initDockerClusterLoopJoin.sh</a></li>
</ul>
<p>筆者寫了另一個起始方案，會有5個manager node，而且依賴順序如下</p>
<ul>
<li>node22 =&gt; node21</li>
<li>node23 =&gt; node22</li>
<li>node24 =&gt; node23</li>
<li>node25 =&gt; node24</li>
<li>node21 =&gt; node22</li>
</ul>
<pre><code># initialize docker cluster in multipass
./initDockerClusterLoopJoin.sh
</code></pre>
<p>在上述的環境中，5台機也是manager。 initDockerClusterLoopJoin 的前半部份，它會建立順序依賴，即每一台機器，都經前一台機器進行加入的動作。而後半部份會把node21刪掉，並經multipass用一個全新的guest os重起，重新加入到。</p>
<p>在全關的情況下，只要正常啟動三台manager，它們都可以繼續運行。</p>
<p>這個測試的例子表明，即使原本作為依賴的機器死了，只要群齊中其餘多數manager仍然存在，它們也是可以復活的。更重要的是，即使最初引領一切的node21死掉了，什至是被刪掉重來，也是相安無事的。</p>
<h2 id="結論"><a class="header" href="#結論">結論</a></h2>
<p>更新時，最保守的做法，是先加入新的manager，再除去舊有的manager。但這個做法下，manager的IP就不可避免地被改變。若然DNS或者防火牆沒有相應的自動化幫忙，先加入再替換就變得很痛苦了。</p>
<p>而上述的測試，其實代表了我們可以先暫停或移除舊有的manager，更新完後再接回去，這樣部份IP就可以重用。我們只要維持多於原本半數的manager活著，然後逐一替換或升級原有的機器，也不會有問題。即使在升級途中，其他manager不幸地斷線，重啟後它們還是有條件自行修復。我們也不需要顧及更新順序，只需想好Virtual IP的分配策略就足夠，其餘就像是單機升級一樣。</p>
<h1 id="實戰升級流程"><a class="header" href="#實戰升級流程">實戰升級流程</a></h1>
<p>假設我們有5個 node，都為manager，各個 docker 版本都為28.0.4 ，我們將要關掉node 5 (ubuntu 22)，並加入node 6 (ubuntu24)，更新流程如下</p>
<ol>
<li>如果node5有vvip，login node 5，關掉vvip
<ul>
<li><code>systemctl stop keepalived &amp;&amp; systemctl disable keepalived</code></li>
</ul>
</li>
<li>login node1, 把node5降為drain模式，變為worker，並從群集中刪除
<ul>
<li><code>docker node update --availability drain node5</code></li>
<li><code>docker node demote node5</code>
<ul>
<li>若然node5不是直接關機、刪除，只想好好地離開群集，可以 login node5, 在node5上預先執行 <code>docker swarm leave</code></li>
</ul>
</li>
<li><code>docker node rm --force node5</code>
<ul>
<li>如果之前node5有好好地離開群集，而且狀態已經轉為down，那麼就不用“force“了，用最保守的刪除指令就可以 <code>docker node rm node5</code></li>
</ul>
</li>
</ul>
</li>
<li>login node1, 取得manager token
<ul>
<li><code>docker swarm join-token manager</code></li>
</ul>
</li>
<li>node5關機，新增node6，使用相容的ip段，或者使用node5的ip</li>
<li>login node6, 加入群集，設定vvip
<ul>
<li><code>docker swarm join --token xxxx XX_IP:XX_PORT</code></li>
<li><code>apt-get update &amp;&amp; apt-get install keepalived -y</code></li>
<li><code>systemctl start keepalived</code></li>
</ul>
</li>
</ol>
<p>上述的操作，有一些可能的陷阱，筆者就剛好踩過，未來不知道會不會有官方保證</p>
<ul>
<li>docker的版本需要相同，不同版本可能不能加入群集，例如
<ul>
<li>docker 28.0.4 不能加到 docker 27.5.1。</li>
<li>docker 27.2.x 不能加到 docker 27.5.1。</li>
</ul>
</li>
<li>docker swarm，官方雖然宣稱支援不同版本共存，但這指的是已加入的node，在不解綁的情況下原機升級。</li>
<li>在swarm已有多版本共存的情況下，有一個node選擇完全脫離，它想再加入，也是會失敗的。可能這不是docker自身的限制，而是底層library的相容性問題。筆者在實測不同版本時，就得到這樣的error。<code>docker credentials: cannot check peer: missing selected ALPN property</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線-6---load-balancer--負載平衡器"><a class="header" href="#swarm-mode-上線-6---load-balancer--負載平衡器">Swarm mode 上線 6 - load balancer | 負載平衡器</a></h1>
<p>前面我們一直談 swarm 的設定，但對於真實的服務，我們還要考慮客戶端是如何連接我們的伺服器群集。通常網路服務，客戶端都會經過域名轉換成IP，然而通過IP連線服務。</p>
<h2 id="ingress-network"><a class="header" href="#ingress-network">Ingress Network</a></h2>
<p>假設我們 swarm 內有5個節點，那到底域名應該指向我們哪一個節點的 IP 呢？</p>
<p>如果我們不考慮節點死機的話，其實5個節點的IP都可以。因為 swarm 會自動把同一個公開的 port ，在每一個節點上都可以訪問到。</p>
<p>以下例子，即使只有一個 container 運行，佔用 port 8888，它還是會在5個節點上全開。 swarm 通過自己的 ingress network，它所有節點的 8888 串連起來。</p>
<pre><code class="language-yaml">services:
  http:
    image: bretfisher/httpenv
    ports:
      - 8888:8888
    deploy:
      replicas: 1
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
</code></pre>
<p>我們可以在每個節點上，都會找到這個 ingress network，而且那個Network ID，應該是一樣的</p>
<pre><code>&gt; docker network ls | grep ingress
t7rmk6g9zybm   ingress           overlay   swarm
</code></pre>
<p>如果上述的 service 的 replicas 調成大於1的數量， ingress network 還會方便地自動 round robin (輪替) 地分派流量，達到最簡單的負載平衡。</p>
<h2 id="virtual-ip"><a class="header" href="#virtual-ip">Virtual IP</a></h2>
<p>前述的設定，我們有一最大的假設，就是節點不會死機。但實際情況下，各種原因，例如安全性更新、重啟中，都會讓節點暫時無法使用。即使所有 service 都是會自動 failover (故障轉移)，但客戶端還是用舊機 IP ，它還是無法訪問。因為該機 IP 已無法使用，除非我們連 IP 也懂 failover。這時， Virtual IP 就是我們的救命靈藥。</p>
<p>在 ubuntu 上，我們可以經過 keepalived 去設定 Virtual IP</p>
<pre><code class="language-bash">apt-get update &amp;&amp; apt-get install keepalived -y
</code></pre>
<p>然後設定 keepalived ， 假設 172.22.1.5 是我們的 Virtual IP 。 然後每個節點都要加入conf</p>
<pre><code class="language-conf"># vim /etc/keepalived/keepalived.conf
# assume failover ip is 172.22.1.5
vrrp_instance VI_1 {
    # change interface according to machine status
    interface eth1
    # one node is MASTER, other nodes are BACKUP
    state MASTER
    # virtual_router_id 1-255
    # all nodes in same group must be same value
    virtual_router_id 101
    # lower value will become master
    # ex, node1 priority 100, node2 priority 200, node3 priority 150.
    # if node 1, 2, 3 alive, node2 will become master.
    # if node 2 gone, node 3 will become master.
    priority 100
    advert_int 1
    virtual_ipaddress {
        172.22.1.5
    }
}
</code></pre>
<p>上述需要特別注意的是</p>
<ul>
<li>virtual_router_id : 要一起share ip的節點都要有同一個值。</li>
<li>priority : 每個節點應該都要不一樣，最大的那個節點，就會優先使用 Virtual IP 。</li>
</ul>
<h2 id="proxy-gateway-load-balance"><a class="header" href="#proxy-gateway-load-balance">proxy gateway load balance</a></h2>
<p>前面的例子，我們已經成功設定 ingress Network，也加了 virtual ip 。如果大家的目標是單一 web 應用，應該就已經很足夠。但作為一個足夠節儉的老闆，怎會讓一個 Swarm 只跑一個 Web 應用？但問題來了，一個 docker swarm service 就已經佔用一個公開端口 (例如上述的8888，或是更常見的443)。怎麼可以做到多個 service 分享同一個端口？答案就是回到傳統的 Web Server 當中，使用它們的 virtual host 及 proxy 功能，以達到這一效果。我們就以 Nginx 為例，去建立一個守門口的網關 (gateway) 。</p>
<p>以下就是一個最簡單的例子，最前端的 http-gateway (nginx) 對外公開端口 8080 ，它根據 virtual host，去分派對應的請求去 dmzhttp (bretfisher/httpenv) 及 managerhttp (bretfisher/httpenv) 。構架圖就是以下這樣。</p>
<pre><code>                              ┌───────────┐  
              ┌──────────────►│  dmzhttp  │  
              │               └───────────┘  
              │                              
           ┌───────────────┐                 
           │ http-gateway  │                 
  ────────►│ (nginx:8080)  │                 
           └──┬────────────┘                 
              │                              
              │              ┌─────────────┐ 
              └─────────────►│ managerhttp │ 
                             └─────────────┘ 
</code></pre>
<p>換成 docker stack ，就大概如下</p>
<pre><code class="language-yaml">services:
  http-gateway:
    image: http-gateway
    ports:
      - 8080:8080
    deploy:
      replicas: 1
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
  dmzhttp:
    image: bretfisher/httpenv
    deploy:
      replicas: 2
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
  managerhttp:
    image: bretfisher/httpenv
    deploy:
      replicas: 3
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
</code></pre>
<p>docker stack有一個很好的功能，就是 service 名會自動成為同一段網絡中的 hostname 。即是http-gateway中，它可以經DNS，找到 dmzhttp 、 managerhttp，也就是它的 nginx 可以設定成如下的樣子。</p>
<pre><code class="language-conf"># default.conf
server {
	listen       8080;
	listen  [::]:8080;
	server_name  managerhttp;
	resolver 127.0.0.11 valid=30s;

	location ^~ / {
		set $upstream_manager managerhttp;
		proxy_cache off;
		proxy_pass http://$upstream_manager:8888$request_uri;
	}
}
server {
	listen       8080;
	listen  [::]:8080;
	server_name  dmzhttp;
	resolver 127.0.0.11 valid=30s;

	location ^~ / {
		set $upstream_dmz dmzhttp;
		proxy_cache off;
		proxy_pass http://$upstream_dmz:8888$request_uri;
	}
}
</code></pre>
<p>上面的例子中，就是一般的 virtual host + nginx proxy 設定。特別要說明的是 resolver 那一行，它指向 docker DNS (127.0.0.11)， 而且還可以讓nginx在找不到上游時，不要馬上死亡。這樣 docker swarm 中各個 service 隨時加加減減，有保命的作用。</p>
<p>最後我們的 http-gateway 就是 nginx image + default.conf 上述的 docker 就可以用以下方式打包。</p>
<pre><code># Dockerfile
# docker image build -t http-gateway ./
FROM nginx:latest
COPY default.conf /etc/nginx/conf.d/default.conf
</code></pre>
<p>上面的 docker stack 和 nginx config，只要同步增加 service 及對應的 proxy pass，就可以o讓同一個端口，根據不同hostname做分流。當然，如果大家可以共用端口及 hostname 也可以，分流就改用 nginx location 來設定，不過這是更加偏向 nginx 的內容，日後有機會再介紹。本篇就先集中於 docker 相關的議題。</p>
<p>在安全性的角度， docker 還有一些配置可以做，就是讓 dmzhttp 和 managerhttp 在不同的機器上發佈。假設我們的網絡分開兩段，一段是 manager 專用，一段是 dmz 專用。在建立 docker swarm 後，我們可以為不同的節點加入對應的標簽。</p>
<pre><code class="language-bash">docker node update --label-add zone=manager YOUR_MANAGER_NODE
docker node update --label-add zone=dmz YOUR_DMZ_NODE
</code></pre>
<p>然後我們通過修改 docker stakc 中的 placement -&gt; constraints ，限制不同的 service 在不同的節點上運行。</p>
<pre><code class="language-diff">services:
  http-gateway:
    image: http-gateway
    ports:
      - 8080:8080
    deploy:
      replicas: 1
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
  dmzhttp:
    image: bretfisher/httpenv
    deploy:
      replicas: 2
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
+     placement:
+       constraints:
+         - node.labels.zone==dmz
  managerhttp:
    image: bretfisher/httpenv
    deploy:
      replicas: 3
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
+     placement:
+       constraints:
+         - node.labels.zone==manager
</code></pre>
<p>使用上面的例子，我們就可以達到簡單分離的效果。但大家緊記，這個分離效果始終是一個規則式功能，它與防火牆的隔離還是有本質上的區別。除了利用傳統的防火牆技術外，我們的docker swarm network，其實也可以做更多隔離，我們日後再慢慢加強這個例子。</p>
<h1 id="基於安全性的各種考量"><a class="header" href="#基於安全性的各種考量">基於安全性的各種考量</a></h1>
<p>前面介紹了 ingress network ，亦介紹了 proxy gateway 。能做到的基本都做到了，再來就是考量安全性的問題。因為加了 proxy gateway ，前述的例子是所有 service ，都放在同一個 yaml 檔中。好處是，所有相關的東西存放在同一個檔中， gateway ，背後的 service 都一眼看到。但壞處就是有其中一個 service 更新，都要改那個 yaml 檔。更大的問題是， stack deploy 的指令，不單只更新其中一個 service ，就連其他 service 都會自動取得最新 image 而 redeploy 。</p>
<p>對於一個緊密的系統來講，同步更新可能不是大問題。但對於一些預定排程發佈的系統可不能這樣因為副作用而更新了。如果你也有這樣的分開管理需求，可以參考下面做法，把 gateway service 及 upstream service 放在不同的檔案中，然後經過 external network把所有 service 串連起來。</p>
<pre><code class="language-yaml"># nginx-stack.yaml, docker stack deploy -c nginx-stack.yaml nginx
services:
  http-gateway:
    image: http-gateway
    ports:
      - 8080:8080
    deploy:
      replicas: 1
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure

# manager-stack.yaml
services:
  managerhttp:
    image: bretfisher/httpenv
    networks:
      - nginx_default
      - default
    deploy:
      replicas: 3
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.zone==manager
networks:
  nginx_default:
    external: true

# dmz-stack.yaml
services:
  dmzhttp:
    image: bretfisher/httpenv
    networks:
      - nginx_default
      - default
    deploy:
      replicas: 2
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.zone==dmz
networks:
  nginx_default:
    external: true
</code></pre>
<p>這樣，不同 service 的維護人員，就可以獨自控制自己的檔案。在第一次發佈時，確認 nginx-stack.yaml 先行發佈就可以了。對應的發佈指令是<code>docker stack deploy -c nginx-stack.yaml nginx</code>，它會自動産生一個 nginx_default （即 stack名字_default ）的網絡。之後其他service，就可以經networks的設定找到它了。</p>
<pre><code class="language-yaml">services:
  YOUR_SERVICE:
    networks:
      - nginx_default
      - default

networks:
  nginx_default:
    external: true
</code></pre>
<p>上述即使分離檔案，在安全性考量時還是有一個問題，就是 ingress network 的問題。試想一下，dmzhttp （Demilitarized Zone）原本被設定的原因，就是想限制外來的訪問請求，只能訪問公開的服務。但因為經過 ingress network 之後，它們會在所有機器上開放這些 port。那就是，以下面的例子來講，若 dmzhttp 是公開的服務， intrahttp 是內部服務，即使用 intrahttp 使用不同的port 8889。但一經 swarm mode 預設的 ingress network ，在<code>node.labels.zone==dmz</code>的那些節點，還是可以訪問到 intrahttp 。</p>
<pre><code class="language-yaml">services:
  dmzhttp:
    image: bretfisher/httpenv
    ports:
      - 8888:8888
    deploy:
      replicas: 2
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.zone==dmz
  intrahttp:
    image: bretfisher/httpenv
    ports:
      - 8889:8888
    deploy:
      replicas: 3
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.zone==intra
</code></pre>
<p>我們前述介紹的 proxy gateway ，其實已經有一定程度可以解決這個問題。因為 proxy gateway 是根據 http 協定中的 host header 去做分流。在邊界網絡進來的「合法」訪問，道理上會好好地經引導到我們的 dmzhttp 。不過網路的邪惡可容小看， proxy gateway 也會有被騙的一日。有特定能力的攻擊者，只需找到目標域名，還是可以接觸到 intrahttp 。</p>
<p>若要做進一步隔離，在這種情況下，我們可以在 dmz , intra 機器中各設定一套 swarm ，完全獨立，這是最安全的做法。但這樣做的管理成本就會變高，因為兩個網段都會有自己的 manager 節點，而且在 dmz 網段的 manager 節點也有被攻擊的可能。</p>
<p>若我們回到單一 swarm 的方向，可以修改各個 service 中的 port 和 deploy 。利用 post mode 中的「host」，配合 deploy mode 中的「global」，完全跳開 ingress network。</p>
<pre><code class="language-yaml">services:
  dmzhttp:
    image: nginx
    ports:
      - target: 80
        published: 8888
        mode: host
    deploy:
      mode: global
      update_config:
        delay: 1s
      restart_policy:
        condition: any
      placement:
        constraints:
          - node.labels.zone==dmz
  intrahttp:
    image: bretfisher/httpenv
    ports:
      - target: 8888
        published: 8888
        mode: host
    deploy:
      mode: global
      update_config:
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.zone==intra
</code></pre>
<p>上面的例子中， dmzhttp 會在所有 dmz 的機器中，每個節點只運行一份服務，而且直接使用該機的 8888 port ，外面不會再有 ingress network 的 存在。同樣地，intrahttp 會在 intra 的所有節點，運行一份服務，佔用它們的8888 。這兩個服務，即使使用一個 port ，swarm 也不會說有任何問題，因為它們不會經 ingress network 搶佔其他人的 8888。</p>
<p>可能會有讀者問，如果 host mode 這麼安全，為什麼預設會是 ingress network，那我們就要先了理清 ingress network 與 host mode 有有什麼分別？假設我們只運行一個service，它佔用8888。</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>功能</th><th>ingress mode</th><th>host mode</th></tr>
</thead>
<tbody>
<tr><td>replicas 數</td><td>同一個 service replicas 為任意數量，什至比節點的數目多</td><td>因為有 port 限制，每個節點最多只能運行一份</td></tr>
<tr><td>Virtual IP</td><td>Virtual IP 任意在節點中跳轉也可以，因為 ingress 會自動找到對應的 service 所在的節點</td><td>Virtual IP必需要與 service 所在節點綁定，其他節點訪問不到</td></tr>
<tr><td>load balance</td><td>有</td><td>沒有</td></tr>
</tbody>
</table>
</div>
<p>host mode 就像我們傳統在各自的節點上自行佈署自己的程序，各個節點只有一份。所以不會有自動 load balance 的效果，如果客戶端訪問固定的IP，就會得到是固定的接器接受請求。我們有需要，就要在前面加一個 Proxy Gateway (或 HA  proxy )。 Virtual IP 也一樣， host mode 下需要好好地自動跟著 service 的生命期，不過幸運的是， Docker 預設己經有自動重啟 service 功能，即前文中的 restart_policy ，它在 host mode 下也適用。如果大家有配合 deploy 中的 global mode ， Virtual IP 的並沒有實際變動。但如果沒有 global mode ，就要再想想辦法了。</p>
<p>最後考慮 load balance 的問題，如果進入點的 service 的真的不太消耗資源，沒有 load balance 也是可以的 ，但若超負荷，就必需要自建 proxy gateway 。經過進入點後，若我有背後的 service 就沒有所謂的 ingress 和 host mode 選擇。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="swarm-mode-上線-7---load-balancer--反向代理"><a class="header" href="#swarm-mode-上線-7---load-balancer--反向代理">Swarm mode 上線 7 - load balancer | 反向代理</a></h1>
<p>前述我們介紹了負載平衡器的概念，也使用了nginx作為反向代理，管理網絡訪問，分流到對應的服務上( docker service )。 nginx是穩定的，大家初次使用 reverse proxy （反向代理），請選擇它，因為相對簡單，也易於在單機上做對比測試。</p>
<p>而nginx有個麻煩的地方，就是每次加 docker service，都需要更改 nginx 的設定。我們service 越多，config檔就越長。一個不少心，某些設定有衝突，就會讓 nginx 無法重起。</p>
<p>所以，我們在一定規模後，就需要改用自動化的反向代理。 <a href="https://doc.traefik.io/traefik/">traefik</a> 就是其中之一。官方有提供一個 swarm 的範例，需要設定的部份相對比較多。幸好筆者找到一個Github網路資源，<a href="https://github.com/bluepuma77/traefik-best-practice/blob/main/docker-swarm-traefik/docker-compose.yml">bluepuma77 traefik-best-practice</a> ，內有一個traefik在docker swarm上的基本設定，足以解開筆者的某些謎思，可以讓筆者進行使用驗證。</p>
<p>bluepuma77 提供的範例可能還有些複雜，筆者就再簡化一下，讓大家可以從最基本的環境中開始。</p>
<p>下述 docker service 中</p>
<ul>
<li>traefik: 自動偵測 swarm 中，有那些其他 service 需要經過traefik 代理。</li>
<li>whoami: 一個官方提供的簡單版http 回應，它正常可以回應 http 80的請求。</li>
</ul>
<pre><code class="language-yml"># traefik-stack.yaml
services:
  traefik:
    image: traefik:v3.4
    ports:
      - target: 80
        published: 80
        protocol: tcp
        # mode: host
    networks:
      - proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      #- /var/log:/var/log
    command:
      - --api.dashboard=true
      - --log.level=INFO
      #- --log.filepath=/var/log/traefik.log
      - --accesslog=true
      #- --accesslog.filepath=/var/log/traefik-access.log
      - --providers.swarm.exposedByDefault=false
      - --providers.swarm.network=proxy
      - --entrypoints.web.address=:80
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role==manager
  whoami:
    image: traefik/whoami
    networks:
      - proxy
    deploy:
      replicas: 3
      labels:
        - traefik.enable=true
        - traefik.http.routers.whoami.rule=Host(`whoami.localhost`)
        # other rules reference to https://doc.traefik.io/traefik/routing/routers/#path-pathprefix-and-pathregexp
        - traefik.http.services.whoami.loadbalancer.server.port=80
        # test command with curl, ingress seems only work on ipv4
        # curl -v -H 'host:whoami.localhost' http://127.0.0.1/

networks:
  proxy:
    name: proxy
    driver: overlay
    attachable: true
</code></pre>
<p>有一些重要的地方需要特別說明：</p>
<ul>
<li>需要設定 <code>--providers.swarm.exposedByDefault=false</code>，不然traefik自己也需要定義反向代理的port。設定了這個，也可以讓 swarm 中某些 service 得以被忽略。有需要經 traefik 對外的，就在 <code>label</code> 下設定 <code>traefik.enable=true</code></li>
<li>需要設定<code>--providers.swarm.network=proxy</code>，swarm中也需要有該網絡的存在。不然traefik 沒有預設的網絡可以走。</li>
<li>現時 docker service 使用是的 ingress mode，方便 traefik service 可以在不同的 manager 上遊走。測試時需要注意使用 ipv4 ，例如 curl 需要指定 ipv4 的 ip 即<code>curl -v -H 'host:whoami.localhost' http://127.0.0.1/</code> ，若直接使用 whoami.localhost ，有機會會指向 ivp6 ， ingress mode 就接不到。</li>
</ul>
<h1 id="ssl"><a class="header" href="#ssl">SSL</a></h1>
<p>做完上述的使用驗證後，我們可以正式開始看官方的例子，該例子加入了SSL，這就更充份地體現反向代理的用途。</p>
<p><a href="https://doc.traefik.io/traefik/setup/swarm/">官方教學連結</a></p>
<p>官方的yaml也很長，筆者實測了一個簡化版本。</p>
<pre><code class="language-yaml"># traefik-ssl.yaml
services:
  traefik:
    image: traefik:v3.4
    ports:
      - target: 443
        published: 443
        protocol: tcp
    networks:
      - traefik_proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    configs:
      - source: dynamic-tls.yaml
        target: /dynamic/tls.yaml
    secrets:
      - source: certs-local.key
        target: /certs/local.key
      - source: certs-local.crt
        target: /certs/local.crt
    command:
      - --api.dashboard=true
      - --log.level=INFO
      - --accesslog=true
      - "--providers.file.filename=/dynamic/tls.yaml"
      - --providers.swarm.exposedByDefault=false
      - --providers.swarm.network=traefik_proxy
      - --entrypoints.websecure.address=:443
      - --entrypoints.websecure.http.tls=true
      #- --entrypoints.websecure.asDefault=true
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role==manager

  # Deploy the Whoami application
  whoami:
    image: traefik/whoami
    networks:
      - traefik_proxy
    deploy:
      labels:
        # Enable Service discovery for Traefik
        - "traefik.enable=true"
        # Define the WHoami router rule
        - "traefik.http.routers.whoami.rule=Host(`whoami.swarm.localhost`)"
        # Expose Whoami on the HTTPS entrypoint
        #- "traefik.http.routers.whoami.entrypoints=websecure"
        # Enable TLS
        - "traefik.http.routers.whoami.tls=true"
        # Expose the whoami port number to Traefik
        - traefik.http.services.whoami.loadbalancer.server.port=80

networks:
  traefik_proxy:
    name: traefik_proxy
    driver: overlay
    attachable: true

configs:
  dynamic-tls.yaml:
    file: ./dynamic/tls.yaml

secrets:
  certs-local.key:
    file: ./certs/local.key
  certs-local.crt:
    file: ./certs/local.crt
</code></pre>
<p>餘下的就照跟官方設定</p>
<p>生成cert file。（或大家有正式的證書，就可以免去這一步。）</p>
<pre><code class="language-bash">mkdir -p certs
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout certs/local.key -out certs/local.crt \
  -subj "/CN=*.swarm.localhost"
</code></pre>
<p>指向cert的動態設定檔。</p>
<pre><code class="language-yaml"># dynamic/tls.yaml
tls:
  certificates:
    - certFile: /certs/local.crt
      keyFile: /certs/local.key
</code></pre>
<p>然後我們就可以這樣測試</p>
<pre><code class="language-bash">curl -v -k -H 'host:whoami.swarm.localhost' https://127.0.0.1/
</code></pre>
<p>筆者在一開始時，始終無法設定 <code>dyanmic/tls.yaml</code> ，其實是筆者誤會了 traefik 的讀取方式。本個例子中，traefik 其實會動態讀取 swarm 及 file provider 的設置，而<code>dyanmic/tls.yaml</code>是經過file provider的方式生效。也就是 <code>traefik-ssl.yaml</code> 中的<code>"--providers.file.filename=/dynamic/tls.yaml"</code>。</p>
<p>本個例子與官方例子最大的不同，是官方的cert, tls, 是直接使用bind mount的方式存取，如果你有多過一個manager，這個方式不太有效。本文就用了swarm config及swarm secret，方便多個manager自動配置。不過swarm config及swarm secret都有個缺點，若要更新它們的內容，就必需要重命名（例如dynamic-tls.yaml=&gt; dynamic-tls.yaml2） ，否則swarm不允許發佈。</p>
<p>完整 yaml 請見 <a href="https://github.com/macauyeah/ubuntuPackerImage/tree/main/traefik">github</a></p>
<h1 id="reference"><a class="header" href="#reference">Reference:</a></h1>
<ul>
<li>https://github.com/bluepuma77/traefik-best-practice/blob/main/docker-swarm-traefik/docker-compose.yml</li>
<li>https://doc.traefik.io/traefik/routing/routers/#path-pathprefix-and-pathregexp</li>
<li>https://doc.traefik.io/traefik/setup/swarm/</li>
<li>https://github.com/macauyeah/ubuntuPackerImage/tree/main/traefik</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="schedule-job-with-docker"><a class="header" href="#schedule-job-with-docker">Schedule Job with Docker</a></h1>
<p>在Linux底下，crontab是一個最簡單建立Schedule Job的方法。大家用crontab -e 就可以進入設定。</p>
<pre><code># crontab -e
*/1 * * * * /opt/run.sh
</code></pre>
<p>其中每個星號，順序代表的是分、時、日、月、星期。上面的例子就是不論何月何日何時，只要每一分鐘就執行一次<code>/opt/run.sh</code></p>
<h2 id="singleton-job"><a class="header" href="#singleton-job">Singleton Job</a></h2>
<p>問題是，實際情況下，你想執行程式的時間都不一定會少於1分鐘。所以你總是有機會上一個job未跑完，下一個job就開始了。為了保障自已，需要一些參考機制，去決定是否讓job開始跑。</p>
<p>有些情況，可能你會想用job server去做監管，但若只為單線執行的工作，起一個job server還是會增加管理上的複雜性。</p>
<p>最簡單的做法，就是根據不同的程式語言，使用file lock（鎖上）的機制，先上鎖，再做事。但要注意考慮有沒有出現異常情況，令你自己反鎖自己。即是你的process死了，但不懂自己解鎖，這樣以後你也不能再執行了。</p>
<p>在Linux Bash Shell下，就有一個很簡單的做法，就是使用flock指令。用它的最大好處，就是從OS層面下，去鎖上。只要process結束了，不論正常還是不正常結束，都會自動解鎖。</p>
<p>以下例子就是在執行<code>/opt/run.sh</code>前，先要取得<code>/tmp/run.lockfile</code>的鎖。如果沒法取鎖，就自動放棄執行後面的指令。</p>
<pre><code>flock -n /tmp/run.lockfile /opt/run.sh
</code></pre>
<pre><code># crontab -e
*/1 * * * * flock -n /tmp/run.lockfile /opt/run.sh
</code></pre>
<h2 id="timeout"><a class="header" href="#timeout">Timeout</a></h2>
<p>引入singleton的概念後，其實會引發另一個問題。因為異常的情況，還有機會是不生不死，process hang。所以我們還需要設定一個最大的執行時間，讓你的process在異常的情況下，被強行清走。</p>
<p>例如，ping指令在linux預設是永遠不會自動停止的，可以模擬process hang的情況。如果我們想定時從外部收走ping process，就可以使用timeout指令。以下指令就是2分鐘後殺指ping process。</p>
<pre><code># in file /opt/run.sh
timeout 2m ping localhost
# to check process id, you could use
# &gt; ps aux | grep ping
# you will see two different id for ping and timeout
</code></pre>
<p>配合errorcode使用，你可能還會在想在timeout時送出一個email通知自已。</p>
<pre><code># in file /opt/run.sh
timeout 2m ping localhost
exitCode=$?
if [[ $exitCode -eq 124 ]]; then
    echo "timeout"
    # send email alert with timeout
elif [[ $exitCode -gt 0 ]]; then
    echo "exit with error"
    # send email alert with error exit
else
    echo "exit normal"
fi
</code></pre>
<p>配合docker使用，你可能需要考慮signal怎樣傳遞。</p>
<p>在筆者測試的環境中，似乎SIGTERM會被擋，也有可能是SIGTERM太強，它只把前景的docker container run收走，但其內的ping process還在docker daemon中行走。所以最後改用SIGINT，讓docker container run可以好好地把SIGINT傳入其內。</p>
<pre><code># It seems that docker captured the SIGTERM. Send SIGINT instead

# in file /opt/run.sh
timeout --signal=SIGINT 10s docker container run --rm pingtest -c 20
exitCode=$?
if [[ $exitCode -eq 124 ]]; then
    echo "timeout"
    # send email alert with timeout
elif [[ $exitCode -gt 0 ]]; then
    echo "exit with error"
    # send email alert with error exit
else
    echo "exit normal"
fi
</code></pre>
<p>還有一個常見的問題，就是中間夾雜了sudo，這樣前面的signal也是傳不過去，都被sudo擋了。所以只能把整段script都變成sudo或直接使用root執行；又或者把你的user加入docker group，執行docker command時就不用sudo。</p>
<pre><code># not work if wrapped sudo inside
timeout -signal=SIGINT 10s sudo docker container run --rm pingtest -c 20
timeout 10s sudo docker container run --rm pingtest -c 20

# workaround, add sudo outside of the whole script;
sudo /opt/run.sh
</code></pre>
<p>Full demo, github repo <a href="https://github.com/macauyeah/cronjobWithDocker.git">cronjobWithDocker</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="docker-variable-control"><a class="header" href="#docker-variable-control">Docker Variable control</a></h1>
<p>我們在Docker Image的打包時，最簡單當然就是每個步驟都使用最新版本。例如Docker Base Image，大家可能選用latest tag，安裝linux package （Linux包）,也可能就apt install / yum 安裝最新的穩定版本。但如果我們想要更好地做測試，就要使用指定版本，方便追蹤問題。而Docker在打包和運行時，都有不同的方式讓大家定義或覆寫指定參數。</p>
<h2 id="docker-build-arg"><a class="header" href="#docker-build-arg">Docker build arg</a></h2>
<p>我們先從打包Image開始。</p>
<p>例如我們需要使用一個Base image為 ubuntu，版本預設為22.04，但有需要時可以經build指令覆寫，可以這樣寫</p>
<pre><code class="language-Dockerfile">ARG ubuntu_version=22.04
FROM ubuntu:${ubuntu_version}
</code></pre>
<pre><code class="language-bash"># default ubuntu_version=22.04
docker image build -t test2204 ./
# or overwrite by --build-arg
docker image build -t test2404 --build-arg="ubuntu_version=24.04"
</code></pre>
<p>雖然Dockerfile的RUN指令都是使用linux shell，但在Dockerfile中想表達條件控制（if else statment）就不太易看。在外部加入script做控制，是另一個可行的後備選擇，它更可以連image名字也進行參數化。</p>
<pre><code class="language-bash"># in bash script, you also can
if [ $beta == true ]
then
    ubuntu_version=24.04
else
    ubuntu_version=22.04
fi

docker image build -t test:${ubuntu_version} --build-arg ubuntu_version=${ubuntu_version}
</code></pre>
<h2 id="docker-container-run-and-docker-compose"><a class="header" href="#docker-container-run-and-docker-compose">Docker Container Run and Docker Compose</a></h2>
<p>一般來講，Linux Container 在執行時，就等於進入Linux Shell。也就是，我們可以使用Shell中的環境變數。</p>
<p>我們在打包Image前，已經可以在Dockerfile中定義自己的ENV數參（也就是環境變數）。與前面的Build Arg有所不同的是，ENV是定義在Dockerfile中，在Container運行時以環境變數的形式存在，它也可以在運行中被改變。而Arg，則只在打包Image時存在，運行期間就不存在了。（當然，你在打包時，用Arg傳入Env，以運到這個目的。）</p>
<p>另一個更特別的性質是，那怕ENV沒有定義在Dockerfile中，我們運行時也可以加入更多的環境變數，大家就當成是一般Linux操作，隨時在自己的shell中加入變數。</p>
<pre><code class="language-bash"># -e, --env for inline variable
# --env-file for file
docker container run -e MYVAR1 --env MYVAR2=foo --env-file ./env.list ubuntu bash
</code></pre>
<p>同樣地Docker compose，也支援環境變數。筆者建議environment可以使用Array格式，日後可以更方便地直接改為env_file。</p>
<pre><code class="language-yaml"># docker-compose.yaml
services:
  ubuntu:
    image: ubuntu:22.04
    environment:
      - RACK_ENV=development
      - SHOW=true
      - USER_INPUT
</code></pre>
<p>上述的寫法沒有任何問題，不過如果你的docker-compose.yaml是放在git等版本控制中，你更新環境變數就有可能會影響到其他人，這時你就會想轉成env_file。</p>
<p>docker-compose.yaml預設就會讀當前資料夾的.env，就算不存在，也可以正常運行。（當然，大家的Image/Container應該要有預設值）</p>
<pre><code class="language-yaml"># docker-compose.yaml
services:
  ubuntu:
    image: ubuntu:22.04
    # if env_file is not defined, it will load .env.
    # or you can load the specific file.
    # env_file:
    #   - ./a.env 
</code></pre>
<p>env_file內，每一行就是一個變數</p>
<pre><code># .env or a.env
RACK_ENV=development
SHOW=true
USER_INPUT
</code></pre>
<p>使用預設的.env還有一個好處，就是我們可以把docker-compose.yaml也變成受環境變數控制。</p>
<pre><code class="language-yaml"># docker-compose.yaml with variable control, only works in default .env
services:
  ubuntu:
    image: ubuntu:${ubuntu_version}
</code></pre>
<pre><code># .env
ubuntu_version=22.04
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="distribution-registry-的設置與維護"><a class="header" href="#distribution-registry-的設置與維護">Distribution Registry 的設置與維護</a></h1>
<p>在這篇文章中，我們將會聊一聊如何設置 Docker 私有影像倉庫，包括標籤命名、SSL 配置及垃圾回收等操作，以確保 Docker Image 的有效管理。</p>
<h1 id="docker-tag-命名"><a class="header" href="#docker-tag-命名">Docker Tag 命名</a></h1>
<p>一般來講，同一個docker image會提供多個不同的版本，每個版本會附予不同的tag，以作標識。但以docker image的維護者來講，它的tag通常代表的是自己程式的版本號。不過這個版本號卻存在很多變數，就讓筆者好好地逐一說明。</p>
<h2 id="程式的版本號"><a class="header" href="#程式的版本號">程式的版本號</a></h2>
<p>在沒有Docker的年代，其實所有軟件在發佈時，都會標示版本號，方便使用方明確追蹤問題，自行選擇升級、降級以解決相容性問題。大家要重現問題，也能清清楚地重現。所以docker image的tag，在某程度，都是代表發佈自己的程式版本號。但以前的年代，軟件底層的依賴，例如OS層面的共享程式庫，則不在發佈的管控中，所以過去的程式，在跨電腦安裝時，都會出現缺少某些共享庫的問題。而使用了Docker後，image以內的共享庫的都會在打包的那一刻固定和發佈，就不會有漏的問題。</p>
<h2 id="庫更新怎麼辦"><a class="header" href="#庫更新怎麼辦">庫更新，怎麼辦</a></h2>
<p>上面說到image可以打包共享庫，但問題是共享庫也會有安全性更新問題，那麼對docker image的維護者來講，它自己的tag又該如何命名？</p>
<p>因為庫的量可大可少，所以一般來說，都不可能完全把各個庫的版本號寫在自己的tag上。退而求其次，就是用“版本號+日期“，庫的細版本號，就存在原始碼當中。<a href="https://hub.docker.com/_/ubuntu/tags">Ubuntu</a> 就是這樣的例子。</p>
<p>不過“版本號+日期“的命名方式真的方便嗎？每次下遊用戶想更新去最近版本，都要自己找一次最近的日期。這樣對很多用戶來講都不夠方便。所以docker又提供了一個重tag的功能。例如ubuntu:noble，在早些時候指著noble-20240904.1，然後過幾天，又指向更新的noble-20241009。更常見的是latest，每次image都預設會存在，docker也希望大家會定期更新這個tag，讓大家可以更易地找到最新版本。</p>
<p>註: 這跟git tag有所不同，git tag並不預期會變的。當協作者收到tag後，那怕上遊刻意更新tag指針，協作者沒有刪除原tag之前，都不會知道tag更新去了哪裏。</p>
<h2 id="我們該如何選"><a class="header" href="#我們該如何選">我們該如何選</a></h2>
<p>在發佈方和引用方來講，引用時可以明確使用唯一的“版本號+日期“，對穩定性來講是有意義的。不過多多少少，會產生額外的時間成本。發佈方來說，就是多用了一些儲存空間，方便引用方可以隨時找到舊(庫)版本。而引用方，就要手動修改引用號，作為驗收依據，自動更新的難度比較大。</p>
<p>但對於自動更新要求比較大的情況下，可能就是使用latest或者會隨時更新的share tag(共用tag)比較實際。但我們也依然要定一些方式去版本更新記錄，例如：同時使用</p>
<ul>
<li>beta</li>
<li>latest</li>
<li>archive</li>
</ul>
<p>每日自動更新beta，只有所有測試都通過時，才把archive指向現在的latest，再把latest指向現在的beta。這樣做的好處是，核心的docker stack檔案改變的機會較少，也可以免除docker swarm做太細緻的權限管理。</p>
<h1 id="private-registry-私有影像倉庫"><a class="header" href="#private-registry-私有影像倉庫">Private Registry 私有影像倉庫</a></h1>
<p><a href="https://distribution.github.io/distribution">Distribution</a> ，原本是由 docker 自己發行的私有影像倉庫 ，原名就為 “regsitry”。</p>
<p>如果 server 群沒有互聯網，又或對私隱很有要求，需要自建一個最簡單的倉庫，可以用這個。當然，那台機第一次必需經互聯網。架起後就可以斷網，並由其他 client 提送新的 registry image更新。</p>
<h2 id="registry-server-起動方式"><a class="header" href="#registry-server-起動方式">Registry Server 起動方式</a></h2>
<p>最簡單的起動方式，但什麼都不設定。</p>
<pre><code class="language-bash">docker run -d -p 5000:5000 --name registry registry:3
</code></pre>
<p>若想要加入 SSL，讓你的 client 不會認為它是不安全的 registry ，最簡易可以寫成 docker compose, 由 <code>docker compose up -d</code> 執行。</p>
<pre><code class="language-yml"># docker-compose.yml
registry:
  restart: always
  image: registry:3
  ports:
    - 5000:5000
  environment:
    REGISTRY_HTTP_TLS_CERTIFICATE: /certs/domain.crt
    REGISTRY_HTTP_TLS_KEY: /certs/domain.key
  volumes:
    - /path/data:/var/lib/registry
    - /path/certs:/certs
</code></pre>
<p>上述的 environment 中，有條件的話，還請設定需要登入才能訪問限制。最簡單，可以使用 apache http header 驗證方式。</p>
<pre><code class="language-diff"># docker-compose.yml
registry:
  restart: always
  image: registry:3
  ports:
    - 5000:5000
  environment:
    REGISTRY_HTTP_TLS_CERTIFICATE: /certs/domain.crt
    REGISTRY_HTTP_TLS_KEY: /certs/domain.key
+   REGISTRY_AUTH: htpasswd
+   REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd
+   REGISTRY_AUTH_HTPASSWD_REALM: Registry Realm
  volumes:
    - /path/data:/var/lib/registry
    - /path/certs:/certs
+   - /path/auth:/auth
</code></pre>
<p><code>REGISTRY_AUTH</code>, <code>REGISTRY_AUTH_HTPASSWD_PATH</code>, <code>REGISTRY_AUTH_HTPASSWD_REALM</code> 的值照抄就好，然後<code>/path/auth/htpasswd</code> 就需要以 htpasswd 的格式提供內容 <a href="https://httpd.apache.org/docs/2.4/misc/password_encryptions.html">apache password_encryptions</a>。即是以下那個樣子</p>
<pre><code>USERNAME_1:BCRYPT_HASH_1
USERNAME_2:BCRYPT_HASH_2
USERNAME_3:BCRYPT_HASH_3
</code></pre>
<h2 id="client-連線方式"><a class="header" href="#client-連線方式">Client 連線方式</a></h2>
<p>一切都設定好後，在 client 端，就可以登入並推送你的 image，(題外話，cli登入的都是以明文的方式存在電腦中，所以不要隨便在公開的地方存入自己的帳號)</p>
<pre><code class="language-bash"># login
docker login YOUR_DOMAIN:5000
# try re-upload image
docker image tag registry:3 YOUR_DOMAIN:5000/registry:3
docker image push YOUR_DOMAIN:5000/registry:3
</code></pre>
<p>如果 server 端沒有提供SSL，那麼 client 就只能設定 http 的不安全連線。 <a href="https://distribution.github.io/distribution/about/insecure/">https://distribution.github.io/distribution/about/insecure/</a></p>
<p>修改 <strong>client</strong> 端的 /etc/docker/daemon.json (Windows Docker Desktop請經 Gui修改)，然後重啟 <strong>client</strong> 端的 docker</p>
<pre><code class="language-json">{
  "insecure-registries" : ["YOUR_DOMAIN:5000"]
}
</code></pre>
<h2 id="registry-server-維護---garbage-collection-垃圾回收"><a class="header" href="#registry-server-維護---garbage-collection-垃圾回收">Registry Server 維護 - Garbage collection 垃圾回收</a></h2>
<p>當我們設立了自己的 Registry 倉庫之後，少不免就是要維護硬碟的用量。很多過期的 Image ，沒有需要，那就手動刪除，然後進行 Garbage collection (垃圾回收)。另一種情況，就如前述教學中，大家使用統一版本號，例如 latest ，表面上看似只有一個 tag ，但其實底下可能已經藏有多個不同的版本，也需要經過Garbage collection來清理空間。</p>
<p>因為回收過程比較危險，所以官方並不建議自動做，以下就簡單講講為了做刪除和回收，設定檔要怎樣改。為方便改設定，我們更新 docker compose yaml 檔，把 server config 都帶到 container 外面。</p>
<pre><code class="language-diff">registry:
  restart: always
  image: registry:3
  ports:
    - 5000:5000
  environment:
    REGISTRY_HTTP_TLS_CERTIFICATE: /certs/domain.crt
    REGISTRY_HTTP_TLS_KEY: /certs/domain.key
    REGISTRY_AUTH: htpasswd
    REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd
    REGISTRY_AUTH_HTPASSWD_REALM: Registry Realm
  volumes:
    - /path/data:/var/lib/registry
    - /path/certs:/certs
    - /path/auth:/auth
+   - /path/config.yml:/etc/distribution/config.yml
</code></pre>
<p>config.yml 就如下所示，為了提供 API 刪除 image 的可能，<code>storage.delete.enbled</code> 要為 <code>true</code>，又為著之後進行回收時，可以避免有人於回收中途上載，所以預先加入 <code>storage.maintenance.readonly.enabled</code> 的控制項。回收之前要把readonly改為true，回收後再調為false。 每次修改完，記得重啟一下 docker service 。</p>
<pre><code class="language-yml">storage:
  filesystem:
    rootdirectory: /var/lib/registry
  delete:
    enabled: true
  maintenance:
    readonly:
      enabled: false
</code></pre>
<p>Garbage collection 指令</p>
<pre><code class="language-sh"># inside container
# bin/registry garbage-collect [--dry-run] [--delete-untagged] [--quiet] /path/to/config.yml
bin/registry garbage-collect --delete-untagged=true /etc/docker/registry/config.yml

# outside container, at host level
docker exec -it YOUR_CONATINER_NAME bin/registry garbage-collect --delete-untagged=true /etc/docker/registry/config.yml
</code></pre>
<h1 id="draft-1"><a class="header" href="#draft-1">draft</a></h1>
<p>some image keep using same tag to keep check latest version; but older blob is not able to be deleted according to normal manifest garbage collection. Must use –delete-untagged flag to delete unused blob</p>
<p>quote from offical web site <a href="https://distribution.github.io/distribution/about/garbage-collection/">https://distribution.github.io/distribution/about/garbage-collection/</a>
The –delete-untagged option can be used to delete manifests that are not currently referenced by a tag.</p>
<h1 id="reference-1"><a class="header" href="#reference-1">Reference</a></h1>
<ul>
<li><a href="https://distribution.github.io/distribution/about/insecure/">https://distribution.github.io/distribution/about/insecure/</a></li>
<li><a href="https://distribution.github.io/distribution/about/garbage-collection/">https://distribution.github.io/distribution/about/garbage-collection/</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="oracle-database-in-docker"><a class="header" href="#oracle-database-in-docker">Oracle Database in Docker</a></h1>
<p>雖然筆者之前有提過，Docker並不是萬能，Docker在管理有狀態應用(Stateful Application)的情況下，只能走單機路線。但因為Docker實在很方便，所以連Oracle Database這類強狀態應用也有出<a href="https://github.com/oracle/docker-images/blob/main/OracleDatabase/SingleInstance/README.md">Docker版本</a>。當然，它在預設的情況下，只能在單機下操作。</p>
<p>不過即使在單機操作下，還是有一些跟其他Docker Image有差異的地方，需要特別拿出來聊聊。</p>
<p>假設根據官方的教學，跑起了一個oracle19c的Docker Container。再查看當中的Process，你會發現有一個內部PID為1的runOracle.sh</p>
<pre><code>sudo docker container exec -it oracle19c top
## top output
##    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
##      1 oracle    20   0   11712   2756   2480 S   0.0  0.0   0:00.04 runOracle.sh
sudo docker container top oracle19c
## UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
## 54321               1069154             1069135             0                   Sep14               ?                   00:00:00            /bin/bash /opt/oracle/runOracle.sh
</code></pre>
<p>在Docker中這個PID為1的Process是很重要的，它是判斷整個Container有沒有運行的依據。它就是當初在Docker Image中Entrypoint或CMD指定的那個指令生起的Process。Docker daemon要進行停止指令，要停止container時，也是對著PID為1的那個process來處理。</p>
<p>一般的情況下，如果PID為1的那個process可以無腦地停了、重開，那一切都好辦。但在Oracle Database的情況下，就不適合。因為Database始乎都是有交易概念的(Transaction)，它的停止並不是殺了process就了事，它還要考慮HDD操作中，有那些可以被考慮為完成，有那些下次要還原(undo)、重做(redo)。如果殺了process就等於Oracle 的Shutdown Abort，有機會下次開機會，就會有交易異常而且無法決定該如何操作。</p>
<p>大家需要先進入Docker container，經sqlplus進行必要的關閉Database指令。但此時，PID為1的那個process，其實還在進行中，在Docker 層面，它就像是Docker Container還在正常運行中，只是Database離線了。又因為sqlplus關閉Database並不是馬上有結果的，所以在整體關閉時可能需要串連command。就像</p>
<pre><code># in container
echo "shutdown immediate;" | sqlplus -s / as sysdba &amp;&amp; kill 1

# in docker host, by script
sudo docker container exec -it oracle19c /bin/sh -c 'echo "shutdown immediate;" | sqlplus -s / as sysdba' \
	&amp;&amp; sudo docker container stop oracle19c
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="docker-來源掃瞄---docker-image-scan"><a class="header" href="#docker-來源掃瞄---docker-image-scan">Docker 來源掃瞄 - Docker Image Scan</a></h1>
<p>當網安要求越來越高時，我們也要留心 docker image 的來源是不是有漏洞問題。 docker hub 本身就已經有一些安全掃瞄報告，以 nginx 的 1.27.3 版本為例， <a href="https://hub.docker.com/layers/library/nginx/1.27.3/images/sha256-1c93c0fdf35c65d1a441ea049552faea6395ce4d5ad96258344d6e65d4c8c29e?context=repo">docker hub nginx 1.27.3</a> ， docker hub 已經列出相當多的CVE漏洞。 不過對於不公開的 docker image ，安全描瞄可是要收費的。作為小團隊，可能想先尋求一些簡單的免費方案。如果你想同樣的需求，可能Trivy會幫到你。</p>
<h2 id="trivy"><a class="header" href="#trivy">Trivy</a></h2>
<p><a href="https://trivy.dev/latest/">Trivy</a> 是一個用於描瞄軟件版本依賴或設定檔是否引用到一些有漏洞問題的軟件，它也能檢測 docker image 是否有漏洞或錯誤設定的問題。而且更好的是， Trivy 本身亦有 Docker Image 版本，我們就不用煩惱怎樣弄一個 Trivy 的執行環境，只要可以運行 docker ，有網路就可以了。但使用 Docker Image 版的 Trivy 有一個額外要求，就是它要有主機上的 docker.sock 權限。</p>
<p>描瞄的指令如下，其中 docker.sock 就是為了讓 containers 內部的程式可以存取主機的 docker daemon , .cache 則是為了方便暫在下載資源。</p>
<pre><code class="language-bash">docker run -v /var/run/docker.sock:/var/run/docker.sock -v $HOME/.cache/:/root/.cache/ aquasec/trivy:0.58.0 image nginx:1.27.3
docker run -v /var/run/docker.sock:/var/run/docker.sock -v $HOME/.cache/:/root/.cache/ aquasec/trivy:0.58.0 image nginx:1.27.3-alpine
</code></pre>
<p>上面故意用 nginx 的兩個同版本號不同平台的 docker image，其實就是為了引出一些潛在問題。nginx 預設是使用的debain OS的，在筆者寫文章的當下，已經更新到最近的 image ，但始終有一大部份可能的漏洞。反觀 alpine OS 版本，就找不到這麼多問題。</p>
<pre><code>nginx:1.27.3 (debian 12.8)
==========================
Total: 141 (UNKNOWN: 0, LOW: 93, MEDIUM: 30, HIGH: 16, CRITICAL: 2)

nginx:1.27.3-alpine (alpine 3.20.3)
===================================
Total: 0 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0)
</code></pre>
<p>這是因為 alpine 預設安裝的依賴較少，所以找到的漏洞也少。正所謂，做多錯多，唔做唔錯（大誤）。這其實有好有不好，因為在發生問題時，在 alpine 下可能連基本的除錯工具都沒有。除非大家有完整測試，或者對 alpine 有相當的認識，你才會選擇一個非官方預設的版本。但就以事論事，引用較少的依賴，長久之下的確是不會有那麼多隱患。大家如果有條件，也可以試試 alpine 或其他版本。</p>
<h2 id="podman-怎麼辦"><a class="header" href="#podman-怎麼辦">podman 怎麼辦？</a></h2>
<p>前一節我們可以看到，Trivy需要經過 socket 的方式才能存取主機上的 container daemon 操作權。但 podman 作為一個不主張 daemon (daemon less)，亦主張不需要 root (rootless)，那麼它該怎樣執行？</p>
<p>其實podman也有user層面上的 socket，而且 trivy 也有對應的方式去轉用第三方 socket (有點像使用遠端主機 socket，但官方並未宣佈正式支援遠端的方式。)</p>
<p>具體使用方式，筆者亦已在 steam deck 上測試，使用方式如下。不過因為 steam deck 預設沒有 root，筆者就省略 cache 指令，免得之後要有權限問題要手動清理。</p>
<pre><code class="language-bash">$ systemctl --user start podman.socket
$ ls $XDG_RUNTIME_DIR/podman/podman.sock
/run/user/1000/podman/podman.sock
$ podman run -v $XDG_RUNTIME_DIR/podman/podman.sock:$XDG_RUNTIME_DIR/podman/podman.sock  \
--rm docker.io/aquasec/trivy:0.58.0 image --docker-host=unix://$XDG_RUNTIME_DIR/podman/podman.sock  \
nginx:1.27.3
</code></pre>
<h1 id="ref"><a class="header" href="#ref">Ref</a></h1>
<ul>
<li><a href="https://github.com/containers/podman/blob/main/docs/tutorials/socket_activation.md">Podman socket activation</a></li>
<li><a href="https://github.com/aquasecurity/trivy/issues/3098">Trivy: Support for rootless podman</a></li>
</ul>
<pre><code class="language-bash">docker run -v /YOUR_PROJECT/:/opt/YOUR_PROJECT/ aquasec/trivy fs --scanners vuln,secret,misconfig /opt/YOUR_PROJECT/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="docker-中的非管理員用户-docker-non-root-user"><a class="header" href="#docker-中的非管理員用户-docker-non-root-user">Docker 中的非管理員用户 Docker non-root user</a></h1>
<h2 id="container-user為何重要"><a class="header" href="#container-user為何重要">Container USER為何重要</a></h2>
<p>在制作Docker Image的過程中，有時會接觸到 USER 這個設定。這事關到最後的 Docker Container內部運行的那個 user 到底會有什麼權限。大家也要知道，Docker Container 其實也只是一個 Linux 上的程序，也就是如果Container內權限過大，也有機會從 Container 內部存取到 Host上的資料。</p>
<p>一般情況下，Docker Image 預設的 USER 就是 root，最基礎的base image都是一樣。而我們想換，其實也相當簡單，就像Linux上起User一樣，只要經指令<code>RUN adduser xxx</code> 或<code>RUN useradd xxx</code> 也可以在 Docker Image 中創建帳號和 home 資料夾，之後就隨時經<code>USER xxx</code>來切換</p>
<h2 id="實際上是不是這麼簡單"><a class="header" href="#實際上是不是這麼簡單">實際上是不是這麼簡單?</a></h2>
<p>如果你將要Container中執行的程序，是一個binary，平常你在Linux中也是以 non-root 方式執行，那麼是的，就是那麼簡單。例如你執行系統中的java, node, python，原本在Linux中就已經是誰都可以，那麼你的docker container 也應該沒有難度。</p>
<p>但如果原本的安裝包，預設是由system service來啟動，我們就要花點力氣，看看那個service是怎樣呼叫binary的，然後就一步一步模擬它的做法。例如筆者有打包的codeserver，預設是system service啟動，但它也有提共binary的執行方法，安定好home資料夾後，我們也可以手動啟動。</p>
<h2 id="泛生之檔案權限問題"><a class="header" href="#泛生之檔案權限問題">泛生之檔案權限問題</a></h2>
<p>上述binary的情境之所以簡單，是因為大部份情況下，我們都只對於container 內部運行考慮即可，因為預設投產情況下的運作模式，都是隨時起、隨時刪、隨時砍掉重練，只要container內部運作可以自給自足，就可以了。Docker Swarm的運作也是如此，所以它不預期有的持久化資料權限的問題。</p>
<p>而持久化資料權限的問題，其實早在單個Linux伺服器就已經存在。同一個伺服器中，不同process就有不同的UID，當他們需要共同讀/寫某些檔案，就會設定多人權限。同理，當多個Container要共同檔案，也是同樣問題。在討論共享檔案之前，我們先看看預設 Docker Storage Mount 會給我們什麼權限。</p>
<ul>
<li>如果是bind mount，bind mount的權限預設會是Host內的檔案或者資料夾的權限。
<ul>
<li>如果Host是root，container內是non-root，container有機會無法讀寫bind mount內的檔案。
<ul>
<li>留意權限設置就可以解決問題</li>
</ul>
</li>
<li>如果Host是non-root，但container 內是root，從container內生成的檔案，Host的non-root user就無法使用。
<ul>
<li>Host是non-root的話就一定無解，Host至少有sudo權限，臨時變成管理員，去修正問題。</li>
</ul>
</li>
<li>如果host和container也是non-root，但UID不夾，其實也不能交換使用。
<ul>
<li>跟上述一樣，最後要靠sudo來解決問題。</li>
</ul>
</li>
<li>如果host和container也是root，就沒有權限問題，但就有安全性的風險。</li>
</ul>
</li>
<li>如果是volume mount，就還是看看 mount path 是docker image layer中現有的 path還是新起的path
<ul>
<li>大部份手動建立的named volume都是root</li>
<li>經docker compose起的named volume滿足以下條件的話，將會是non-root。
<ul>
<li>docker image 中的已有該path存在。</li>
<li>named volume未存在，docker compose會把對應path的內容在初次建立時抄到named volume 中。</li>
<li>例如ubuntu:24.04中的/home/ubuntu，存在於docker image中，它的擁有者就是UID 1000，我們經docker compose <code>HOME_VOLUME:/home/ubuntu</code>，在HOME_VOLUME建立時，就會是UID 1000。但如果是 <code>NOT_EXISTS:/home/ubuntu/somethingNotExists</code>，那麼NOT_EXISTS建立時，也會是root</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>上述討論的Storage mount是集中在單機情況下，使用HOST OS的本地儲存。若現在的場境是多機共享的share storage，就會更麻煩，還要看看那個share storage本身的屬性。例如常見的Linux NFS，其實有指定的權限，跟NFS的Login權限有關，如果你的process本身對檔案權限很敏感，就請先不要挑戰NFS(例如postgresql)。</p>
<h2 id="rootless-mode---rootless-模式"><a class="header" href="#rootless-mode---rootless-模式">Rootless mode - Rootless 模式</a></h2>
<p>Rootless 模式指的是在Host中，執行Container的使用者，不需要是管理員，筆者就常用於開發環境中。投產環境中反而沒有聽過這樣的討論，因為投產環境很少可以讓非管理員去執行這麼重要的環境管理。</p>
<p>雖然只是開發環境，但這像前述的bind mount討論中，如果Host是non-root，但container 內是root，又或是兩者non-root，但UID不夾，也會出現權限問題。無腦的將host user加入docker group，只可以讓非管理員可以運行docker，但解決不了權限問題。</p>
<p>真正有條件解決的，可能就會向linux subgroup的方式發展。暫時筆者用得比較順的rootless mode，可以無腦用的，不是docker，是podman。有興趣的朋友可以經podman官網看看教學，它給筆者的感覺就像是自動轉換UID。</p>
<p><a href="https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md">podman rootless mode</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="steam-deck-with-podman"><a class="header" href="#steam-deck-with-podman">Steam Deck With Podman</a></h1>
<p>眾所週知，Steam Deck預裝的是一台Linux主機。但它的系統比較特別，為了可以安全更新，所以系統最主要的部份都設定為唯讀(read only)。也就是，傳統你可以直接在Linux上經管理員權限安裝的軟件包，全部都會被擋，即使你把唯讀部份設為可讀寫(read / write)，在下次更新時，都會被一次過覆蓋掉。</p>
<p>筆者作為一個負責任的機迷+開發者，怎樣可以白白讓一台Linux機只可以玩遊戲呢? (怎樣跟老婆交代呢?)</p>
<p>所以筆者千辛萬苦，找到一個折衷方案，讓他可以當為開發機使用，那就是Podman。(當然，若果大家有條件有金錢，直接改裝Windows就可以了。)</p>
<h1 id="podman是什麼"><a class="header" href="#podman是什麼">Podman是什麼?</a></h1>
<p>Podman跟Docker一樣，都是一些管理和運行Container的主程式。跟Docker不一樣的是，它是Open source，而且是daemonless。</p>
<p>所謂的daemonless，就是不會有一個背景程式去長期管理Container。好處是不會因為背景程式死了，就全部Container一起掛掉，預設也不需要走管理員權限路線。但也因此跟Docker有一些使用上的差異，例如Podman沒有原生的docker-compose結構，即使坊間有python寫的podman-compose去硬對應docker-compose，但某些network是跟結構還是不能直接從Docker轉移過來。</p>
<p>就筆者早期的踩雷經驗而言，用Podman跑起一兩個獨立固定Port的Container來說，都很夠用，也不會遇到奇怪的Bug。所以這次，亦用來作為Steam Deck運行整合式開發的Container。</p>
<h1 id="steam-os-35-後"><a class="header" href="#steam-os-35-後">Steam OS 3.5 後</a></h1>
<p>在Steam OS 3.5之後，已經有預安裝的 podman，筆者建議，就直接使用預安裝版本就好。如果一定要自行安裝，請參閱後述的 【Steam OS 3.5前，不平凡的安裝之路】。</p>
<h2 id="build-in-podman"><a class="header" href="#build-in-podman">build in podman</a></h2>
<p>Steam OS 3.5，雖然已經有預安裝 podman ，但在實際環境下，多安裝一個 podman-compose 可以更方便地一體化操作。 我們可以經 python 安裝。</p>
<pre><code class="language-bash"># install podman-compose by python package manager pip
python -m ensurepip --upgrade
python -m pip install podman-compose
</code></pre>
<p>剛安裝 podman-compose ，會出現在自己的 home 目標的隱藏目錄。最後一步就是要加到自己的 PATH 環境變數裏面。我們如果源用 bash 設定，就直接修改 <code>~/.bash_profile</code> 。</p>
<pre><code class="language-bash"># edit .bash_profile, add following command
export PATH=$PATH:~/.local/bin/

# then reboot / source .bash_profile
</code></pre>
<p>修改保存後，就重啟。之後 podman-compose 的指令就可以任意存取了。</p>
<p>要補充一點，就是官方預安裝的 podman 還是缺少了一些 DNS 的元件，大家會看到 warning 提示。<code>WARN[0002] aardvark-dns binary not found, container dns will not be enabled</code>。該問題筆者認為主要是 podman rootless 的網路模式有很多限制，有很多功能都不是預設可以使用，要麽自行安裝 plugin 。內部網路是正常的，但唯獨DNS沒法解釋，所以如果大家只做 ip 測試是沒有問題。但若然想要互聯網服務，就必需要自己進行DNS解釋。例如你可能要這樣</p>
<pre><code class="language-bash">curl https://github.com --resolve 'github.com:443:140.82.116.4'
</code></pre>
<p>這個解法最麻煩的是要為每個 service 內部重新安裝網絡DNS，就有點像每個 service 的內部環境都要很熟悉才能解，所以這並不是一個十分有效的做法。</p>
<p>我們還有另一種解法，就是 service 設定檔中將 network_mode 設為 host ，即是直接使用主機上的網絡。然後各個 service 之間都直接使用 localhost 溝通，它們之間的 port 也是互相看到的，而且連接互聯網時，DNS 也可以正常運作。但這個解法的缺點就同一個 port 不能有多個 service 使用，也就是不可能簡單地進入群集模式。不過我們現在主要用於開發環境，所以這並不會是很太大的問題。</p>
<h2 id="build-in-distrobox"><a class="header" href="#build-in-distrobox">build in distrobox</a></h2>
<p>在 Steam OS 3.5 中，除了 podman 外，還有預裝 distrobox 。 distrobox 其實是基於 container 技術的擴展應用，它目標是讓用經過 container 就可以輕鬆使用到不同 linux 的發佈版本。例如我想在 Steam OS 中使用 Ubuntu ，經過 distrobox 就可以用到。道理上， distrobox 基於 container (podman) 操作的，所以它能做到的，其實自己手動經 podman 也是可以做到。但若果大家想使用跨 Linux 版本的 GUI 程式，筆者還是建議優先使用 distrobox 。因為 distrobox 預設已為不同版本的 Linux 的 Image (來源影像檔) 加入部份調整，在運行時亦有x11等互通，指令也較為簡單。</p>
<p>以下做來例子，示範在 Steam OS 中就執行 Ubuntu 版本的 vscode。</p>
<pre><code class="language-bash">xhost +si:localuser:$USER # enable x11 for desk user

distrobox create --image ubuntu:24.04 --name ubuntu
distrobox enter ubuntu

# install vscode inside distrobox ubuntu
sudo apt-get install wget gpg
wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &gt; packages.microsoft.gpg
sudo install -D -o root -g root -m 644 packages.microsoft.gpg /etc/apt/keyrings/packages.microsoft.gpg
echo "deb [arch=amd64,arm64,armhf signed-by=/etc/apt/keyrings/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main" |sudo tee /etc/apt/sources.list.d/vscode.list &gt; /dev/null
rm -f packages.microsoft.gpg

sudo apt install apt-transport-https
sudo apt update
sudo apt install code # or code-insiders

# start vscode inside distrobox ubuntu
code

# delete distrobox ubuntu
distrobox stop ubuntu
distrobox rm ubuntu
</code></pre>
<p>註: Distrobox 也不是萬能的，例如它的 Ubuntu 版本內沒有 snap ，所以不能執行 Ubuntu 版本的 Firefox。
snap will not works (firefox not works)</p>
<h1 id="steam-os-35前不平凡的安裝之路"><a class="header" href="#steam-os-35前不平凡的安裝之路">Steam OS 3.5前，不平凡的安裝之路</a></h1>
<p>以下內容寫於2023年10月，當時版本為 Steam OS 3.4.x。 2023年11月之後 Steam OS 3.5.x , 3.6.x 推出後，筆者還有使用一段時間。直至2024年10月，才正式砍掉重練。以下安裝步聚，大家請留意是否有需要微調。</p>
<h2 id="install-homebrew"><a class="header" href="#install-homebrew">install homebrew</a></h2>
<p>Steam OS 3，雖然可以使用更改read / write，再使用pacman來安裝podman。但因為Steam OS更新後，全部要重來，工作量和網路流量都不少，所以筆者改為使用homebrew來安裝podman。homebrew只需要首次安裝時使用管理員權限，之後就會在/home資料夾下留下可執行的程式，所以它不會被Steam OS更新所破壞。</p>
<pre><code class="language-bash"># brew install script, need sudo password
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"  # with sudo password

# brew post install script, no sudo required
(echo; echo 'eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"') &gt;&gt; /home/deck/.bash_profile
eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
</code></pre>
<h2 id="install-podman"><a class="header" href="#install-podman">install podman</a></h2>
<pre><code class="language-bash">brew install podman

# running rootless mapping for podman container
# it might also affect how it download oci image
sudo touch /etc/subuid /etc/subgid
sudo usermod --add-subuid 100000-165535 --add-subgid 100000-165535 $USER
</code></pre>
<p>記得記得重新開機，之後應該就可以成功運行container</p>
<pre><code class="language-bash">podman container run --name ubuntu2204 -it ubuntu:22.04 bash
</code></pre>
<h2 id="install-pasta"><a class="header" href="#install-pasta">install pasta</a></h2>
<p>似乎在 podman 升級到 5.0.x 之後，需要一個名為 “pasta” 的依賴套件。這個套件要麼透過 pacman 安裝或從原始碼進行編譯。但為了避免 Steam OS 在更新時會破壞套件，我選擇了直接下載了它的二進位檔案。（我嘗試從原始碼編譯，但許多C 函式庫在 Steam OS 上無法取得的，最後只能直接下載官方的二進位檔。）</p>
<p>It seems after upgrading podman to 5.0.x, podman need a dependency “pasta”. Either install by pacman or build from source. In-case steam os will break the package later, I download the binary directly. (I tried to build from source but a lot of c library missing from steam os. That’s why I download the binary direclty form official website)</p>
<pre><code class="language-bash">curl https://passt.top/builds/latest/x86_64/pasta -o pasta

chmod u+x pasta
# chmod a+x pasta, if pasta's owned by root. let it share exec permission for everyone.

# update PATH variable in current session or add in ~/.bashrc
export PATH=$PATH:$(pwd)
</code></pre>
<h2 id="change-oci-runtime"><a class="header" href="#change-oci-runtime">change oci runtime</a></h2>
<p>在添加了 pasta 之後，運行 podman 5.0.x 仍然失敗。podman 會抱怨 ‘crun’ 的版本不正確。這是由於機器上存在兩個版本的 ‘crun’，一個來自 Steam OS 的 /usr/bin/crun，一個來自 brew。</p>
<p>After adding pasta, running podman 5.0.x still fail. podman complaint ‘crun’ version is wrong. Becuase two verions of ‘crun’ in the machine, one from steam os /usr/bin/crun, one from brew.</p>
<pre><code class="language-bash">podman run --name basic_httpd -dt -p 8080:80/tcp docker.io/nginx
# Error: OCI runtime error: crun: unknown version specified
</code></pre>
<p>為解決這個問題，我們需要修改 podman 的設定，讓它的 oci runtime指向 brew 資料夾。（或者任何一個你行找回來的版本，版本最底要求為1.14.x以上，crun於brew 的版本為1.15)</p>
<p>To solove the problem, need to config podman oci runtime to brew folder. (or any crun path with version higher than 1.14.x, version of crun in brew is 1.15)</p>
<pre><code class="language-bash">mkdir -p ~/.config/containers/
cp /usr/share/containers/containers.conf ~/.config/containers/
</code></pre>
<p>如下，在<code>[engine.runtimes]</code>底下加入 brew crun path</p>
<p>add brew crun path to section <code>[engine.runtimes]</code> like below</p>
<pre><code class="language-conf"># vim ~/.config/containers/containers.conf
[engine.runtimes]
crun = [
  "/home/linuxbrew/.linuxbrew/bin/crun"
]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="notes-about-customizing-cloud-image-for-multipass"><a class="header" href="#notes-about-customizing-cloud-image-for-multipass">Notes about customizing cloud image for Multipass</a></h1>
<h2 id="前言"><a class="header" href="#前言">前言</a></h2>
<p>原本筆者只是想做docker cluster，但因為在實機中建VM極其麻煩，所以就研究了好一陣子如何快速起VM。</p>
<p>以下是筆者有初步研究，但未有完全實行的方向。</p>
<ul>
<li>Hyper-V (2023-08-17 更新)
<ul>
<li>有預設的Ubuntu template，但只有ubuntu desktop版，沒有server版。Desktop gui顯得浪費資源</li>
<li>clone VM很費時，需要通過Export，Import達到Clone效果。若好好地處理各VM的HDD存放位置，Export，Import也不錯。</li>
<li>沒有自帶的cloud-init，需要自己想辦法做一些Clone後置的處理。</li>
<li>若要走cloud image + cloud-init，可能需要<a href="https://learn.microsoft.com/en-us/windows-hardware/get-started/adk-install">Windows ADK</a>，並配合qemu做轉換。</li>
</ul>
</li>
<li>Windows Subsystem Linux
<ul>
<li>起VM很方便，但同一個Linux version只有一個instance</li>
<li>可能需要需要通過Export，Import Instance來達到Clone效果</li>
<li>可能沒有fix ip。可能對於起docker swarm不利。</li>
</ul>
</li>
<li>Virtual box (2024/01/31 更新)
<ul>
<li>沒有Ubuntu template</li>
<li>若要clone的話就變得跟Hyper-V差不多。</li>
<li>Virtual Box, Hyper-V應該要跟Vagant結合，這樣可以取代multipass + packer的組合。</li>
<li>Vagent原本就提供了很多Image Template，官方稱為Box，但主要以供給Virtual Box使用為主。若你需要於Hyper-V執行特定的Linux，可能需要找一些第三方提供的Image Template。</li>
</ul>
</li>
</ul>
<p>經過一輪資料搜集，發現了一個Ubuntu multipass engine，聲稱可以跨平台快速起VM。裏面有一些很吸引的功能，可以自己建立images、使用固定IP。</p>
<p>那怕即使是沒有snapshot，在自定義images的配合下預裝docker，要隨時加減cluster node都是一件容易的事。</p>
<h1 id="ubuntu-multipass"><a class="header" href="#ubuntu-multipass">Ubuntu multipass</a></h1>
<h2 id="參考軟硬件需求"><a class="header" href="#參考軟硬件需求">參考軟硬件需求</a></h2>
<p>醜話說在前頭。經過一輪測試，multipass最大的問題，就是custom image、fix IP都只能在ubuntu中才能使用。以下是筆者成功實現的軟硬件架構。</p>
<ul>
<li>你可以使用實體主機，BIOS提供Virtualization，在實機上安裝Ubuntu，最後行起multipass。
<ul>
<li>參考配置: 實機:CPU 10 core, 32G RAM, 1T HDD</li>
</ul>
</li>
<li>你可以使用實機主機，BIOS提供Virtualization，在實機上安裝Windows 10 和Hyper-V，並在Hyper-V上安裝ubuntu，並對該Ubuntu提供ExposeVirtualizationExtensions。
<ul>
<li>參考配置: 實機:CPU 10 core, 32G RAM, 1T HDD；VM Ubuntu: CPU 4 core，10G RAM，128G HDD</li>
</ul>
</li>
</ul>
<h2 id="重點"><a class="header" href="#重點">重點</a></h2>
<p>詳細的Proof of Concept，筆者記錄了在</p>
<ul>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage">Packer template git repo link</a>
<ul>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/template.pkr.hcl">Packer template.pkr.hcl link</a></li>
<li><a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/initDockerCluster.sh">Multipass run packer image script link</a></li>
</ul>
</li>
<li><a href="#在ubuntu-server-2204上安裝multipass並配置固定ip的注意事項">Multipass Static IP script snippet</a></li>
</ul>
<p>在這裏就補充一些重點。</p>
<ul>
<li>packer是使用cloud-init和qemu的技術，行起template中指定的cloud image (在筆者的例子中就是ubuntu-22.04-server-cloudimg-amd64.img)</li>
<li>大家可以定義image行起後進行一些操作，而那些操作都是經過qemu vnc、ssh進去操作的。</li>
<li>操作完後就會直接儲存當時的image。所以在操作結束之前，盡可能地刪cache或刪去不要的user / group settings。</li>
<li>最後生成的image，還是一個cloud image。若要再運行它，必需要使用支援cloud-init的VM來讀取。</li>
<li>cloud-init是用來指定初次運行時要設定的事，例如:hdd size, user account password, ssh key import等。</li>
<li>使用工具cloud-localds可以生成一個seed.img，這樣qemu也可以cloud-init。</li>
<li>Hyper-V應該也可以經過類似方式，進行cloud-init，但筆者未有去實測。如有更簡便的方法請告知。</li>
<li>multipass預設就已經有cloud-init，在ubuntu就可以直接執行。</li>
<li>multipass也可以設定不同的cloud-init參數。</li>
</ul>
<h2 id="成品"><a class="header" href="#成品">成品</a></h2>
<p>最後筆者就選擇了用packer用來預裝docker，經mulitpass無腦起VM，再使用 <a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/initDockerCluster.sh">shell script</a> 對多個node設定docker，達到即時起docker node的功能。這樣就減省了VM的安裝時間，也省去了docker的安裝問題。</p>
<p>說到底，如果只想測試docker cluster，其實windows, macOS中的multipass也可以實現相同的功能。因為安裝docker那些都可以經過shell script自動化，只是每次重複操作，都變得相當慢。另外，因為multipass在windows, macOS不支援fix ip，對於指定docker cluster interface又會再多一重功夫。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="在ubuntu-server-2204上安裝multipass並配置固定ip的注意事項"><a class="header" href="#在ubuntu-server-2204上安裝multipass並配置固定ip的注意事項">在Ubuntu Server 22.04上安裝Multipass並配置固定IP的注意事項</a></h1>
<p>安裝Multipass很容易的，但配置固定IP就不是了。</p>
<p>另一個問題是官方文件都認為設定固定IP不是Multipass的範圍，它不想講太多。 但根據我的經驗，它的<a href="https://multipass.run/docs/configure-static-ips">官方例子</a>在Ubuntu Server 22.04並不能用。 (它可能可以在Ubuntu桌面上運行吧，但我不確定。)</p>
<p>以下是我在不斷踩坑後找到的解決方案。</p>
<h2 id="通過snap安裝multipass"><a class="header" href="#通過snap安裝multipass">通過snap安裝Multipass</a></h2>
<p>簡單，無腦</p>
<pre><code>sudo snap install multipass
</code></pre>
<h2 id="在主機上配置virtual-bridge"><a class="header" href="#在主機上配置virtual-bridge">在主機上配置Virtual Bridge</a></h2>
<p>很重要，很重要，很重要，在所有操作之前停止multipass。然後使用“network-manager“包安裝命令工具“nmcli“。</p>
<pre><code>sudo snap stop multipass.multipassd
sudo apt-get update &amp;&amp; sudo apt-get install network-manager
</code></pre>
<p>修改NetworkManager配置，以便它可以管理所有bridge interface。預設情況下，有很多類型的接口它都不管的。您需要在’unmanaged-devices’行的末尾添加 “<em><strong>,except:type:bridge</strong></em>”。</p>
<pre><code>sudo vim /usr/lib/NetworkManager/conf.d/10-globally-managed-devices.conf
</code></pre>
<p>NetworkManager Config Example</p>
<pre><code class="language-conf">[keyfile]
unmanaged-devices=*,except:type:wifi,except:type:gsm,except:type:cdma,except:type:bridge
</code></pre>
<p>然後重新運行NetworkManager.service，並添加具有固定IP範圍的Bridge network interface。</p>
<pre><code>sudo systemctl reload NetworkManager.service 
sudo nmcli connection add type bridge con-name localbr ifname localbr \
    ipv4.method manual ipv4.addresses 10.13.31.1/24
</code></pre>
<p>現在，如果您使用<code>ip a</code>檢查主機所有網卡，新network interface應該已經出現（但有機會是處於關閉狀態）。</p>
<h2 id="將multipass切換到lxd"><a class="header" href="#將multipass切換到lxd">將Multipass切換到lxd</a></h2>
<p>Multipass網絡功能目前只在<em><strong>lxd</strong></em>後端上提供。</p>
<pre><code class="language-bash">sudo snap start multipass.multipassd
# 在轉driver前，先刪掉所有VM。轉了之後就無法管控之前的VM
multipass delete --all &amp;&amp; multipass purge
multipass set local.driver=lxd
</code></pre>
<p>以下指令與官方教學相同。</p>
<h2 id="在vm中創建額外的網卡"><a class="header" href="#在vm中創建額外的網卡">在VM中創建額外的網卡</a></h2>
<p>在創建新的VM實例時創建額外的網卡。</p>
<pre><code class="language-bash"># 建立新VM時指定它的網卡和mac地址
multipass launch --name test1 --network name=localbr,mode=manual,mac="52:54:00:4b:ab:cd"

# 修改設定檔，對應mac地址使用固定IP
multipass exec -n test1 -- sudo bash -c 'cat &lt;&lt; EOF &gt; /etc/netplan/10-custom.yaml
network:
    version: 2
    ethernets:
        extra0:
            dhcp4: no
            match:
                macaddress: "52:54:00:4b:ab:cd"
            addresses: [10.13.31.13/24]
EOF'

# 重啟VM實例網絡。
multipass exec -n test1 -- sudo netplan apply

# 然後，您應該在VM上看到固定IP列表。
multipass info test1
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="使用-multipass-建立docker-cluster"><a class="header" href="#使用-multipass-建立docker-cluster">使用 Multipass 建立Docker Cluster</a></h1>
<p>以下流程，假設各位已經</p>
<ul>
<li>在Ubuntu Server中開設了virtual bridge 供Multipass設定<a href="#在ubuntu-server-2204上安裝multipass並配置固定ip的注意事項">Static IP</a>，並且network interface定為 <em><strong>localbr</strong></em></li>
<li>使用Packer template制成<a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/template.json">docker.img</a> , 並存放於當前資料夾內</li>
</ul>
<p>使用docker.img 起三個node，並使用network interface <em><strong>localbr</strong></em>，各有一個指定的mac address</p>
<pre><code class="language-bash">multipass launch file://$PWD/docker.img --name node21 --network name=localbr,mode=manual,mac="52:54:00:4b:ab:21"
multipass launch file://$PWD/docker.img --name node22 --network name=localbr,mode=manual,mac="52:54:00:4b:ab:22"
multipass launch file://$PWD/docker.img --name node23 --network name=localbr,mode=manual,mac="52:54:00:4b:ab:23"
</code></pre>
<p>對運行中的三個node，為它們設定static ip</p>
<pre><code class="language-bash">multipass exec -n node21 -- sudo bash -c 'cat &lt;&lt; EOF &gt; /etc/netplan/10-custom.yaml
network:
    version: 2
    ethernets:
        extra0:
            dhcp4: no
            match:
                macaddress: "52:54:00:4b:ab:21"
            addresses: [10.13.31.21/24]
EOF'

multipass exec -n node22 -- sudo bash -c 'cat &lt;&lt; EOF &gt; /etc/netplan/10-custom.yaml
network:
    version: 2
    ethernets:
        extra0:
            dhcp4: no
            match:
                macaddress: "52:54:00:4b:ab:22"
            addresses: [10.13.31.22/24]
EOF'

multipass exec -n node23 -- sudo bash -c 'cat &lt;&lt; EOF &gt; /etc/netplan/10-custom.yaml
network:
    version: 2
    ethernets:
        extra0:
            dhcp4: no
            match:
                macaddress: "52:54:00:4b:ab:23"
            addresses: [10.13.31.23/24]
EOF'

multipass exec -n node21 -- sudo netplan apply
multipass exec -n node22 -- sudo netplan apply
multipass exec -n node23 -- sudo netplan apply
</code></pre>
<p>使用node21作為Leader (Manager)，與其他兩個node一起組成Cluster</p>
<pre><code class="language-bash">multipass exec -n node21 -- sudo docker swarm init --advertise-addr 10.13.31.21
multipass exec -n node21 -- sudo docker swarm join-token manager

managerToken=$(multipass exec -n node21 -- sudo docker swarm join-token manager -q)
multipass exec -n node22 -- sudo docker swarm join --token $managerToken 10.13.31.21:2377
multipass exec -n node23 -- sudo docker swarm join --token $managerToken 10.13.31.21:2377
</code></pre>
<p>Cluster就建立完成。</p>
<p>若想刪掉重來</p>
<pre><code class="language-bash">multipass delete node21
multipass delete node22
multipass delete node23
multipass purge
</code></pre>
<h2 id="備註"><a class="header" href="#備註">備註</a></h2>
<p>在直正使用時，大部份時間還需要做port forwarding。multipass沒有自己的port forward，可以用ssh tunnel來模擬。</p>
<p>例如把Ubuntu Server的8080指向node21的8080，可以這樣</p>
<pre><code class="language-bash">sudo ssh -i /var/snap/multipass/common/data/multipassd/ssh-keys/id_rsa -L 0.0.0.0:8080:10.13.31.21:8080 ubuntu@10.13.31.21
</code></pre>
<p>完整的script可以參考<a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/initDockerCluster.sh">initDockerCluster.sh</a>。</p>
<p>沒有Bare Metal Ubuntu或者沒有static ip也可以參考<a href="https://github.com/macauyeah/ubuntuPackerImage/blob/main/initDockerClusterWithoutStaticIp.sh">initDockerClusterWithoutStaticIp.sh</a>。只是因為network brandwidth問題，我就不會在每次更新時都測試。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="vmware下建立docker-cluster"><a class="header" href="#vmware下建立docker-cluster">Vmware下建立Docker Cluster</a></h1>
<p>之前都使用Multipass作為Proof of Concept，自己做測試用。直正上Production，Network環境就多少有點差異。</p>
<p>假設大家為Application Admin，但無條件處理Vmware層面上的事項，只可以從VM內部install / setup application。</p>
<h2 id="安裝docker"><a class="header" href="#安裝docker">安裝Docker</a></h2>
<p>script 都來自<a href="https://docs.docker.com/engine/install/ubuntu/">Docker 官方網</a>，筆者微調了一些auto accept選項。</p>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg

sudo install -m 0755 -d /etc/apt/keyrings
curl -kfsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg

echo \
  "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  "$(. /etc/os-release &amp;&amp; echo "$VERSION_CODENAME")" stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null

sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
</code></pre>
<p>假設三台VM已經安裝docker，ip分別為 10.13.31.21, 10.13.31.22, 10.13.31.23。</p>
<p>在其中一台VM上，例如:ip 10.13.31.21上，</p>
<pre><code>sudo docker swarm init --advertise-addr 10.13.31.21 --data-path-port=7777
</code></pre>
<p>與前述Multipass不同的是，這裏的data-path-port要自定義，因為預設的<em><strong>port 4789</strong></em>在Vmware的有特殊同途。</p>
<p>之後部份就跟傳統做法一樣，先取得manager join token, 然後在其他VM上使用該token加入cluster</p>
<pre><code># at 10.13.31.21
sudo docker swarm join-token manager

# at 10.13.31.22, 10.13.31.23, 
sudo docker swarm join --token XXXXXXXXXXXXXXXXXXXXXXXXXX 10.13.31.21:2377
</code></pre>
<p>這樣，在swarm上的application，就會自動在10.13.31.21, 10.13.31.22, 10.13.31.23，上遊走。</p>
<p>即使你的app container目前是跑在10.13.31.23:8080上，但因為swarm mode routing mesh，你經過10.13.31.21:8080都可以連到該app。</p>
<p>如果你只是做stateless app load balance分流，這樣就足夠了，不用考慮ip fail over。但如果你要做到ip fail over，還要額外設定keepalive virtual ip，這個virtual ip會自動依付到某台活著的VM上，這樣外界才不會連到一個死ip上。又或者額外建一台load balancer，可以偵測到swarm node上那台機還活著，從而達到fail over效果。但這台load balancer也有一些穩定性要求，若然大家只是用一個普通的nginx做load balance，還是會有單點故障問題(single point of failure)。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="自己架設docker的共享儲存空間"><a class="header" href="#自己架設docker的共享儲存空間">自己架設Docker的共享儲存空間</a></h1>
<p>Docker很好用，在單機環境下真的很好用。Docker原本的設計，是為了快速迭代而設計成Image的。在一般設定下，每次新建或重建container，都會根據Image重設一下各方面的環境，包括儲存空間。重設CPU，Memory，大家都很易理解，但重設儲存空間，真的不是每一個使用情況都可以這樣。</p>
<p>又或者說，未必所有使用情況都會有一個第三方的儲存空間可以用。所以良心的Docker在單機環境下也有提供bind mount或是docker named volume，作為可以長期保存，不受container生死的影響，以達到長期存在Data的存在。</p>
<h2 id="單機-儲存空間"><a class="header" href="#單機-儲存空間">單機-儲存空間</a></h2>
<p>單機情況下很簡單，就用一個docker compose做例子</p>
<pre><code>services:
  nginx:
    image: nginx:1.23
    restart: always
    ports:
      - 80:80
      - 443:443
    volumes:
      - ./html/:/usr/share/nginx/html/
      - nginxlogs:/var/log/nginx/

volumes:
  nginxlogs:
</code></pre>
<p>其中html就是一個bind mount，而nginxlogs就是一個docker named volume，兩者都可以長期保存data，除非各位自己手動刪除，否則不會因為container的興亡而不見了。</p>
<p>但有兩個很重要的分別</p>
<ul>
<li>bind mount，直接跟host os連接，實際上是每次folder有更新，docker都要同步host和container之間的資料。
<ul>
<li>bind mount在linux下很暢順，因為大部份docker image/container原本就是linux engine，所以folder mount真的可以互通。</li>
<li>bind mount在windows / mac下，就會不斷抄資料。面對大量檔案，例如node_module，就會有速度上的問題</li>
</ul>
</li>
<li>docker named volume，就是docker 分離一些獨立空間，然後再綁到container上
<ul>
<li>相對bind mount，即使在windows / mac下，都沒有那個速度上的問題。筆者猜測，即使是獨立空間，其實本身都已經限定在linux enginx下，所以沒有需要抄資料。</li>
<li>但在windows / mac下，因應docker 底層建立Linux VM的技術不同，你可能沒法在windows / mac預設環境下直接讀取docker named volume。</li>
<li>若要讀取docker named volume，最好的做法，還是連上docker container，然後用docker cp 來抄回資料。一但抄資料，其實都會有速度上問題，不過docker cp是手動決定何時做的，不做docker cp，其實container也是可以用。</li>
</ul>
</li>
</ul>
<h2 id="cluster-docker-swarm---儲存空間"><a class="header" href="#cluster-docker-swarm---儲存空間">Cluster (Docker Swarm) - 儲存空間</a></h2>
<p>雖然良心的bind mount和named volume解決了單機上的儲存問題，但到了cluster環境，就沒有可以跨機同步儲存空間的做法，要做就自己建立。</p>
<p>筆者也稍為研究了一下同步的問題，不過對技術真的很有要求。所以退而求其次，筆者還是選擇簡單的第三方儲存空間。就是做一個可以分享存取的NAS。</p>
<h3 id="建立nfs"><a class="header" href="#建立nfs">建立nfs</a></h3>
<p>linux下要安裝nfs其實很簡單，不過要注意資料夾和防火牆權限。</p>
<p>以下安裝教學以ubunut 22.04為例，記得把下面的YOUR_DOCKER_NODE_ADDRESS_RANGE轉為你的真實IP段落</p>
<pre><code>apt update &amp;&amp; apt install nfs-kernel-server ufw -y

mkdir -p /mnt/nfs_share
chown -R nobody:nogroup /mnt/nfs_share/
chmod 777 /mnt/nfs_share/

echo "/mnt/nfs_share YOUR_DOCKER_NODE_ADDRESS_RANGE/24(rw,sync,no_subtree_check)" &gt;&gt; /etc/exports

exportfs -a

systemctl restart nfs-kernel-server

ufw allow from YOUR_DOCKER_NODE_ADDRESS_RANGE/24 to any port nfs
ufw allow ssh
ufw enable
</code></pre>
<h3 id="修改docker-compose"><a class="header" href="#修改docker-compose">修改docker compose</a></h3>
<p>最後，你在原來的docker-compose的docker volume上加driver_opts就大功告成。</p>
<p>記得把下面的YOUR_NFS_IP轉為你的真實IP</p>
<pre><code>volumes:
  nginxlogs:
    driver_opts:
      type: "nfs"
      o: "nfsvers=4,addr=YOUR_NFS_IP,nolock,soft,rw"
      device: ":/mnt/nfs_share/nginxlogs"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="docker-syslog"><a class="header" href="#docker-syslog">docker syslog</a></h1>
<p>平常大家在做單機app時，寫log有很多選擇，最簡單就是寫在檔案中。但在docker container裏面，寫檔案時要注意怎樣保留log檔，避免因為重建container時不見了。</p>
<p>docker 大部份官方預設image，都把log導向至stdout和stderr。這是方便docker做管理，也方便大家使用統一的docker logs指令來查看，即使到了Swarm mode底下，docker service logs也是同樣原理，使用差異不大，頂多就是不保證log的實時性。</p>
<p>如果網路延遲不計較的話，最大問題也是logs怎樣保存的做法。預設就是container刪走的時候，logs也會一借走。單機模式下，沿用最普遍的方法寫log的做法不是不可行，只是考慮到在極端情況下，同一個node(節點)中，有可能同時運作同一個service(服務)的多個分身(replica)，這裏它們寫檔案時就有機會互相搶佔。</p>
<p>筆者認為，比較合理的是外部提供的服務，例如syslog，把寫檔的操作交給節點的Host OS處理。然後就保證好每筆log都會是一條完整的記錄。</p>
<p>以下就以linux Host裏面的syslog，為大家簡介一下設定的步驟。</p>
<h2 id="設定docker-導向-syslog"><a class="header" href="#設定docker-導向-syslog">設定docker 導向 syslog</a></h2>
<p>把該主機的docker daemon (<code>/etc/docker/daemon.json</code>)，設定使用syslog driver，並以特定的方式編寫syslog tag。</p>
<pre><code class="language-json">//file: /etc/docker/daemon.json
{
  "log-driver": "syslog",
  "log-opts": {
    "tag": "dockercontainer/{{.ImageName}}/{{.Name}}/{{.ID}}"
  }
}
</code></pre>
<p>無腦設定已完成，重啟docker就可以了。</p>
<pre><code class="language-bash">sudo systemctl restart docker
</code></pre>
<p>但為了日後管理方便，能把docker log放進獨立的一個檔案中，會更易找問題。所以我們可以進一步設定syslog。我們以Ubuntu 22.04為例，可以在/etc/rsyslog.d/下增加一個設定檔(<code>/etc/rsyslog.d/*.conf</code>)，指定看到syslog tag以dockercontainer為首的記錄，都要獨立抽出來。</p>
<pre><code class="language-conf"># file: /etc/rsyslog.d/51-docker.conf
:syslogtag,startswith,"dockercontainer" -/var/log/dockercontainer.log
</code></pre>
<p>為免有檔案權限問題，手動指定檔案的所有權後，才正式重啟syslog。然後所有相關記錄都會寫在/var/log/dockercontainer.log</p>
<pre><code class="language-bash">sudo touch /var/log/dockercontainer.log
sudo chown syslog:adm /var/log/dockercontainer.log
sudo systemctl restart rsyslog
</code></pre>
<h2 id="滾滾滾滾滾動的log檔"><a class="header" href="#滾滾滾滾滾動的log檔">滾滾滾滾滾動的log檔</a></h2>
<p>檔案一天一天地長大，如果可以，還是自動清掉太舊的記錄為妙。Linux Syslog，通常也會配著logrotate使用。</p>
<p>筆者亦以Ubuntu 22.04為例子，做了個最簡單的自動滾Log功能。目標就是當log檔案大於1M後，就要重開log檔。舊的log檔最多保留7份，多了就刪掉最舊的。</p>
<pre><code class="language-conf"># file: /etc/logrotate.d/rsyslog-dockercontainer
/var/log/dockercontainer.log
{
        rotate 7
        size 1M
        missingok
        notifempty
        compress
        delaycompress
        sharedscripts
        postrotate
                /usr/lib/rsyslog/rsyslog-rotate
        endscript
}
</code></pre>
<p>加了設定後，什麼都不用重啟，因為它是Ubuntu 的排程動作，到執行時就會以最新的設定檔執行，詳見<code>/etc/cron.daily/logrotate</code>.</p>
<p>有需要手動測試的話，需要手動呼叫<code>/usr/sbin/logrotate</code>。加入-d參數後，會被視為debug mode，這是官方的說法，但因為debug mode沒有執行效果，更加像是linux中常見的dry run mode。</p>
<pre><code class="language-bash"># dry run only, no effect
sudo /usr/sbin/logrotate -d /etc/logrotate.conf
# do the real task and show verbose output
sudo /usr/sbin/logrotate -v /etc/logrotate.conf
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="git-co-work-flow"><a class="header" href="#git-co-work-flow">Git Co-Work Flow</a></h1>
<p>雖然git面世已很久，但相當一部份澳門朋友都是solo man，很少合作寫code，對git branch始終都有些恐懼。所以這次來解召一個基本原則，至少你不會爛了code救不回來。</p>
<p>若然大家未熟悉git，初次利用git合作寫program，請盡量減少使用共同分支(branch)，可以極大地減少問題。</p>
<h2 id="第一個大原則---建立一條自己分支"><a class="header" href="#第一個大原則---建立一條自己分支">第一個大原則 - 建立一條自己分支</a></h2>
<p>在一個repo中，為自己建立一條分支(branch)，可以減少Remote repo中有人比你先commit，而令你push失敗的情況。</p>
<pre><code class="language-bash">git clone xxx
git checkout -b YOUR_BRANCH

# 提交你的改動
git add FILE_OR_FOLDER
git commit
# 上傳
git push origin YOUR_BRANCH
</code></pre>
<p>除非你的隊友故意你用的分支名先commit，又或者你自己有幾台電腦，幾台一起做改動。不然push 應該不會有問題。</p>
<h2 id="第二個大原則---用fetch取代pull"><a class="header" href="#第二個大原則---用fetch取代pull">第二個大原則 - 用fetch取代pull</a></h2>
<p>很多人在取用Remote Repo的更新時，都會使用pull。但pull其實是fetch及merge的混合，而且merge還要考慮source branch是那條分支的問題，若然大家都有一條獨立branch，那麼這個無腦pull並不存於每人只有一台電腦下的多人協作中。</p>
<p>fetch的過程中，還可以加入參數–prune，順便依照Remote Repo的指示，同步刪掉本機中一些不再存在的origin/branch。</p>
<pre><code class="language-bash"># 不要用pull，用fetch看看server的最新改動
git fetch origin --prune
# 跟上述command類似，只是在fetch的途中，把main和 origin/main自動同步
git fetch origin main:main --prune
</code></pre>
<h2 id="第三個大原則---merge前先commit"><a class="header" href="#第三個大原則---merge前先commit">第三個大原則 - Merge前先Commit</a></h2>
<p>經過前述fetch後，其實他人的改動並未加入自己的分支中，必需經過merge才會出現。但並不是沒有conflict就無腦merge。 假若自己有改動，未commit，應該老虎蟹都先commit。這是為了在merge後，還有機會可以無腦reset，回到之前那個commit。這就像是做任何更新前，先做backup。</p>
<pre><code class="language-bash"># 看看有沒有未commit的改動，若有，先commit。
git status
git add FILE_OR_FOLDER
git commit

# 把別人的改動加到自己的分支中, 若有衝突請，git會提示你去修正
git merge origin/OTHER_BRANCH

# 檢查merge後的code有沒有問題，沒有就可以上傳
git push origin YOUR_BRANCH
</code></pre>
<h2 id="第四個大原則---由某個特定的人來管理master或main-branch"><a class="header" href="#第四個大原則---由某個特定的人來管理master或main-branch">第四個大原則 - 由某個特定的人來管理master或main branch</a></h2>
<p>main branch(以前叫master branch)，是他人下載時的預設分支，也是Github、Gitlab的預設顯示分支。所以該分支存放著的source code，應該在代表信心度比較高。</p>
<p>在協作的環境中，每人都有自己分支，那就代表要有一位人員做管理，他負責checkout main, 然後合併其他已驗證的分支。</p>
<pre><code class="language-bash"># 用fetch看看server的最新改動
git fetch origin --prune

# 看看自己分支有沒有未commit的改動，若有，先commit。你不應在main中改動，否則後述部份會有機會亂了。
git status
git add FILE_OR_FOLDER
git commit

# Optional，切換到他人的分支，執行程式以驗證更新
git checkout origin/SOMEONE_BRANCH
# 檢視差異，若發現有任何問題，例如他的分支落後於main，或很大機會出現衝突，可以叫對方先更新到最新狀況，再重來一次
git diff main origin/SOMEONE_BRANCH

# 有信心，就可以合併到main中
git checkout main &amp;&amp; git merge origin/SOMEONE_BRANCH
git push origin main

# 回到你原來的分支中
git checkout YOUR_BRANCH
</code></pre>
<p>在某些比較嚴僅的環境中(例如Github、Gitlab)，main分支可能會被系統機制鎖定，必需通過系統內建的Pull Request(或Merge Request)，才能通過審核，合併到main。另外，也有一些關於開發上的<a href="https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow">Git workflow</a>，主要針對功能管理、版本發佈、錯誤修正等控制。有機會再為大家介紹。</p>
<p>希望以上的流程，可以有效且容易地讓大家協作。如果有任何command錯誤或更新，都可以經Github Pull Request通知筆者。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="github-flow---github-開發流程"><a class="header" href="#github-flow---github-開發流程">github flow - github 開發流程</a></h1>
<h2 id="那些年那個很穩定卻又不受歡迎的-git-flow-開發流程"><a class="header" href="#那些年那個很穩定卻又不受歡迎的-git-flow-開發流程">那些年那個很穩定卻又不受歡迎的 git flow 開發流程</a></h2>
<p>多年前，朋友就向筆者介紹git的團隊整操作流程。筆者深思過後，的確實用，那些年的git-flow，很美滿，由開發、測試，到發佈、修補漏動（backport），都有清楚明確的指引。</p>
<p>原作者連結：<a href="https://nvie.com/posts/a-successful-git-branching-model/">git-flow</a></p>
<p>大家如果沒有更複雜的需求，真的可以照搬，筆者也很推這一個模型。</p>
<p>但在長期推廣下，筆者發現大部份人其實都不熟git的基本操作，什至連git graph也不看，現在看git flow，就更不可能接受。那怕是有常用git的個人團隊，也是不怎使用分支模型。</p>
<p>前一兩年，筆者也不懂，筆者也努力地簡化git flow。例如把master和develop合而為一，但最後也是少有人可以接受，很多人還是卡在分支那邊，對checkout、merge還是很陌生。在跟更多不同人的協作過後，筆者總於意會到一件事。其實大部份人，只想知道最後、最新的狀態，只會更新 master / main ，也因為個人開發，所以連衝突也不會有，更不需要使用merge。那怕是少型團隊，頂多也是維護main的衝突，間中用用merge，而checkout還是用不著。</p>
<p>其實這個情況，並不限於小型團隊。因為 web app 和 DevOps 的流行，所以越來越少機會要維護多個舊的穩定版本。大家都專心於最後一個開發及發佈版本就完事，用戶的某個版本有問題？更新到最新版本吧。（註：越底層的應用開發模式，因為相容性問題，不可能只保留一個穩定版本。）</p>
<h2 id="那麼我們就大力簡化吧---github-flow-開發流程"><a class="header" href="#那麼我們就大力簡化吧---github-flow-開發流程">那麼我們就大力簡化吧 - github flow 開發流程</a></h2>
<p>既然大部份情況，大家都只在乎 main / master / 預設分支，那我們也沒有必要跟著複雜的 git flow 走。但在 DevOps 的角度下，為保證 main / master 穩定性，大家還是至少要遵守branching 、pull (merge) request 、code review 、auto test 原則 。</p>
<p>github就最簡單的branching 、 pull request 、 code review 提出了它們的 <a href="https://docs.github.com/en/get-started/using-github/github-flow">github flow doc</a>, <a href="https://githubflow.github.io/">github flow</a>。</p>
<p>簡而言之，就是每個人在開發時，都先從 main 起一個新分支，不斷更新。待合適的時候，就透過 pull requst，向原項目負責人提出申請，只要項目負責人點頭，就可以把改動傳入 main 中。又因為Github 原本的定位在於個人與個人之間的協作，初時已經需要通過fork建立獨立的倉庫，那怕你不愛分支也必需分支。所以 pull request，code review 的作用更明顯，後逐的協作更理所當然。</p>
<p>但若果回到公司團隊協，Github flow 就應該像筆者之前提出協作方案，各自起分支，最後由某個人守門，把所有結果放到 main 中。（<a href="#git-co-work-flow">前文連結</a>）</p>
<h2 id="github-flow-沒有提及的發佈---佈署--release---deployment"><a class="header" href="#github-flow-沒有提及的發佈---佈署--release---deployment">Github flow 沒有提及的發佈 - 佈署 | Release - Deployment</a></h2>
<p>在上文中，經過 pull request 、 code review 、 auto test ，道理上，開發者可以做的都已經做過了，然後就是等待發佈 - Release。</p>
<p>對於單純的庫類型的程式碼，筆者認為，的確沒有事可以再做，實務上就是直接找人其他程多員試用最新版本，看看有沒有問題。只要 main / master 上，明確的表示版本號的變更，就差不多等於直接發佈。有需要提供binary版本的，就還需要觸發上載binary的流程，但這個跟 pull request 觸發 auto test 差不多， auto test 成功後就上載。</p>
<p>對於服務類型的程式碼，例如 Web App 等，直接發佈到正式環境還是有些不妥吧？始終會即時影響到業務，我們至少有個測試場，經用戶做實際的業務操作去驗收。但這個時機，應該是在Github flow的什麼時候做？</p>
<p>在原始的git flow中，有一個叫做 develop 的相對穩定分支，僅次於 main 。它是功能開發完成後第一次pull request 的地方，我們可以用這個概念來做自動發佈到測試場。但若在github flow 中加入了這個 develop / uat / staging 分支，其實就等於複雜地回到過去傳統的 git flow中，對好多新手來講難以接受。Github flow 的成功簡化，其實很大依賴著自動化測試。現在的測試用例，並不再限於單元測試。就連整合測試，也可以經Docker等容器化技術去做，只要我們的自動化測試有足夠信心，就可以發佈。但反觀我們的 Web App 例子，我們認為自動化測試難似涵蓋所有情境，也難以開發。所以我們還在有個時間發佈到測試場，進行人工測試。</p>
<h3 id="pull-request--快速迭代"><a class="header" href="#pull-request--快速迭代">pull request + 快速迭代</a></h3>
<p>筆者結合自己的經驗，配上國外討論區 Stack overflow 的內容，筆者認為Github flow上進行 pull request 後，就是最好的發佈測試場時機。所以我們需要盡快進行驗收測試，完成後在Git commit上加上Tag，以示通過驗收測試，可以發佈正式環境的版本。</p>
<p>不過這個模式是有一個很重要的前題假設：快速迭代。當我們驗收完成後，盡可能快地發佈到正式環境，不然會阻礙下一個功能的pull request驗收，或是覆蓋了上一個pull request的驗收環境。</p>
<p>用反面的例子來說明，如果我們有很多功能需要驗收，或變化很多，或存在多輪的里程碑開發，我們就不適宜那上述模式。最保險的做法，還是回到傳統的 git flow ，引入 develop / uat / staging 分支。但如果大家還是那麼討厭傳統 git flow，筆者還是有另一個提議。</p>
<h3 id="既不想回到傳統-git-flow-但又需要慬㥀的考慮驗收發佈流程"><a class="header" href="#既不想回到傳統-git-flow-但又需要慬㥀的考慮驗收發佈流程">既不想回到傳統 git flow ，但又需要慬㥀的考慮驗收發佈流程</a></h3>
<p>如果開發的功能變化比較大，需要多方面協調、測試、驗收，經歷多次里程碑後，才有一個對外發佈的版本，大家可以考慮分開 Repository 做開發。例如: v1，v2的 Repository 完全獨立。 v1 是已發佈的版本，有獨立的測試場，任何即時候需要修正，就在v1的 Repository 做 pull request。 v2 則是未發佈版本，亦有獨立的測試場。加入任何新功能後，就在v2的 Repository 做 pull request，用自己專用的測試場做驗收。到 v2 正式發佈後， v1 就封存處理，再開一個 v3 作為下一個大版本的開發。這個模式，那怕在庫類型的程式碼也用得上。</p>
<p>這樣做的好處是 git Repository 和歷史記錄都會獨立，自動發佈的腳本程也會簡單明確一些。壞處則是 v1 v2 難以做功能對比，我們只能靠人腦記著 v1 有沒有什麼後期加入的修正和功能，需要同步移植到 v2 中 (相對的，著是同一個Repository，可以利用merge 功能確保 v1 有的，v2 都己處理，只是必需要很懂處理版本衝突問題。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="git-submodule"><a class="header" href="#git-submodule">git submodule</a></h1>
<p>初次實務上使用submodule來同時管理幾個project的更新。如果有任何理解上的錯誤，請在github中提issue或pull request。</p>
<h1 id="why-submodule"><a class="header" href="#why-submodule">why submodule</a></h1>
<p>假設你的團隊中有三個人，A君做A Project，B君做B Project，C君做Main Project。如果可以，A，B各提供已編譯的Binary或Library，給C君直接使用就最好。</p>
<p>但要做到好好管理，A，B都要有自己的發佈系統，即是把Binary上傳到某個分享Repo中，這樣C君就能有條理地通過IDE或Compile工具下載對應的版本。如果是javascript，Repo可能就是npm repo，如果是java，可能就是maven repo。這亦代表A，B君對程式編譯、打包、版本命名等都要很熟悉，不能一輩子都命名為v1.0.0。</p>
<p>如果團隊對這些都不熟悉，C君還有什麼方法呢?其實靠著Submodule的功能，C君也可以硬把A，B的Source code取出，做最後打包。</p>
<p>這跟A、B君自己把source code壓縮然後Email寄給C君是有不同的。因為這樣C君並不清楚A，B的git脈絡：C君需要自己做好A、B的版本記錄。想要只回滾A，B的版本普不容易。但經過git Submodule後，C君可以清楚知道現在正使用的是A、B的那一個commit版本。假如有一天，A、B、C三個都更新了，但發現合起來時就跑不動。C君可以保持A、C的版本不變，單獨提取B的某個版本進行測試。當然，你可以說原本Email也可以這樣管理，但始終你不清楚B的版本記錄，Email的日期並不代表Source Code的進度。(因為有時候,Bug Fix是針對舊版本的做更新，新功能的Email日期反而比Bug Fix要早)</p>
<p>同理，如果大家要連結多個沒有發佈系統的文字資料，也可以利用Submodule。例如筆者正在編輯一<a href="https://macauyeah.github.io/AProgrammerPrepares/">本書</a>，當中不同的主題，就是使用Submodule的功能串連起。</p>
<h1 id="command"><a class="header" href="#command">Command</a></h1>
<p>馬上看來來Submodule可以怎樣做。 假設你已經知道git 怎樣用，也起了git repo。假設你是C君，進入你的本機repo資料夾內，使用submodule參數。</p>
<pre><code class="language-bash">cd SOMEWHREE_IN_MAIN_FOLDER
git submodule add SUBMODLE_REPO_LINK
cd MAIN_FOLDER
git add -u &amp;&amp; git commit -m 'Add sub module'
</code></pre>
<p>上面的效果，就是把C君當前repo的狀態，連結到B君submodule當時預設分枝(default branch)的最後一個commit 中。然後C君在自己的repo怎樣更新，它引用到B君的submodule版本都不會變。</p>
<p>直到某一刻，B君說他加了一個穩定的新功能，請C也連帶更新一下。C君也做好自己的準備後，使用submodule參數進行更新。</p>
<pre><code class="language-bash">cd MAIN_FOLDER
git submodule update --remote
# run any unit test, integration test, confirm that it works after submodule update, then commit
git add -u &amp;&amp; git commit -m 'update sub module and auto checkout'
</code></pre>
<p>注意，如果C君有多於一個submodule，上述指令會全部一口氣更新。另外，如果你覺得B君的最新版本不能用，還是可以針對B君取得特定的版本。</p>
<pre><code class="language-bash">cd SUBMODULE_FOLDER
git checkout SUBMODULE_COMMIT
cd MAIN_FOLDER
git add -u &amp;&amp; git commit -m 'update sub module to specific commit'
</code></pre>
<p>如果，你是D君，直接下載A君的多module project，那在初次下載時，submodule還是空的，需要先init，再update。</p>
<pre><code class="language-bash">git clone ...
ls SUBMODULE_FOLDER
# SUBMODULE_FOLDER will be empty
cd MAIN_FOLDER
git submodule init
git submodule update
ls SUBMODULE_FOLDER
# submodule code should be there
</code></pre>
<p>如果你同時是A,B,C君，其實多個module也是你自己管理的，你可以直接進入各個submodule commit。但要記得，main module也要commit才會連上最新的submodule。</p>
<pre><code class="language-bash">cd SUBMODULE_FOLDER
# make some change
git add -u &amp;&amp; git commit -m 'update in submodule only'
# remeber to push submodule to origin
cd MAIN_FOLDER
git add -u &amp;&amp; git commit -m 'update main module to ref new submodule commit'
# remeber to push main module to origin
</code></pre>
<p>不過筆者還是建議大家分開使用。不要全部混在一起，因為太多同步問題會漏。</p>
<h2 id="draft-2"><a class="header" href="#draft-2">draft</a></h2>
<p>.gitmodules
[submodule “some-sub-module”]
path = some-sub-module
url = ../some-sub-module.git
branch = minimize</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="git-分支整合的時機"><a class="header" href="#git-分支整合的時機">git 分支整合的時機</a></h1>
<p>不知道大家的開發團隊、專案規模有多大，但只要系統或程式已發佈，同時又要做維護更新，專安的git庫都至少會有兩條分枝：</p>
<ol>
<li>新功能 - main / feature</li>
<li>最新的穩定發佈版本 - Release / v1.x.x</li>
</ol>
<p>最好的情況下，在開發完新功能之前，穩定版本都沒有需要緊急修正的地方，開發者可以專心開發新功能（main / feature）。然而這個情況並不能經常維持。</p>
<h2 id="情況1有bug要馬上修正"><a class="header" href="#情況1有bug要馬上修正">情況1:有Bug要馬上修正</a></h2>
<p>最常見到的情況，就是穩定發佈版本有瑕疵，可以經過小修小改來止血，由v1.x.x ⇒ v1.x.y，這些可能對用戶來說，是沒有太大感覺的改動。不過對於開發流程，就免不了由v1.x.y整合（merge）回main時，出現修改衝突的問題。</p>
<h3 id="建議"><a class="header" href="#建議">建議</a></h3>
<p>若屬於日後不再需要的改動，不需於整合到main中， 當然什麼都不用做。但若屬於必要的更新，就需要早早整合到main中。整合雖然痛苦，但延後整合沒有好處。以筆者的經驗，每次整合時有衝突，而越早整合越有條件知道該取用自動混合的那個版本。以整合工具的語言來說，就是更容易的作出use mine / use theirs / edit。</p>
<h2 id="情況2-不同功能之間有衝突"><a class="header" href="#情況2-不同功能之間有衝突">情況2: 不同功能之間有衝突</a></h2>
<p>上述情況1，已經算是可控的。主要因為穩定發佈版本都只會接受小修小改，大改都會直接在main中開當為新功能開發。當你有多個很重要的功能在不同時期被提出，而有些功能你沒有信心在下個發佈中提出，你就會選擇以獨立分支來實現不同的功能，最後選擇信心度高、權重也比較高的功能來發佈。這樣的好處是你可以有限時間先完成最必要的功能，但問題是多個功能分支之間，更容易地有衝突，後期也需要很廢心力地整合。</p>
<h3 id="建議-1"><a class="header" href="#建議-1">建議</a></h3>
<p>少做資料夾層面的改動，因為git rename的功能並不是萬能的，會令很多git自動選擇版變得不可讀。筆者的經驗，就是錯把後端和前端的資料夾混在一起，令後端的一些重命名影響到前端。前端也因為有重寫的需要，對資料夾結構大改。最後結果就是很多看不懂的git自動選擇版。有一些有選對，但有一些就選錯。</p>
<p>可以做一些事前處理，來減經痛苦。在筆者的資料夾問題情境，在把後端將要整合的多個commit中，挑選最早前沒有命名問題的commit先整合一次。然後前端先手動模擬後端的人工命名，自行commit一次，最後再把後端剩餘的commit再做整合。這個做法不是完全解決問題，但至少可以讓use mine / use theirs / edit更新易理解。</p>
<p>而另一個建議是，縮短發佈週期，逼使其他開發中的功能越早做整合，也逼使每個功能不要做太大規模的改動。如果真的做大規模改動，就要有心理準備要多次重要的整合。</p>
<h2 id="情況3-多個穩定發佈版本需要同時維護"><a class="header" href="#情況3-多個穩定發佈版本需要同時維護">情況3: 多個穩定發佈版本需要同時維護</a></h2>
<p>若然大家面對的工作規模真的很大，同時有多個版運行版本，就如gitlab，每一個月都有一個新功能版本(16.0.x, 16.1.x, 16.2.x,… 16.9.x)，但它不會強逼大家更新，對於過去一段時間的功能版本，也會推出安全性更新(前述的x會不斷修正問題)。</p>
<p>這是一個很負責任的發佈模式，不過對於開發者來講就一定很地獄。因為16.0.x的安全更新並不能無痛地整合到16.9.x中，可能每個版本重新人工修改還要來得穩健。</p>
<h3 id="建議-2"><a class="header" href="#建議-2">建議</a></h3>
<p>各個分支人工修改可能更適合。最後就是取決於商業政策的考量，到底公司願意為已發佈的功能版本提供多久的支援。就以gitlab為例，其實它也只承諾維持兩三個月前的功能版本。是否會backport到多個月之前的版本，就看問題的嚴重性和backport難易度。</p>
<p>也分享一些筆者朋友的經驗，他們開發的是軟件跟硬件整理的軟件庫。但因為硬件有限制，例如庫的大小、算力的差異，所以最後分支多到爆炸。這也是軟硬整合的痛，問題暫時無解。除非老闆肯放棄市場。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="git---持續整合策略--git---continuous-integration-strategy"><a class="header" href="#git---持續整合策略--git---continuous-integration-strategy">Git - 持續整合策略 | Git - Continuous integration strategy</a></h1>
<p>對於原始碼的管理，平常筆者也有在用gitlab的Continuous integration，針對每次提交(commit)，都會有自動編譯和測試。但當一個專案中，有很多關聯庫(dependency library)的引用時，光是專案中每個commit 行auto build就不夠用了。更嚴重的是，若然大家有很多微服務micro service，它們的更新不會反映在commit中。</p>
<p>所以定期重跑動動編譯和測試，是筆者認為可以緩解關聯更新的問題，至少可以提高知道問題所在。</p>
<h2 id="night-build的原意"><a class="header" href="#night-build的原意">Night Build的原意</a></h2>
<p>筆者先做了一些功課，參考別人怎樣思考Night build （定期重新編譯）這件事。</p>
<ol>
<li>每次整合新功能到穩定分支（stable branch）之前，都需要做自動測試。</li>
<li>當專案複雜性越來越大，每次自動測試都把全部測試跑一次，就會遇到效能瓶頸。</li>
<li>所以考慮commit時做單元測試（unit test），然後每個固定的時間問隔做整合測試（integration test）。那個固定的時間間隔就是Night build。</li>
</ol>
<h2 id="night-build之於integration-test"><a class="header" href="#night-build之於integration-test">Night Build之於integration test</a></h2>
<p>筆者原始的問題並不是來自於效能瓶頸，而是涉及關聯性更新問題。這些要麼就有是經code base 層面引發關聯性自動試測，要麼就是Night build重複測試。</p>
<p>這兩個功能，gitlab都有提供，只是筆者初步構想下，Night build比較易設定，也乎合原始的定位。</p>
<p>因為要考慮micro service的於沙盒環境的部署，最簡易的Night build只需要一個共用的環境就夠。但也同樣意味著，Night build需要進行多個不同的分支測試，就需要多個不同的環境。</p>
<p>另外Night build的測時時機也是一個問題，因為測試當下，並不能百份百對應關聯micro services的提交狀況，大家就更需要做好發佈的版本號語意管理。</p>
<h2 id="night-build-實務操作上的注意點"><a class="header" href="#night-build-實務操作上的注意點">Night Build 實務操作上的注意點</a></h2>
<p>Night build第一個要注意的問題，就是要確保同一個commit，真的可以重複建設。一般來說，大家的目標只在運行測試，而自動測試不具破壞性，就基本可以重複的。而如果測試當中包含發佈測試版本，那就還要考慮重複發佈有沒有生效或造成附作用。</p>
<p>以Java maven為例，重複發佈測試版本需要遵守特定的規則，版本號需要以SNAPSHOT結尾，這是為讓maven每天都會重新下載它們的包。而沒有SNAPSHOT結尾的，就只會做一次性下載，減少重複下載造成的資源浪費。若真遇著不支援重複發佈的情況，就需要以日期時間做版本號，就像vscode的某些插件，就是以時間截結尾以作為區分。</p>
<p>Night build另一個要注意的問題，就是開發圖隊何時進行下一輪開發，這會決定何時有新的版本號。扣除上述因為工具不支援的而引發的副作用，還要考慮沒有更新而發生的問題。</p>
<p>有個尷尬情況是，團隊在發佈現行版本時，release commit與main有機會是同一個commit(也就是未有進行下一輪開發)。若不斷重複發佈，有沒有變相發佈了一些沒有預期的功能？例如Docker image，官方大力建議每日自動發佈。當底層的image更新後，頂層引用它們的image，也可以重新發佈，保持安全性。但這樣做的問題，就是頂層的同一個版本號，昨日與今日的運行結果也可能不一樣。這對追蹤問題，並不友好。</p>
<p>所以大家做分支整合時，要預先對版本號作好規劃。然後還要留意Night build不應與release commit重疊。版本號大家做好語意管理，再加上alpha / beta / SNAPSHOT等區分Night build版本，應該就足夠了。而commit重疊問題，就要留意開發週期，Night build要麼就比release早一個commit(即在release時，不推進Night build)，要麼晚一個commit(即馬上規劃下一個版本號進行Night build)。</p>
<div style="break-before: page; page-break-before: always;"></div>
<p>之前看了一位git大神的演講，提及一個叫MONO Repository的使用情況。後期找資料之後，才發現到這是一個公司成長後的一個重大的挑戰。</p>
<h1 id="何謂mono-repository"><a class="header" href="#何謂mono-repository">何謂MONO Repository</a></h1>
<p>git的傳統，就是為每一個獨立的專案，建立一個新的Repository (中譯：倉庫)。這個很直觀，獨立專案，獨立管理。從零開始有很多好處，Repo體積通常會小一點，因為其內的東西都是緊密相關。做更新處理時，維護人員也更清楚自己的影響程度。這種架構方式，就叫Multi Repository。基本上，大家預設也是會走這個模式。</p>
<p>但當公司規模一直變大，多個專案可能不再獨立，各個專案或多或少都有一些關聯性。當任一專案更新，都有機會影響到其他人。如果公司使用Micro Service （微服務），就更有機會提早遇到。每次更新時，要跨專案地找出影響範圍原本就已經不容易，現在每個專案獨立地存放在不同的倉庫中，每個倉庫的更新速度不一樣，想要找到合適的地方、合適的時間點推出更新，更是困難。</p>
<p>所以，就有公司就提出，將所有專案都放在同一個Mono Repository中，方便用工具去檢查更新影響。相比Multi Repository，這樣做還可以保證同一個改動可以發生中同一個Commit中，可以讓跨專案的團隊可以即時合作（強逼修改別人的專案）。但這樣使一定會有很技術問題出現。跨專案團隊不可能每個專案都熟悉，因為不熟悉而引起的副作用一定會有，所以Main / Master分支出現有缺陷的機會提高了。亦有人提出，使用Mono架構，還必要使用trunk base分支模式。也就是那些新功能，雖然要創建分支開發，但亦要盡早整合到Main / Master中。這才能讓不同的團隊盡早知道問題，並解決問題。</p>
<p>除了開發模式更具挑戰外，Mono架構對git的效能也有很大影響。因為多專案混合，Repository的大小基本都會很大。每個git指令都會變慢，所以必需做一些週期性的cache，讓git graph, git status這樣日常操作變得暢順。同樣地，持續整合/發佈需要作出調整。不過這些筆者就不在這邊詳述了，有興趣朋友可以到git 大神的Youtube觀看。</p>
<p><a href="https://youtu.be/aolI_Rz0ZqY?si=z8Ry--EhCQlHuP7a">So You Think You Know Git - FOSDEM 2024
</a></p>
<p>註：據筆者的資料搜集，很多大公司（Software龍頭）都有使用Mono Repository去做集中管理。只不過筆者不知道如何Fact check，就不在這裏提了。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="git-worktree"><a class="header" href="#git-worktree">Git Worktree</a></h1>
<p>看了Git 大神的影片 part two，才知道原來切換git分支還是有不同的做法。傳統中，我們使用<code>git checkout BRANCH_NAME_1</code> 來切換到我們想要的分支。通常這樣做，代表我們放棄原來的工作環境，換到另一個工作環境中。</p>
<p>這樣做很好，對不對？</p>
<p>是的。但有些時候，我們只是被逼離開原本的工作環境，跳到一個過去的分支/節點去查一些東西，或者修正一些東西。更什的是我們原本的工作環境都還是混亂狀態下，我們不想做commit（提交），我們只好用<code>git stash</code>，暫時將工作環境存起，然後再<code>git checkout BRANCH_NAME_1</code>。在你想做的事做完後，再<code>git checkout OLD_BRANCH</code>。</p>
<p>看起來其實也沒有很麻煩，是不是？</p>
<p>但其實當你的專案有一定大小，你在不同版本跳來跳去，你的IDE就會不斷地重新編譯。更不幸的是，當你的不同版本中有模組數量的差異，弱一點的IDE，什至會攪死它的cache，之後就會發生鬼打牆。為解決IDE引發的問題，筆者有時會直接<code>cp -r YOUR_PROJECT TEMP_PROJECT</code>，在一個新資料夾下另起爐灶。那就是有兩個不同的資料夾裝載著你的專案。</p>
<p>這樣應該沒有問題了吧，是不是？這次是真的可以了，扣除了筆者個人健忘的問題，就沒什麼問題了。</p>
<p>不知大家有沒有經驗，連續commit了幾次，但最後一次commit卻忘了push（與伺服器同步），然後就跳到其他地方繼續工作。如果我們在同一個git repository下，我們commit了但忘了push，即使我們<code>git checkout</code>去了其他分支，用git GUI畫出commit graph時，也至少可以提醒筆者有一個未與伺服器同步的分支。但如果當初我們用的是<code>cp</code>，那就沒戲唱了，什至乎當初複制了去哪裏都忘了。（當你老闆同時要你跟多個專案，健忘真的很容易發生。）</p>
<p>這問題有解嗎？有的，git在2.5版本以後，就提供了一個<code>git worktree</code>的指令。它有點像cp 指令，更重要的是，它打通了兩個資料夾下的隱藏資料庫<code>.git</code>，當大家在那兩個資料夾底下，都可以看到另一方的存在。大家可以用<code>git branch -a</code>或<code>git log --oneline --graph</code>來看看。</p>
<p>詳細的指令介紹：<a href="https://git-scm.com/docs/git-worktree">git worktree</a></p>
<p>git 大神的影片 <a href="https://youtu.be/Md44rcw13k4?si=9WVrEg37qOuXpauw">Part 2</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="git-修改歷史記錄"><a href="#git-修改歷史記錄" class="header">Git 修改歷史記錄</a></h1>
<p>有時候，我們修正一系統檔案，例如某個commit中，多了一個不該放的檔案，又或者想修改該commit的作者，我們就要追搜到某個commit，然後用rebase隨個改。</p>
<p>例如本次repo，有一個githubAction.md，因為錯誤原因，被加到了main中，也藏了很久。如果我們想連根拔起，我們需要加出它第一次出現的commit。</p>
<pre><code>$ git log githubAction.md
commit 60ccd70f6b768138cbe23c93ffcfa32574ce895c
</code></pre>
<p>那我們就以它前一個commit作為rebase的根據，進行逐個commit修正。</p>
<pre><code>$ git rebase -i 60ccd70f6b768138cbe23c93ffcfa32574ce895c^
pick 60ccd70 draft some content
pick e2ee9a3 add some senario.
pick b91afc1 refine submodule;
pick 98cd366 add notes about submodule specific checkout;
pick 064b06f test directly commit in submodule main
pick 7b648d2 update git submodules notes
pick 556f25e add notes about merge timing
pick 5244804 Create git-continuous-integration-strategy.md
pick 107e486 add more pratical nodes about ci;
pick d93cbee add mono repo challenge
pick 1c471b6 add worktree notes
pick 9063ccb notes about different of git flow and github flow;
pick b72e89e Update github-flow.md, add ref more link
pick 0b8f2a9 draft github flow release problem
pick 8b333fc finalize github flow release strategy
</code></pre>
<p>在rabase選項中，把需要改的commit由pick改為edit。(rebase會以舊到新顯示)。然後儲存。例如</p>
<pre><code>edit 60ccd70 draft some content
edit e2ee9a3 add some senario.
edit b91afc1 refine submodule;
pick 98cd366 add notes about submodule specific checkout;
pick 064b06f test directly commit in submodule main
pick 7b648d2 update git submodules notes
pick 556f25e add notes about merge timing
pick 5244804 Create git-continuous-integration-strategy.md
pick 107e486 add more pratical nodes about ci;
pick d93cbee add mono repo challenge
pick 1c471b6 add worktree notes
pick 9063ccb notes about different of git flow and github flow;
pick b72e89e Update github-flow.md, add ref more link
pick 0b8f2a9 draft github flow release problem
pick 8b333fc finalize github flow release strategy
</code></pre>
<p>我們第一次會在60ccd70，我們作出想要的改動，然後經amend去改掉60ccd70</p>
<pre><code>$ rm githubAction.md
$ git add -u
$ git commit --amend --author="newuser &lt;newemail&gt;"
</code></pre>
<p>確定無誤的話，就可以去下一步，即是到了e2ee9a3</p>
<pre><code>$ git rebase --continue
</code></pre>
<p>因為已經rebase過，你此時看到的不會再是hash不再是e2ee9a3，而是自動rebase完的e2ee9a3。若大家有東西要改，就使用commit –amend。如果沒有東西要改，也沒有conflict，可以繼續rebase –continue下去。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot---maven-cheat-sheet"><a class="header" href="#spring-boot---maven-cheat-sheet">Spring Boot - Maven Cheat sheet</a></h1>
<h2 id="基礎"><a class="header" href="#基礎">基礎</a></h2>
<p>刪除所有結果，全部重新編譯</p>
<pre><code class="language-bash">mvn clean compile
</code></pre>
<p>跑起用Spring boot寫的main class，運行Spring boot context。</p>
<pre><code class="language-bash">mvn spring-boot:run
# or
mvn clean compile spring-boot:run
</code></pre>
<p>執行測試用例，預設只會測試test資料夾下以某些命名規則的class(例如class名以Tests或Test結尾的class，其他命名規則筆者未有能力一一驗證)</p>
<pre><code class="language-bash">mvn test
# or
mvn clean compile test
</code></pre>
<h2 id="多profile多組件多測試"><a class="header" href="#多profile多組件多測試">多Profile、多組件、多測試</a></h2>
<p>使用-P指定編譯時的選用pom.xml中的project.profiles.profile參數。也可以用此來傳遞到spring profile，使得編譯後的spring war預設選擇特定profile。</p>
<pre><code class="language-bash">mvn clean compile -PmvnProfile
# or
mvn clean compile spring-boot:run -PmvnProfile
</code></pre>
<p>使用-pl限定mvn指令只對某個子組件生效，但有時候子組件之間也有引用關係，所以需要再額外加上-am參數(–also-make)</p>
<pre><code class="language-bash">mvn clean compile spring-boot:run -pl SUBMODULE_NAME -am
</code></pre>
<p>使用-Dtest=限定只執行某個class的測試用例，或單個測試函數。(可以無視class名的命名規則)</p>
<pre><code class="language-bash">mvn test -Dtest=TEST_CLASS_NAME
# or
mvn test -Dtest=TEST_CLASS_NAME#TES_METHOD_NAME
</code></pre>
<p>若屬於多組件情況下，其他子模組找不到同樣名稱的測試，會測試失敗。需要再加上-Dsurefire.failIfNoSpecifiedTests=false</p>
<pre><code class="language-bash">mvn test -pl SUBMODULE_NAME -am -Dtest=TEST_CLASS_NAME -Dsurefire.failIfNoSpecifiedTests=false
# or
mvn test -pl SUBMODULE_NAME -am -Dtest=TEST_CLASS_NAME#TES_METHOD_NAME -Dsurefire.failIfNoSpecifiedTests=false
</code></pre>
<h2 id="打包"><a class="header" href="#打包">打包</a></h2>
<p>在本機電腦中，把java變成jar或者war。通常用於自行發佈的環境中。</p>
<pre><code class="language-bash">mvn package
</code></pre>
<h2 id="例外情況"><a class="header" href="#例外情況">例外情況</a></h2>
<p>強行把一個第三方jar，種到本機電腦中的.m2/repository</p>
<pre><code class="language-bash"># copy from https://maven.apache.org/guides/mini/guide-3rd-party-jars-local.html
mvn install:install-file -Dfile=&lt;path-to-file&gt; -DgroupId=&lt;group-id&gt; -DartifactId=&lt;artifact-id&gt; -Dversion=&lt;version&gt; -Dpackaging=&lt;packaging&gt;
</code></pre>
<p>有時特定Profile沒法成功執行測試用例，或者你認為有些測試問題不影響使用，需要跳過package中的test。</p>
<pre><code class="language-bash">mvn package -Dmaven.test.skip=true  # won't compile test folder
mvn package -DskipTests=true # compile, but won't run
</code></pre>
<p>若想預設特定submodule為不執行test。可以修改對應的pom.xml</p>
<pre><code class="language-xml">	&lt;profiles&gt;
		&lt;profile&gt;
			&lt;id&gt;dev&lt;/id&gt;
			&lt;properties&gt;
				&lt;maven.test.skip&gt;true&lt;/maven.test.skip&gt;
			&lt;/properties&gt;
			&lt;activation&gt;
				&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
			&lt;/activation&gt;
		&lt;/profile&gt;
	&lt;/profiles&gt;
</code></pre>
<p>此後有需要測試，則要手動執行</p>
<pre><code class="language-bash">mvn test -pl SUBMODULE_NAME -am -Dmaven.test.skip=false
</code></pre>
<p>若你不想整個submodule 跳過，想逐個class跳過。可以</p>
<pre><code class="language-xml">		&lt;plugins&gt;
			&lt;plugin&gt;
				&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
				&lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
				&lt;version&gt;3.2.5&lt;/version&gt;
				&lt;configuration&gt;
					&lt;excludes&gt;
						&lt;exclude&gt;**/SpecialTest.java&lt;/exclude&gt;
					&lt;/excludes&gt;
				&lt;/configuration&gt;
			&lt;/plugin&gt;
		&lt;/plugins&gt;
</code></pre>
<p>此後有需要測試，則要手動執行指定特定class。但你只能一個個class手動測試。</p>
<pre><code class="language-bash">mvn clean compile test -pl SUBMODULE_NAME -am -Dtest=SpecialTest -Dsurefire.failIfNoSpecifiedTests=false
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="web-socket-vs-http11-vs-http2"><a class="header" href="#web-socket-vs-http11-vs-http2">Web Socket vs http/1.1 vs http/2</a></h1>
<h2 id="http11"><a class="header" href="#http11">http/1.1</a></h2>
<p>現時最基本的http protocol。但它效能不算很好的原因，在於每次都要起連線，先Client Request，再Server Response。雖然它可以使用<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Keep-Alive">Keep-Alive</a> header，同一個TCP/IP連線中連續做多次request/response循環，但重點是它需要先後request/response，所以當中有一個response長度很大，就要慢慢等它完結。</p>
<h2 id="http2"><a class="header" href="#http2">http/2</a></h2>
<p>沿用http/1.1的大部份東西，包括status code等，但傳送的方法做了更改。</p>
<p>在傳統的Client Server行為中，假設第一個Client request是去問Server取得主網頁index.html。在Client得知完整的index.html response後，分析其中有一個main.css，才後知後覺的再問server去取main.css，這才有了第二個request。</p>
<p>http/2，就是一種Server有主導權的機制。Server明明知道index.html會連著main.css，所以在第一次回傳時，把main.css跟index.html一起回傳，即是回傳比Client原本查詢範圍更多的結果。即它可以主動推送資料，不用等Client去做二次操作。</p>
<h2 id="web-socket"><a class="header" href="#web-socket">Web Socket</a></h2>
<p>原本在http/1.1的時代，就有人提出了升級的玩法。Web socket就是把http 1.1的request/response循環，在第一次握手後，硬改為TCP/IP 的傳統Socket機制。Client/Server可以隨時Read/Write。但跟傳統TCP Socket的差別在於，Web Socket可以保證Read時可以讀取一個完整內容，而傳統TCP Socket每次Read都可能只有該內容的一部份，要多次Read及計算長度才能確保讀完完整的內容。</p>
<p>因為建立了Socket，長期維持連線，再加上多工機制，所以十分適合作為實時傳輸用。</p>
<h1 id="spring-boot-implementation"><a class="header" href="#spring-boot-implementation">Spring boot implementation</a></h1>
<p>筆者查看了一下Spring boot的教學，http/2只有一些基本文件支援描述，但沒有簡單無腦可以的教學。但對於Web Socket，倒是有的。</p>
<p>STOMP (Simple / Streaming Text Orientated Messaging Protocol)是Web Socket內的一個實現方式，Spring boot提供的就是STOMP底下的Web Socket。筆者實驗後，感覺就是傳統的http 1.1升級Web Socket的做法。</p>
<h1 id="基於http2-的web-socket升級版"><a class="header" href="#基於http2-的web-socket升級版">基於Http2 的Web Socket升級版</a></h1>
<p>筆者之前亦跟好友聊過一下Web Socket、Http 2的差異，經好友梳理，其實Web Socket也不一定是Http 1.1，現在Http 2也開始可以這樣玩了。</p>
<p>好友轉發的<a href="https://medium.com/@pgjones/http-2-websockets-81ae3aab36dd">Medium</a>的文章描述下，IETF在2018年後也制定了新的玩法<a href="https://www.rfc-editor.org/rfc/rfc8441">RFC8441</a>，Web Socket可以經 http 2轉化出來。</p>
<p>無奈筆者還受困於Spring http/1.1的限制內，未能為大家介紹更多。</p>
<h1 id="reference-2"><a class="header" href="#reference-2">Reference</a></h1>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism">Mozilla Web socket</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Keep-Alive">Mozilla Keep-Alive</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Glossary/HTTP_2">Mozilla HTTP/2</a></li>
<li><a href="https://medium.com/@pgjones/http-2-websockets-81ae3aab36dd">Medium - pgjones - HTTP/2 WebSockets</a></li>
<li><a href="https://en.wikipedia.org/wiki/HTTP/2">Wikipedia - HTTP/2</a></li>
<li><a href="https://www.cloudflare.com/zh-tw/learning/performance/http2-vs-http1.1/">Cloudflare - HTTP/2 與 HTTP/1.1 的比較：其如何影響 Web 效能？</a></li>
<li><a href="https://stackoverflow.com/questions/52441828/http-1-1-websocket-and-http-2-0-analysis-in-terms-of-socket">stack overflow - HTTP/1.1, webSocket and HTTP/2.0 analysis in terms of Socket</a></li>
<li><a href="https://spring.io/guides/gs/messaging-stomp-websocket/">Spring - Using WebSocket to build an interactive web application</a></li>
<li><a href="https://www.rfc-editor.org/rfc/rfc8441">IETF - RFC8441</a></li>
<li><a href="https://github.com/macauyeah/spring-boot-stomp">Source Code - spring-boot-stomp</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-data-jpa-自動化的選擇---code-first"><a class="header" href="#spring-data-jpa-自動化的選擇---code-first">Spring Data Jpa 自動化的選擇 - Code First</a></h1>
<h2 id="code-first-vs-database-first"><a class="header" href="#code-first-vs-database-first">Code First vs Database First</a></h2>
<p>在早期SQL資料庫盛行的年代，在設計要使用資料庫儲存資料時，很經常遇到一個策略選擇的問題<em>Code First</em> vs <em>Database First</em></p>
<p>這兩個策略的差異可能越來越講不清，筆者也找了一些現時網路上的講法。</p>
<p>Code First: 先從寫程式的角度出發，設計數據模型，再使用工具把你程式碼中的數據模型類(Class)，生成一個對應用SQL資料庫的表(Table)，自動編做好對應的數據結構(Schema)。這樣你在設計時，以程式設計為主導，方便熟悉程式的人使用。這常見於第一手開發設計，因為資料都是第一次收集和儲存，考慮收集程式的運作最為實際。</p>
<p>Database First: 先從SQL資料庫的儲存、取用資料的方式出發，先用SQL成生Table及Schema，再轉變成為程式碼中的數據模型。這樣的資料庫在日後作分析用途時，比較簡單易懂，方便使用熟悉SQL的人去使用。這也常見於二次開發程式，因為這樣可以確保不會錯誤地破壞原有資料庫。</p>
<p>那麼筆者為何講這兩個差異越來越講不清？那是因為現在的資料庫不能單純地只考慮初次或二次開發問題，而是需要考慮多個系統協調運行的問題。</p>
<h2 id="多系統共享協定---database-first"><a class="header" href="#多系統共享協定---database-first">多系統共享協定 - Database First</a></h2>
<p>因為隨著資料系統發展，有些資料會作為數據源出現或用作共享媒界，如果一定要對設計策略作分類，在多系統協調運作下，這些應該叫使Database First。不論它們是SQL還是NoSQL資料庫，我們的程式碼都要為這個預先定義好的數據結構作出妥協。不論使用工具，還是人為分析，都要把共享的數據結構轉換成自己程式中的數據模型。</p>
<p>即使不是多系統協調運作，有時候因為要移植系統，但同時又要令兩個系統版本相容。新系統也是被逼使用Database First的方式設計。</p>
<h2 id="自動化考量---code-first"><a class="header" href="#自動化考量---code-first">自動化考量 - Code First</a></h2>
<p>前述我們講到，很多時候我們也是從Database First的方式思考。不過筆者就這個Database First，也弄到滿身傷痕。</p>
<p>首先，拋開工具轉換的誤差，我們人為的把共享數據轉化為數據模型，共享數據有時會有一些先天的缺陷，例如: 資料沒有設計Primay Key (主鍵，唯一鍵)、日期時間的定義不明確等。面對一些意義不明的數據來源，要整合確實很要命。而且二次開發中，不可能100%重用原有的資料庫結構，很多時都會加入新的欄位或更多表格去計數。一旦加入新欄位，在團隊多人開發中，那麼使用唯一的共享開發環境，就變很易有程式碼上的衝突。</p>
<p>若需要多人開發，各人有一個Code First的開發用資料庫，是很必要的。這也可以在系統正式升級前，對比開發中資料庫及舊資料庫的結構，觀看它們之間的差異，評估升級的風險。</p>
<p>也許Code First並不是重點，重點是可以隨時建立一個測試用的資料庫，這才方便合作開發。自動化的地方，不單只限於數據結構，範例資料也該是如此。如果有維繫一個初始範例資料，可以在有需要時自動生成，對於多變的環境一定有很幫助。</p>
<p>現時，筆者基本上都會人為檢視資料庫，人工對照編寫程式中的資料結構(即是人工的Database First)，並確保那時程式再次經自動化生成的測試用資料庫，並沒有失真(即是Code First)。至於範例資料，初期筆者也只使用SQL生成，但後期因為資料結構開始複雜，筆者也暫暫使用程式碼生成，雖然工作量會多了，但對於資料庫升級、品牌更換，這是很有效的手段，程式碼升級測試也更順暢，絕比SQL生成更易維護。</p>
<h1 id="ref-1"><a class="header" href="#ref-1">Ref</a></h1>
<ul>
<li><a href="https://builtin.com/articles/code-first-vs-database-first-approach">Code First vs Database First</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-multiple-datasource"><a class="header" href="#spring-boot-multiple-datasource">Spring Boot Multiple DataSource</a></h1>
<p><a href="https://github.com/macauyeah/spring-boot-multiple-datasource">Example Code</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="lambda-表達式之可讀性"><a class="header" href="#lambda-表達式之可讀性">Lambda 表達式之可讀性</a></h1>
<p>Java作為一個真OOP物件導向的程式，在設計和編寫上是很嚴謹，什至是囉嗦的程度。近年很多Programmer因為各種原因，都放棄Java跳船去其他語言。</p>
<p>Javascript是其中一個很多人的選擇，因為Javascript有nodejs的加持，在Web世界下，可以同時走frontend、backend路線。而Javacript亦有一個很明顯的特性，就是大部份的library都以callback的型式出現。另外，Javascript也讓很多人覺得很簡潔，這除了是因為它沒有強型態的規限外，另一個原因也是因為有callback的大量使用。</p>
<h2 id="function-pointer"><a class="header" href="#function-pointer">Function Pointer</a></h2>
<p>其實callback，籠統一點講就是在一個function A傳入另一個function pointer B。而編寫function A的作者，並初期並不知道function pointer B的實際操作會是什麼。A作者只是強調在特別定時候，它就會使用這個function pointer B。而這種把function pointer 傳來傳去的做法，就可以看成是Functional Programming的基礎。</p>
<p>Functional Programming除了把function pointer 當成是一等公民以外，還有很多附加要求，例如：</p>
<ul>
<li>Pure Function: 它只會使用到自己的Local Variable本地變數，這樣它的作用域就鎖死在Function內部，就不會有副作用。
<ul>
<li>傳統的OOP，Class中不少變數會以Class Attribute型式存在，雖然它們可能是private attribute，但還是獨立於Function外，這樣各Function的操作，都要靠作者好好地記著Class Attribute的狀態。</li>
</ul>
</li>
<li>Nested Functions: 與普通程式語言類似，很多情況下都需要local variable，而Function Programming要足夠好用的話，就需要彈性地在function裏定義local function pointer。</li>
</ul>
<h2 id="java-lambda-表達式"><a class="header" href="#java-lambda-表達式">Java Lambda 表達式</a></h2>
<p>其實從Java 8開始，就有提供Lambda表達式，這是一個可以制作匿名function pointer的方法。所以硬要講，Java也可以做Functional Programming。</p>
<p>但必需要盡早強調的是，Java經常性地使用class attribute，它們很多時候都會引申請狀態的概念。即是在它們必需經過特定步驟後，class attribute才會有特定的意義。也就是Lambda表達式想保持Pure Function的特性，它可以使用的時期就有很大限制。</p>
<p>但我們還有必要使用Lambda嗎? 以筆者的經驗來講，它還是有作用的，特別在於它可以改善Class Function的閱讀性。</p>
<p>例如下面一個Java Class。它是一個工廠，提供一個服務可以生產一堆車。那些車而需要經過特定檢測，才能推出。</p>
<pre><code class="language-java">public class Factory {
    // ex1
    public static List&lt;Car&gt; generateListOfCarByForLoop() {
        List&lt;Car&gt; tempCars = new ArrayList&lt;&gt;();
        // many other logic
        // many other logic
        // many other logic
        List&lt;Car&gt; passTestCars = new ArrayList&lt;&gt;();
        for (Car car : tempCars) {
            if (car.getWheels().size() == 4) {
                // many other check logics
                // many other check logics
                // many other check logics
                passTestCars.add(car);
            }
        }
        return passTestCars;
    }
}
</code></pre>
<p>中間的for loop可以用lambda來改寫。</p>
<pre><code class="language-java">    // ex2
    public static List&lt;Car&gt; generateListOfCarByLamda() {
        List&lt;Car&gt; cars = new ArrayList&lt;&gt;();
        // many other logic
        // many other logic
        // many other logic
        cars = cars.stream().filter((car) -&gt; {
            if (car.getWheels().size() == 4) {
                // many other check logics
                // many other check logics
                // many other check logics
                return true;
            }
            return false;
        }).toList();
        return cars;
    }
</code></pre>
<p>有人會說，上述ex2只是形式上改變了，沒有特別易讀。就像ex3這樣，把特定邏輯抽成獨立function，才是真正的易讀，對嗎?</p>
<pre><code class="language-java">   // ex3
    public static List&lt;Car&gt; generateListOfCarByForLoopFunction() {
        List&lt;Car&gt; tempCars = new ArrayList&lt;&gt;();
        // many other logic
        // many other logic
        // many other logic
        List&lt;Car&gt; passTestCars = filterCarsByWheelsSize(tempCars, 4);
        return passTestCars;
    }

    private static List&lt;Car&gt; filterCarsByWheelsSize(List&lt;Car&gt; originalList, int targetSize) {
        List&lt;Car&gt; passTestCars = new ArrayList&lt;&gt;();
        for (Car car : originalList) {
            if (car.getWheels().size() == targetSize) {
                // many other check logics
                // many other check logics
                // many other check logics
                passTestCars.add(car);
            }
        }
        return passTestCars;
    }
</code></pre>
<p>上述ex3是一個有效的改進。如果大家不計較傳入參數的先後順序及交互影響的話，就已經很足夠。</p>
<p>但如果大家對於多參數的解讀又怎樣?</p>
<pre><code class="language-java">private static List&lt;Car&gt; someotherfunction(List&lt;Car&gt; cars, List&lt;Wheel&gt; wheels)
</code></pre>
<p>大家又會不會突然停住，想想到底是cars影響wheels，還是wheels影響cars?</p>
<p>對於多參數的function來講，相互影響就會越來越多，但使用Lambda的話，可以針對性地表達這是一個Predicate Lambda。</p>
<pre><code class="language-java">    // ex4
    public static List&lt;Car&gt; generateListOfCarByLamdaComposition() {
        List&lt;Car&gt; cars = new ArrayList&lt;&gt;();
        // many other logic
        // many other logic
        // many other logic
        List&lt;Wheel&gt; wheels = new ArrayList&lt;&gt;(4);
        cars = cars.stream().filter(
            filterCarByWheelSizePredicate(wheels)
        ).toList();
        return cars;
    }

    private static Predicate&lt;Car&gt; filterCarByWheelSizePredicate(List&lt;Wheel&gt; wheels){
        return (car) -&gt; {
            if (car.getWheels().size() == wheels.size()) {
                // many other check logics
                // many other check logics
                // many other check logics
                return true;
            }
            return false;
        };
    }
</code></pre>
<p>就最後的ex4版本，可以很明確的知道是cars被Predicate所作用</p>
<p>如果大家還有其他使用Lambda的明顯好處，也可以一起來Github分享大家的<a href="https://github.com/macauyeah/spring-boot-demo">Code</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="lambda-表達式之可讀性2---java-sorting"><a class="header" href="#lambda-表達式之可讀性2---java-sorting">Lambda 表達式之可讀性2 - Java Sorting</a></h1>
<p>對於習慣寫SQL的朋友來講，排序是件很容易的事，通常在SQL的結尾，先後加上不同欄位名稱，就可以有排序效果。例如:</p>
<pre><code class="language-sql">select car.size, car.NumberOfWheels
from car
order by car.size, car.NumberOfWheels
</code></pre>
<p>即使要改變排序的條件，先以car.NumberOfWheels再car.size，那改一改就好</p>
<pre><code class="language-sql">select car.size, car.NumberOfWheels
from car
order by car.NumberOfWheels, car.size
</code></pre>
<p>但對於Java來說，就不是這麼容易的一回事。很多依賴SQL的商用開發者，可能也不記得Java是怎樣做Sorting interface的。但對於NoSQL的世代來講，Database應該視為一個Storage Engine。某些排序還是要靠Program層面做，例如傳統的Java就需要提供一個回傳-1, 0, 1的Function，以決定A應該排在B前面，還是相等，還是排在B後面。</p>
<pre><code class="language-java">    public static void sortExample(){
        List&lt;Car&gt; cars = new ArrayList&lt;&gt;();
        // ... many cars
        cars.sort(ChainComparator.getOldSchoolComparator());
    }

    private static Comparator&lt;Car&gt; getOldSchoolComparator(){
        return (a, b)-&gt;{
            Double aCarSize = a.getSize();
            Double bCarSize = b.getSize();
            if (aCarSize.compareTo(bCarSize) != 0) {
                return aCarSize.compareTo(bCarSize);
            } else { // if tied
                Integer aNumOfWheel = a.getWheels().size();
                Integer bNumOfWheel = b.getWheels().size();
                return aNumOfWheel.compareTo(bNumOfWheel);
            }
        };
    }
</code></pre>
<p>上述例子雖然已使用Lambda去簡化寫法，但實際上如果排序欄位很多，就會出現一個很長的表達式。而且也很難去改寫中間的先後次序，例如怎樣才能很輕易地把numOfWheel改到放在carSize前面。即使我們有辦法把分段邏輯都抽入個別Function裏面，那個If的結構也是抽不走。</p>
<p>在Java 8 Lambda出現後，其實Comparator也有提供新的寫法，它可以連在一起繼續延伸，讓平手、再查一下條件的情況簡化了。這也是讓Dynamic Sorting變得有可能。</p>
<pre><code class="language-java">    public static void sortExample(){
        List&lt;Car&gt; cars = new ArrayList&lt;&gt;();
        // ... many cars
        cars.sort(ChainComparator.getComparatorChain());
    }
	private static Comparator&lt;Car&gt; getComparatorCarSize(){
        return (aCar, bCar)-&gt;{
            Double aCarSize = aCar.getSize();
            Double bCarSize = bCar.getSize();
            return aCarSize.compareTo(bCarSize);
        };
    }

    private static Comparator&lt;Car&gt; getComparatorNumOfWheels(){
        return (aCar, bCar)-&gt;{
            Integer aNumOfWheel = aCar.getWheels().size();
            Integer bNumOfWheel = bCar.getWheels().size();
            return aNumOfWheel.compareTo(bNumOfWheel);
        };
    }

    private static Comparator&lt;Car&gt; getComparatorChain(){
        return ChainComparator.getComparatorCarSize()
            .thenComparing(ChainComparator.getComparatorNumOfWheels());
    }
</code></pre>
<p>上述的例子，可能還是沒有太體現出Lambda的好處，主要是Java型態的問題，上面那樣寫我們每次都要重複地編寫適合Car的Comparator，就變得有點囉唆。但貼心的Comparator還有提供進一步的Lambda結構。</p>
<pre><code class="language-java">    public static void sortExample(){
        List&lt;Car&gt; cars = new ArrayList&lt;&gt;();
        // ... many cars
        cars.sort(ChainComparator.getComparatorChain2());
    }

    private static Comparator&lt;Double&gt; getComparatorDouble(){
        return (aCarSize, bCarSize)-&gt;{
            return aCarSize.compareTo(bCarSize);
        };
    }

    private static Comparator&lt;Integer&gt; getComparatorInteger(){
        return (aNumOfWheel, bNumOfWheel)-&gt;{
            return aNumOfWheel.compareTo(bNumOfWheel);
        };
    }

    private static Comparator&lt;Car&gt; getComparatorChain2(){
        Comparator&lt;Car&gt; chainedComparator = Comparator.comparing(
            car-&gt;car.getSize(), // converter
            ChainComparator.getComparatorDouble() // reuse exisiting comparator
        );
        chainedComparator = chainedComparator.thenComparing(
            car-&gt;car.getWheels().size(), // converter
            ChainComparator.getComparatorInteger() // reuse exisiting comparator
        );
        return chainedComparator;
    }
</code></pre>
<p>上述的例子中，getComparatorDouble，getComparatorInteger可能是別人寫好的Comparator，它們不是針對Car來使用的。但我們還是可以經過Comparator.comparing的介面，硬把Car轉為Double或Integer，然後就可以重用別人準備好的getComparatorDouble，getComparatorInteger。</p>
<p><a href="https://github.com/macauyeah/spring-boot-demo/">Github Code</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="升級-webclient-ssl-reactor-netty-126重新配置-ssl-設定"><a class="header" href="#升級-webclient-ssl-reactor-netty-126重新配置-ssl-設定">升級 WebClient SSL (Reactor Netty 1.2.6)：重新配置 SSL 設定</a></h1>
<p>因為SSL provider 更新了的關係，好多 HttpClient / WebClient 設定SSL的部份都要重寫以免出現 deprecated 問題</p>
<p><code>reactor.netty.http.client.HttpClient</code> 在 1.0.x, 中可以這樣自行設定SSL逾時的部份，但當中的<code>spec.sslContext().defaultConfiguration</code> 在新版本，例如1.1.x後就會出現 deprecated。</p>
<pre><code class="language-java">// deprecated version
HttpClient.create()
  .secure(spec -&gt; spec.sslContext(SslContextBuilder.forClient())
    .defaultConfiguration(SslProvider.DefaultConfigurationType.TCP)
    .handshakeTimeout(Duration.ofSeconds(30))
    .closeNotifyFlushTimeout(Duration.ofSeconds(10))
    .closeNotifyReadTimeout(Duration.ofSeconds(10)));
</code></pre>
<p>觀看各大網站，都未有更新，唯有自行研究官方說明。</p>
<p>筆者撰寫本文的時候，netty 發行版本為 1.2.6， 1.3.0 還里程碑(M6)的階段。所有參考皆來自1.2.6版本，實際上我們要使用新的後綴為ContextSpec類，看Class名應該有分http 1.1， 2， 3的版本，筆者就試用最基本的http 1.1。<code>Http11SslContextSpec</code>, (有條件的朋友可以試用<code>Http2SslContextSpec</code>, <code>Http3SslContextSpec</code>)</p>
<pre><code class="language-java">import reactor.netty.http.Http11SslContextSpec;
import reactor.netty.http.client.HttpClient;
import java.time.Duration;
import org.springframework.web.reactive.function.client.WebClient;
import org.springframework.http.client.reactive.ReactorClientHttpConnector;

//...
        Http11SslContextSpec http11SslContextSpec = Http11SslContextSpec.forClient();

        HttpClient httpClient = HttpClient.create()
                .secure(spec -&gt; spec.sslContext(http11SslContextSpec)
                        .handshakeTimeout(Duration.ofSeconds(30))
                        .closeNotifyFlushTimeout(Duration.ofSeconds(10))
                        .closeNotifyReadTimeout(Duration.ofSeconds(10)));

        WebClient webClient = WebClient.builder().clientConnector(new ReactorClientHttpConnector(httpClient))
                .build();
//...
</code></pre>
<p>雖然這個寫法來看netty 1.2.6，但似乎1.1.x 通用。大家有需要可以交互測試一下。</p>
<h1 id="reference-3"><a class="header" href="#reference-3">Reference</a></h1>
<ul>
<li><a href="https://projectreactor.io/docs/netty/1.2.6/reference/http-client.html#http-client-timeout">netty 1.2.6 http-client-timeout 的設定</a></li>
<li><a href="https://projectreactor.io/docs/netty/1.1.30/reference/index.html#timeout-configuration">netty 1.1.30 timeout-configuration 的設定</a></li>
<li><a href="https://projectreactor.io/docs/netty/1.2.6/api/index.html">netty 1.2.6 java api doc</a></li>
<li><a href="https://projectreactor.io/docs/netty">netty release version</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-01---萬物始於spring-boot-context"><a class="header" href="#spring-boot-01---萬物始於spring-boot-context">Spring Boot 01 - 萬物始於Spring boot context</a></h1>
<p>筆者早些時候向一位朋友討論，為何Java那麼不受歡迎。朋友一句就回答，Java煩爆，沒有人會喜歡。</p>
<p>老實講，Java在句法上，實在囉唆。但以筆者的經驗，即使使用其他語言和開發框架，在實戰到一定複雜程度下，其實也一樣煩爆。</p>
<p>而現在的Java框架中，就以Spring boot的入門門檻低。筆者從Spring boot 1.x用到現在的3.x，也真的感受到更多的簡化，所以筆者也加入一起推廣Spring boot的行列。筆者將會通過一系列最小的可執行程式，為大家講解Spring在Web和資料庫上的應用。</p>
<p>所以現在就不廢話，馬上開壇作法</p>
<h2 id="快速下戴模版"><a class="header" href="#快速下戴模版">快速下戴模版</a></h2>
<p>使用Spring initializr，可以很容易就建立一個以Spring boot starter為底的java project。大家可以使用<a href="https://start.spring.io/">Spring 官網</a>又或是<a href="https://code.visualstudio.com/docs/java/java-spring-boot">vscode plugin</a> 快速地建立一個maven或gradle project。筆者較為熟悉maven，就以maven起一個範例。</p>
<p>在使用Spring initializr有幾件事必需要指定的:</p>
<ul>
<li>Spring boot version: 3.x.y 或以上</li>
<li>Language: java</li>
<li>Group Id: 請選擇有意思的域名，如果你用github，可以選 io.github.yourusername</li>
<li>artifactId: 這個範例的名字，例如commandline</li>
<li>Packaging type: 本次使用jar，日後若開發web 應用，可以使用war</li>
<li>Java version: 17或以上</li>
</ul>
<p>之後就不用選了。若你經官網起範例，你會得到一個zip檔，下載後解壓縮。若你使用vscode插件，最後插件會叫有一個位置儲存。它們都是最後也是會得到同一樣範例Java project。</p>
<p>你使用Vscode，Intellij打開，IDE都會自動辨識到它是java maven project，同時會顯示java和maven結構。道理上你用Intellij 應該可以無腦開始編譯(Community 或Ultimate版都可以)，
Vscode有安裝Extension Pack for Java也會開始自動編譯。不想麻煩，也可以試用<a href="https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration/setting-up-your-java-project-for-codespaces">Github Codespaces - java</a>。Github Codespaces其實就是一個雲上的vscode，經網頁可以連到Github VM內的vscode，所以它也會有齊Extension Pack for Java等插件。</p>
<p>筆者最後也會上載已完成的範例，它也可以在Github Codespaces上以Java執行或繼續開發。</p>
<p>打開project中的pom.xml，它為我們添加了兩個很重要的lib</p>
<pre><code class="language-xml">		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
		&lt;/dependency&gt;
		...
		...
			&lt;plugin&gt;
				&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
				&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
			&lt;/plugin&gt;
</code></pre>
<p>spring-boot-starter是重中之重，它定義了怎樣動態地設定日後的其他lib，它是讓我們可以無腦設定的一個關鍵。(但若大家有很多客制化的設定，就要返撲歸真地逐個lib叫起)。</p>
<p>maven在預設情況下，只會負責編譯和打包目前的project原始碼。所有相關依賴(就是xml中的dependency)，並不會自動包起。而spring-boot-maven-plugin，就是幫我們把相關依據都包在一起，讓你的jar可以獨立行起來。</p>
<p>註: 若大家在開發lib jar，並不是一個獨立執行的jar，也就是原始碼上沒有main函數，大家就不應該引用spring-boot-starter和spring-boot-maven-plugin。</p>
<p>我們繼續看其他原始碼，整個資料夾就像以下那樣。</p>
<pre><code>.
|-- HELP.md
|-- pom.xml
`-- src
    |-- main
    |   |-- java
    |   |   `-- io
    |   |       `-- github
    |   |           `-- macauyeah
    |   |               `-- springboot
    |   |                   `-- tutorial
    |   |                       `-- commandline
    |   |                           `-- CommandlineApplication.java
    |   `-- resources
    |       `-- application.properties
    `-- test
        `-- java
            `-- io
                `-- github
                    `-- macauyeah
                        `-- springboot
                            `-- tutorial
                                `-- commandline
                                    `-- CommandlineApplicationTests.java
</code></pre>
<p>CommandlineApplication是我們有main函數的java class。我像可以經過IDE運行main又或者下指令mvn spring-boot:run來執行。</p>
<h2 id="正式開始我們的commandline開發"><a class="header" href="#正式開始我們的commandline開發">正式開始我們的Commandline開發</a></h2>
<p>我們在CommandlineApplication.class中，加入新的程式碼，實現ApplicationRunner和它的函數run。</p>
<pre><code class="language-java">package io.github.macauyeah.springboot.tutorial.commandline;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.ApplicationArguments;
import org.springframework.boot.ApplicationRunner;
// other import

@SpringBootApplication
public class CommandlineApplication implements ApplicationRunner {
	static Logger LOG = LoggerFactory.getLogger(CommandlineApplication.class);

	public static void main(String[] args) {
		SpringApplication.run(CommandlineApplication.class, args);
	}

	@Override
	public void run(ApplicationArguments args) throws Exception {
		args.getOptionNames().stream().forEach(optionName -&gt; {
			LOG.debug("option name:" + optionName);

			args.getOptionValues(optionName).forEach(optionValue -&gt; {
				LOG.debug("option values:" + optionValue);
			});
		});
		LOG.debug("program end.");
	}
	// ...
</code></pre>
<p>這個run函數很直白，就是更好地演譯main中的String[] args。</p>
<p>但大家還要看清楚，這個main並沒有直接執行run。其實它是靠SpringApplication.run及@SpringBootApplication，跑一堆自動設定，最後因為傳入CommandlineApplication.class是一個Spring 可以處理的ApplicationRunner，所以才呼叫它的CommandlineApplication.run。</p>
<p>換個講法，如果今天做的是web應用，傳入去的就會是SpringBootServletInitializer，這個SpringBootServletInitializer也不一定跟main是同一個class。</p>
<p>如果大家有興趣，可以經過反編譯器，點入@SpringBootApplication看它的原始碼，你就可以看到它其實代表了很多自動化的東西。如果我們只做一些在同一個模組下生效的事情，《自動化》極大地降低了大家入門門檻。一般來講，如果大家不在意程式碼的複用度，比較少機會自行設定，自動化已經很有用。而隨著系統規模增加，多模組就慢慢地顯得重要，在大家了解完基本的Spring後，著者再從測試用途test case入手，為大家介紹如何手動設定。</p>
<h2 id="source-code"><a class="header" href="#source-code">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/commandline">Commandline Application</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-02---快速接入database的選擇-spring-data-jpa"><a class="header" href="#spring-boot-02---快速接入database的選擇-spring-data-jpa">Spring Boot 02 - 快速接入Database的選擇: Spring Data JPA</a></h1>
<h2 id="快速下戴模版-1"><a class="header" href="#快速下戴模版-1">快速下戴模版</a></h2>
<p>使用Spring initializr，可以很容易就建立一個以Spring boot starter為底的java project。大家可以使用<a href="https://start.spring.io/">Spring 官網</a>又或是<a href="https://code.visualstudio.com/docs/java/java-spring-boot">vscode plugin</a> 快速地建立一個maven或gradle project。筆者較為熟悉maven，就以maven起一個範例。</p>
<p>在使用Spring initializr有幾件事必需要指定的:</p>
<ul>
<li>Spring boot version: 3.x.y 或以上</li>
<li>Language: java</li>
<li>Group Id: 請選擇有意思的域名，如果你用github，可以選 io.github.yourusername</li>
<li>artifactId: 這個範例的名字，例如spring-boot-data-basic</li>
<li>Packaging type: 本次使用jar，日後若開發web 應用，可以使用war</li>
<li>Java version: 17或以上</li>
<li>Dependency: Spring Data JPA, Spring Boot DevTools</li>
</ul>
<p>這次不像過去順利，因為這裏欠缺了Database連線資料，為了方便測試，我們先在pom.xml加入</p>
<pre><code class="language-xml">&lt;dependencies&gt;
	&lt;dependency&gt;
		&lt;groupId&gt;com.h2database&lt;/groupId&gt;
		&lt;artifactId&gt;h2&lt;/artifactId&gt;
		&lt;scope&gt;runtime&lt;/scope&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>h2與spring的整合很好。即使用什麼都不設定，直接運行<code>mvn spring-boot:run</code>，都可以成功執行了。但如果可以，在application.properties加入資料庫設定，會方便日後移植到其他常用的資料庫品版牌。</p>
<pre><code># src/main/resources/application.properties
spring.datasource.driver-class-name=org.h2.Driver
spring.datasource.url=jdbc:h2:mem:testdb;
spring.datasource.usename=random
spring.datasource.password=random
</code></pre>
<p>然後我們就可以做靠Spring Data JPA去生資料庫的表 (table)。Spring Data JPA預設使用的是Hibernate。假設，我們有一個表叫APPLE。我們就可以開一個class Apple和一個interface AppleRepo去接它。</p>
<pre><code class="language-java">// src/main/java/io/github/macauyeah/springboot/tutorial/springbootdatabasic/Apple.java
@Entity
public class Apple {
    @Id
    String uuid;
    Double weight;
	// getter setter
}

// src/main/java/io/github/macauyeah/springboot/tutorial/springbootdatabasic/AppleRepo.java
public interface AppleRepo extends JpaRepository&lt;Apple, String&gt;{
    // no content here
}
</code></pre>
<p>注意，因為不同需要，AppleRepo可能繼承不同的XXXRepository，它們大部份都是用來觸發寫入資料庫的指令。而這個也晚除了直接存取Hibnerate EntityManager的需要。</p>
<p>亦因為我們現在用的是h2Database，其實資料表並不存在。我們需要在執行Spring Boot時，同步先建立表，所以在application.properties 加入自動建表的設定。</p>
<pre><code># src/main/resources/application.properties
spring.jpa.generate-ddl=true
spring.jpa.hibernate.ddl-auto=update
</code></pre>
<p>然後在Spring Boot Context的環境下，可以隨時執行寫入的操作。</p>
<pre><code class="language-java">	@Autowired
	private AppleRepo appleRepo;

	public void saveApple() {
		Apple apple = new Apple();
		apple.setUuid(UUID.randomUUID().toString());
		apple.setWeight(100.0);
		appleRepo.save(apple);
	}
</code></pre>
<h2 id="source-code-1"><a class="header" href="#source-code-1">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-data-basic">spring boot data basic</a></p>
<p>因為h2Database只是用作測試用，所以spring-boot執行完，資料庫就會被刪除。而上述原始碼當中，還附上了一些dump sql的方法，至少可以讓大家驗證己儲存的結果。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-03---做好database的模組化及測試用例"><a class="header" href="#spring-boot-03---做好database的模組化及測試用例">Spring Boot 03 - 做好Database的模組化及測試用例</a></h1>
<p>這節，我們將會使用spring-data-jpa，寫一個業務上的資料庫模組，提供資料表的存取，讓你的好同僚可以直接使用。這樣可以在多模組的環境中，減少同一個資料表在不同地方重複又重複地重定義。將來要更新，也可以使用jar檔的方式發佈。</p>
<h2 id="下戴模版"><a class="header" href="#下戴模版">下戴模版</a></h2>
<p>我們跟上節一樣，使用Spring Initializr (Maven) 下載模版，但細節筆者就不再講啦。Dependency主要選擇</p>
<ul>
<li>H2 Database</li>
<li>Spring Data JPA</li>
</ul>
<p>對pom.xml作一些微調，並把spring-boot-start-data-jpa，h2改為只在測試中生效。</p>
<pre><code class="language-xml">		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;
			&lt;scope&gt;test&lt;/scope&gt;
		&lt;/dependency&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;com.h2database&lt;/groupId&gt;
			&lt;artifactId&gt;h2&lt;/artifactId&gt;
			&lt;scope&gt;test&lt;/scope&gt;
		&lt;/dependency&gt;
</code></pre>
<p>並把Java檔案搬一搬位置</p>
<pre><code class="language-bash"># old location
src/main/java/io/github/macauyeah/springboot/tutorial/springbootdatatest/SpringBootDataTestApplication.java
src/main/resources/application.properties
# new location
src/test/java/io/github/macauyeah/springboot/tutorial/springbootdatatest/SpringBootDataTestApplication.java
src/test/resources/application.properties
</code></pre>
<p>以上的操作，主要是因為我們的目標是提供Schema，或者叫資料表規格。其他用於做連線的操作，我們不需要打包在jar內。所以把那些次要的東西都放在test資料夾中。我們這時可以先用<code>mvn test</code>指令，確保一切功能還是正常。</p>
<h2 id="entity-folder"><a class="header" href="#entity-folder">Entity folder</a></h2>
<p>然後我們入正題，在pom.xml中加入hibernate-core，spring-data-jpa，</p>
<pre><code class="language-xml">		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.data&lt;/groupId&gt;
			&lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt;
		&lt;/dependency&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt;
			&lt;artifactId&gt;hibernate-core&lt;/artifactId&gt;
		&lt;/dependency&gt;
</code></pre>
<p>然後在main資料夾下加入 Entity、Repository，例如前述用過的Apple和AppleRepo，最後資料夾就像是這樣。</p>
<pre><code>.
|-- pom.xml
|-- src
|   |-- main
|   |   `-- java
|   |       `-- io
|   |           `-- github
|   |               `-- macauyeah
|   |                   `-- springboot
|   |                       `-- tutorial
|   |                           `-- springbootdatatest
|   |                               |-- Apple.java
|   |                               `-- AppleRepo.java
|   `-- test
|       |-- java
|       |   `-- io
|       |       `-- github
|       |           `-- macauyeah
|       |               `-- springboot
|       |                   `-- tutorial
|       |                       `-- springbootdatatest
|       |                           |-- SpringBootDataTestApplication.java
|       |                           `-- SpringBootDataTestApplicationTests.java
|       `-- resources
|           `-- application.properties
</code></pre>
<p>然後我們在Test Case中使用AppleRepo</p>
<pre><code class="language-java">@SpringBootTest
class SpringBootDataTestApplicationTests {
	@Autowired
	AppleRepo appleRepo;

	@Test
	void contextLoads() {
		Apple apple = new Apple();
		apple.setUuid(UUID.randomUUID().toString());
		apple.setWeight(100.0);
		apple.setGravity(1000.0);
		appleRepo.save(apple);
	}
}
</code></pre>
<p>這個跟前述<a href="#spring-boot-02---快速接入database的選擇-spring-data-jpa">02-spring-data-jpa</a>最大的差別，就是我們的main中只有Entity相關的Class，我們發佈jar，別人引用我們的class，別人不會解發其他不相干的商業邏輯。假如發佈02的例子，因為Spring有自動初始化Component的原因，很可能會誤觸發02中的BasicApplicationRunner.java</p>
<h2 id="source-code-2"><a class="header" href="#source-code-2">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-data-test">spring boot data test</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-04---進入-http-json-api-世代"><a class="header" href="#spring-boot-04---進入-http-json-api-世代">Spring Boot 04 - 進入 http json api 世代</a></h1>
<p>本節，我們將會建立一個http服務，提供json api讓程式訪問。</p>
<h2 id="下戴模版-1"><a class="header" href="#下戴模版-1">下戴模版</a></h2>
<p>我們跟上節一樣，使用Spring Initializr (Maven) 下載模版，但細節筆者就不再講啦。Dependency主要選擇</p>
<ul>
<li>Spring Web</li>
<li>Spring Boot DevTools</li>
</ul>
<p>下載後，可以直接運行測試，可以用指令 <code>mvn test</code> 或經IDE運行。Spring會至少測試下能不能成功取用預設的8080端口。</p>
<h2 id="controller"><a class="header" href="#controller">Controller</a></h2>
<p>我們若要實作 http json api，需要在 spring 中加入一個類，附註為
@RestController ，那方便起見，類名我們也命名為 XXXController 吧。作為示範，我們弄一個 HomeController.java ，裏面有最常見的 http GET, POST功能。</p>
<pre><code class="language-java">// src/main/java/io/github/macauyeah/springboot/tutorial/springbootwebapibasic/controller/HomeController.java
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;

// ... other import

@RestController
@RequestMapping("/api")
public class HomeController {
    @GetMapping("/someRecord/{uuid}")
    public Map&lt;String, String&gt; readSomeRecord(@PathVariable String uuid) {
        return Map.of("ret", "your uuid:" + uuid);
    }

    @PostMapping("/someRecord")
    public Map&lt;String, String&gt; createSomeRecord(@RequestBody Map&lt;String, String&gt; requestBody) {
        HashMap&lt;String, String&gt; ret = new HashMap&lt;&gt;(requestBody);
        ret.put("ret", "got your request");
        return ret;
    }
}
</code></pre>
<p>HomeController裏，完整的URL 其實為:</p>
<ul>
<li>GET http://localhost:8080/api/someRecord/{uuid}</li>
<li>POST http://localhost:8080/api/someRecord</li>
</ul>
<p>URL中的api之後的路徑，都是定義在 HomeController 中，而前半的8080及context path，是使用預設值。在正式環境下，可能隨時會被重新定義。但我們做本地測試，只需要驗證預設值就可以了。</p>
<p>我們真的運行起程式<code>mvn clean compile spring-boot:run</code>，再使用最簡測試工具進行測試。Windows的朋友，可以選擇Postman作為測試，它有圖形介面。而linux的朋友，請用curl，預設安裝都會有。下列為方便表示測試參數，筆者選用curl。</p>
<p>測試GET，其中1234會自動對應到spring裏的uuid。</p>
<pre><code class="language-bash">curl http://localhost:8080/api/someRecord/1234

# return
{"ret":"your uuid:1234"}
</code></pre>
<p>測試 POST，其中的 -d 參數，會對應 spring裏的 @RequestBody， -H 參數則是設定 http header 的意思，我們就使用約定俗成的 json 作為 header 。</p>
<pre><code class="language-bash">curl -X POST http://localhost:8080/api/someRecord -H "Content-Type: application/json" -d '{"requst":"did you get it?"}'

# return
{"requst":"did you get it?","ret":"got your request"}
</code></pre>
<p>上面的兩個操作，都回傳了我們輸入的資訊，這代表了我們成功用spring架起了http json api，而且正常讀入資訊。</p>
<h2 id="test-case"><a class="header" href="#test-case">Test Case</a></h2>
<p>雖然我們可以正常地架起 api，但每次開發都要 postman / curl這種工具額外試一次，其實也有一些成本。而且 api 數量變大，或經多次修改後，就重複人手執行，就變得相當討厭。</p>
<p>面對這個問題，筆者會建議寫測試用例，即是Test Case，而且用Spring內置的@SpringBootTest來寫。</p>
<p>產生一個空的Test類，vscode中，最簡單可以Source Action =&gt; Generate Test，然後加入這次要測試的參數。</p>
<pre><code class="language-java">// src/test/java/io/github/macauyeah/springboot/tutorial/springbootwebapibasic/controller/HomeControllerTest.java
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.http.MediaType;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.RequestBuilder;
import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;
import org.springframework.test.web.servlet.result.MockMvcResultHandlers;
import org.springframework.test.web.servlet.result.MockMvcResultMatchers;

@SpringBootTest
@AutoConfigureMockMvc
public class HomeControllerTest {
    @Autowired
    private MockMvc mockMvc;

    @Test
    void testGetSomeRecord() throws Exception {
        RequestBuilder requestBuilder = MockMvcRequestBuilders.get("/api/someRecord/1234")
                .contentType(MediaType.APPLICATION_JSON);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret").value("your uuid:1234"))
                .andDo(MockMvcResultHandlers.print());
    }

    @Test
    void testPostSomeRecord() throws Exception {
        String request = """
                {"requst":"did you get it?"}
                    """;
        RequestBuilder requestBuilder = MockMvcRequestBuilders.post("/api/someRecord")
                .contentType(MediaType.APPLICATION_JSON)
                .content(request);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.jsonPath("$.requst").value("did you get it?"))
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret").value("got your request"))
                .andDo(MockMvcResultHandlers.print());
    }
}
</code></pre>
<p>最後就是執行 <code>mvn test</code> 或經IDE運行，應該都會得到所有測試都通過的結果。</p>
<pre><code class="language-bash">mvn test
# other test result ...
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.368 s -- in io.github.macauyeah.springboot.tutorial.springbootwebapibasic.controller.HomeControllerTest
# other test result ...
</code></pre>
<p>上面的程式碼很多，我們逐一來。</p>
<ul>
<li>@SpringBootTest 寫在類的外面，代表執行這個測試類時，需要運行起整個Spring程序，當然也包括http的部份。</li>
<li>@AutoConfigureMockMvc 寫在類的外面，代表執行這個測試類時，可以模擬一些發向自己的 http 請求。</li>
<li>@Autowired private MockMvc mockMvc 寫在類的裏面，因為之前有定義了可以模擬 http 的請求，Spring在運行時為大家提供了那個所謂的模擬http client的實例。</li>
<li>MockMvcRequestBuilders，則是建造要測試的URL及Header參數。</li>
<li>MockMvcResultMatchers，則是檢查回傳的結果是否如遇期的一樣。</li>
<li>為何這個http client叫模擬 - Mock ? 因為在測試用例中，可能連Controller 內部依賴組件也需要進一步模擬，這樣才能把測試目標集中在Controller裏，這也是單元測試的原意。只是本次的例子看不出模擬與否的差別。而且它還模擬了很多東西，例如權限，只是本篇沒有演示怎麼做。權限功能等將在後述的篇章中解紹。</li>
<li>MockMvcResultMatchers.jsonPath()，這是用來檢測json的結構是否跟預期一樣。有些網路上的其他例子會簡寫成 jsonPath() ，但因為vscode IDE的自動import功能比較差，筆者還是保留傳統的寫法。</li>
</ul>
<p>如果大家覺得@SpringBootTest很難，想折衷地把其他測試方法，那麼把 postman / curl好好管理起來，每次修改完程式，都完整地執行一次 postman / curl ，也可以達到測試的效果。只不過大家還是要好好學會整合 postman / curl，知道如何檢測json結構，什麼時候有錯，什麼時候叫測試通過，所以也要花一樣功夫來實現。</p>
<p>最後，大家千萬不要因為測試難寫而逃課，因為寫測試絕對地可以減輕日後重執行的工作量。除非你的程式碼即用即棄，否則都建議寫測試。(測試跟寫文檔不一樣，有了測試也不能沒有文檔。好消息的是，文檔現在越來越多自動生成的工具，我們日後再找機會介紹。)</p>
<h2 id="source-code-3"><a class="header" href="#source-code-3">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-basic">spring boot web api basic</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-05---為-http-json-api-加入登入要求"><a class="header" href="#spring-boot-05---為-http-json-api-加入登入要求">Spring Boot 05 - 為 http json api 加入登入要求</a></h1>
<p>本節，我們將為之前的http服務，加入認證機制，只有在資料庫現存的用戶可以登入及訪問我們的json api。</p>
<h2 id="下戴模版-2"><a class="header" href="#下戴模版-2">下戴模版</a></h2>
<p>慣例，我們用Spring Initializr (Maven) 下載模版，Dependency主要選擇</p>
<ul>
<li>Spring Web</li>
<li>Spring Boot DevTools</li>
<li>Spring Security</li>
</ul>
<h2 id="controller-1"><a class="header" href="#controller-1">Controller</a></h2>
<p>跟上節一樣，我們起一個Controller，為簡化測試，我們只做http GET api。</p>
<pre><code class="language-java">//src/main/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/controller/HomeController.java
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/api")
public class HomeController {
    @GetMapping("/someRecord/{uuid}")
    public Map&lt;String, String&gt; readSomeRecord(@PathVariable String uuid) {
        return Map.of("ret", "your uuid:" + uuid);
    }
}
</code></pre>
<p>準備我們的test case，但這次我們預期它應該要出現登入失敗的結果。</p>
<pre><code class="language-java">//src/test/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/controller/HomeControllerTest.java
@SpringBootTest
@AutoConfigureMockMvc
public class HomeControllerTest {
    @Autowired
    private MockMvc mockMvc;

    @Test
    void testNoLogin() throws Exception {
        RequestBuilder requestBuilder = MockMvcRequestBuilders.get("/api/someRecord/1234")
                .contentType(MediaType.APPLICATION_JSON);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().is4xxClientError())
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret").doesNotExist())
                .andDo(MockMvcResultHandlers.print());
    }
}
</code></pre>
<p>在我們執行上述的測試，test case 成功過了。我們的基本設定跟上一節其實沒有多大改動，為何現在http api會回傳狀態 401？</p>
<p>那是因為我們在依賴中加了，Spring Security，它配合了Spring Web，就會自動為所有api加入權限檢測。我們的測試中，沒有任何用戶登入，當然會出現 http 401。為了讓我們可以好好管理誰可以使用api，我們就來設定一定Security。</p>
<p>我們加一個WebSecurityConfig.java，暫時指定所有的訪問路徑都必需有USER權限，並且用 http basic的方式登入。</p>
<pre><code class="language-java">//src/main/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/config/WebSecurityConfig.java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.Customizer;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.web.SecurityFilterChain;

@Configuration
@EnableWebSecurity
public class WebSecurityConfig {
    @Bean
    SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http.authorizeHttpRequests(authorizeHttpRequests -&gt; {
            authorizeHttpRequests.requestMatchers("/**").hasRole("USER");
            // 所有的訪問路徑都必需有USER權限
        });
        http.httpBasic(Customizer.withDefaults());
        // 使用http basic作為登入認證的方式
        return http.build();
    }
}
</code></pre>
<p>上述例子，只是擋了沒有權限的人，我們還需要讓有登入身份的用戶可以成得取限User權限。</p>
<p>我們繼續修改，WebSecurityConfig，加入只在記憶體有效的InMemoryUser</p>
<pre><code class="language-java">import org.springframework.security.core.userdetails.User;
import org.springframework.security.core.userdetails.UserDetails;
import org.springframework.security.core.userdetails.UserDetailsService;

import org.springframework.security.provisioning.InMemoryUserDetailsManager;

public class WebSecurityConfig {
    //..
    @Bean
    public PasswordEncoder passwordEncoder() {
        return new BCryptPasswordEncoder();
        // 我們的密碼不應該明文儲，比較保險，我們使用BCrypt演算法，為密碼做單向加密。
    }
    @Bean
    public UserDetailsService userDetailsService() {
        UserDetails user = User.withUsername("admin")
                .password(passwordEncoder().encode("pass"))
                .roles("USER").build();
        // 我們在記憶中體，加入一個測試用的User，它的名字為admin，密碼為pass，權限為User
        return new InMemoryUserDetailsManager(user);
    }

    
</code></pre>
<p>然後加入新的測試，直接模擬Role。結果是通過的。</p>
<pre><code class="language-java">//src/test/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/controller/HomeControllerTest.java
    @Test
    void testLoginWithRoles() throws Exception {
        RequestBuilder requestBuilder = MockMvcRequestBuilders.get("/api/someRecord/1234")
                .contentType(MediaType.APPLICATION_JSON).with(
                        SecurityMockMvcRequestPostProcessors.user("someone")
                                .roles("USER", "ADMIN"));
                                // 沒有使用密碼，只使用Role
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().is2xxSuccessful())
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret").value("your uuid:1234"))
                .andDo(MockMvcResultHandlers.print());
    }
</code></pre>
<p>再來一個測試，改用密碼登入，分別輸入錯的和正確的密碼。</p>
<pre><code class="language-java">    @Test
    void testLoginWithWrongPasswordAndNoRole() throws Exception {
        RequestBuilder requestBuilder = MockMvcRequestBuilders.get("/api/someRecord/1234")
                .header("Authorization", "Basic randompass")
                // 輸入錯的密碼，應該回傳http 401 Unauthorized
                .contentType(MediaType.APPLICATION_JSON);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().is4xxClientError())
                .andDo(MockMvcResultHandlers.print());
    }

    @Test
    void testLoginWithPassword() throws Exception {
        RequestBuilder requestBuilder = MockMvcRequestBuilders.get("/api/someRecord/1234")
                .header("Authorization", "Basic YWRtaW46cGFzcw==")
                // http basic 就是把 admin:pass 轉成base64
                .contentType(MediaType.APPLICATION_JSON);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().is2xxSuccessful())
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret").value("your uuid:1234"))
                .andDo(MockMvcResultHandlers.print());

    }
</code></pre>
<p>最後，當然是正確的密碼才能通過。若果大家還是半信半疑，我們可以跑起真的正服務（IDE RUN或mvn spring-boot:run），然後用curl去試。</p>
<pre><code class="language-bash">curl http://localhost:8080/api/someRecord/1234
// failed with 401
curl -u "admin:pass" http://localhost:8080/api/someRecord/1234
// successed
</code></pre>
<h2 id="使用sql-database讀取用戶登入資訊"><a class="header" href="#使用sql-database讀取用戶登入資訊">使用SQL Database讀取用戶登入資訊</a></h2>
<p>一般而言，我們不可能把所有用戶登資訊打在InMemoryUser中，通常背後有一個資料庫儲存所有的用戶資訊，我們在登入時，讀取它來做對比檢證。</p>
<p>為此，我們在maven中，加入</p>
<ul>
<li>Spring Data JPA</li>
<li>h2 database （或任何你的資料庫，如mysql 、 sql server）</li>
</ul>
<p>最後一步，我們把InMemoryUser去掉，改為從資料庫讀取。因為原始碼太多，就不全部貼上。最主要的是WebSecurityConfig.java要關掉之前的UserDetailsService，改為提供一個UserServiceImpl類，它會實現UserDetailsService的功能。</p>
<pre><code class="language-java">@Configuration
@EnableWebSecurity
public class WebSecurityConfig {
    // 把原來的Bean先變成註解，其他不變

    // @Bean
    // public UserDetailsService userDetailsService() {
    //     UserDetails user = User.withUsername("admin")
    //             .password(passwordEncoder().encode("pass"))
    //             .roles("USER").build();

    //     return new InMemoryUserDetailsManager(user);
    // }
}
</code></pre>
<pre><code class="language-java">// spring-boot-tutorial/spring-boot-web-api-data/src/main/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/config/UserServiceImpl.java

// other import
import org.springframework.security.core.authority.SimpleGrantedAuthority;
import org.springframework.security.core.userdetails.User;
import org.springframework.security.core.userdetails.UserDetails;
import org.springframework.security.core.userdetails.UserDetailsService;
import org.springframework.security.core.userdetails.UsernameNotFoundException;
import org.springframework.security.crypto.password.PasswordEncoder;

@Service
public class UserServiceImpl implements UserDetailsService {
    @Autowired
    PasswordEncoder passwordEncoder;
    @Autowired
    UserRepo userRepo;

    @Override
    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
        // 因為我們資料庫沒有資料，為了方便測試密碼的加密，我們在java code上直接插入一筆資料。
        UserEntity defaultUser = new UserEntity();
        defaultUser.setUsername("admin");
        defaultUser.setPassword(passwordEncoder.encode("pass"));
        defaultUser.setRole("USER");
        defaultUser.setUuid(UUID.randomUUID().toString());
        userRepo.save(defaultUser);
        // 上述為測試用插入資料，不應該出現在正式使用環境中。


        UserEntity user = userRepo.findOneByUsername(username)
                .orElseThrow(() -&gt; new UsernameNotFoundException(username + " not found"));
        // 找找資料庫有沒有正在登入的該名使用者username
        List&lt;SimpleGrantedAuthority&gt; authorities = List.of(new SimpleGrantedAuthority("ROLE_" + user.getRole()));
        LOG.debug("got user uuid:{}, username:{}, role:{} from database", user.getUuid(), username, user.getRole());
        // 如果前面的 findOneByUsername 有結果回傳，我們就給它一個ROLE_XXX的權限。
        return new User(username, user.getPassword(), authorities);
        // 這裏從沒有檢查過密碼是否有匹配，全部交給Spring Security去做
    }
}

//spring-boot-tutorial/spring-boot-web-api-data/src/main/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/entity/UserEntity.java
// spring-boot-tutorial/spring-boot-web-api-data/src/main/java/io/github/macauyeah/springboot/tutorial/springbootwebapidata/repo/UserRepo.java
</code></pre>
<p>上述段落中，筆者省略了UserEntity和UserRepo，它們只是一般的spring-data-jpa概念，有需要可以經文末的連結查看完全原始碼。最需要注意的，是UserEntity的password欄位，在資料庫中是以加密的方式儲存。我們在配匹登入者與資料庫記錄時，也沒有自行檢驗密碼的需要。我們只是在加密過的密碼回傳給Spring Security，Spring框架會自行把登入者輸入的密碼與加密了的密碼作比較。</p>
<h2 id="source-code-4"><a class="header" href="#source-code-4">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-data">spring boot web api data</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-06---spring-boot-web-調試工具"><a class="header" href="#spring-boot-06---spring-boot-web-調試工具">Spring Boot 06 - Spring Boot Web 調試工具</a></h1>
<p>之前兩節，都一直在講怎樣寫code，也介紹了Test Case的好。若為初次接觸，Spring有很多設定需要摸索，若開始時就設定錯誤，對不少人來講都會有很大打擊。在這裏，筆者就介紹一些vscode和spring的工具，可以讓IDE多幫忙一下，減少走歪路的機會。</p>
<h2 id="vscode插件"><a class="header" href="#vscode插件">vscode插件</a></h2>
<p>以下兩個插件，都在於提示用戶設定。</p>
<ul>
<li>Spring Boot Dashboard (vscjava.vscode-spring-boot-dashboard)
<ul>
<li>可以那它來運作spring boot app，省去找尋main 位置的麻煩</li>
<li>綜覽整個程式中的所有Bean (Bean是一個很重要的元素，日後會再提及)</li>
<li>若程式為Spring boot web，可以顯示所 http endpoint。</li>
</ul>
</li>
<li>Spring Boot Tools (vmware.vscode-spring-boot)
<ul>
<li>檢查設定檔的設定值有沒有寫錯 （application*.properties， application*.yml）</li>
<li>綜覽檔案中的有以@為首的與spring相關的元素（檔案很大時就會有用）</li>
<li>可以在IDE運行spring時，查看@元素的bean資訊 (not works ?, 加了actuator也是沒有看見)</li>
</ul>
</li>
<li>Spring Initializr（vscjava.vscode-spring-initializr）
<ul>
<li>經網絡初始化spring 專案的依賴引用設定</li>
</ul>
</li>
<li>Maven for Java (vscjava.vscode-maven)
<ul>
<li>若大家在使用Spring Initializr時，選取了maven作管理工具，那麼這插件就可以在後續幫忙更新引用。</li>
<li>若專案的Spring 及㡳層引用有變，vscode也需要它來引用更新。</li>
<li>這是java 開發工具包(vscjava)的其中一員，它的其他插件也可以順帶安裝。</li>
</ul>
</li>
</ul>
<h2 id="調試工具---open-api--swagger-ui"><a class="header" href="#調試工具---open-api--swagger-ui">調試工具 - open api / swagger-ui</a></h2>
<p>如果我們在開發Web http API ，其實都是為了該某個客戶端使用。但如果該客端明白我們的API該怎樣使用，大家總不會逐個連結，自行編寫使用手冊及範例吧。所以就有了open api 和 swagger-ui 的誕生 。</p>
<p>open api，就是一個公認的使用手冊標準，我們只要在spring-web中加入 springdoc-openapi-starter-webmvc-ui 的程式庫，就可以自動為我們的controller 生成 open api 的說明檔。</p>
<p>更強大的是，這個程式庫可以利用剛生成的open api，配上 swagger-ui ，自動生成一個可供測試的頁面。這個頁面可以供碼農們直接操作，也會產生對應的 curl 指令，讓碼農們可以在任何的主機上重複。這樣，那麼是沒有太多解釋的說明文檔也可以使用。</p>
<p>做法很簡單，在pom.xml中加入依賴。</p>
<pre><code class="language-xml">    &lt;dependency&gt;
        &lt;groupId&gt;org.springdoc&lt;/groupId&gt;
        &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt;
        &lt;version&gt;2.8.8&lt;/version&gt;
    &lt;/dependency&gt;
</code></pre>
<p>然後我們就可以加入Controller，運行 Spring 後，我們可以在 <a href="http://localhost:8080/swagger-ui/index.html">http://localhost:8080/swagger-ui/index.html</a> 找到 swagger 的頁面，然後就可以在 ui 上測試API了。</p>
<h3 id="躲在proxy背後的-swagger"><a class="header" href="#躲在proxy背後的-swagger">躲在Proxy背後的 swagger</a></h3>
<p>如果你跟筆者一樣，使用 code-server 或 github codespaces ，你就不能很隨意地連接到 8080 端口，只能經過Http Proxy去訪問。這樣 open api的原有的設定就不合用了。</p>
<p>這時我們需要自行修改 open api 的 bean，加入我們真正的根路徑。然後筆者使用 code-server，而IDE只會在port 9000上執行，它對外的前置路徑會是 <a href="http://localhost:9000/proxy/8080/">http://localhost:9000/proxy/8080/</a>。</p>
<pre><code class="language-java">@Bean
public OpenAPI customOpenAPI() {
    Server server = new Server();
    server.setUrl("http://localhost:9000/proxy/8080/");
    return new OpenAPI().servers(List.of(server));
}
</code></pre>
<p>現在訪問 <a href="http://localhost:9000/proxy/8080/swagger-ui/index.html">http://localhost:9000/proxy/8080/swagger-ui/index.html</a>，還是會有一些問題，你會看到 “Failed to load remote configuration.” 。但你此時可以在 “explore” 搜尋欄位內貼上 <a href="http://localhost:9000/proxy/8080/v3/api-docs">http://localhost:9000/proxy/8080/v3/api-docs</a>，再一次搜尋檔案，就回復正常了。</p>
<p>註：如果你熟習Nginx這類Reverse Proxy 的概念，你的環境可以直接修改 Request Header，可以在Proxy中加入X-Forwarded-*，就不用煩惱寫Java Bean了，也不用手動在explore裏重新修正api-docs的位置。詳見 <a href="https://springdoc.org/index.html#how-can-i-deploy-springdoc-openapi-starter-webmvc-ui-behind-a-reverse-proxy">https://springdoc.org/index.html#how-can-i-deploy-springdoc-openapi-starter-webmvc-ui-behind-a-reverse-proxy
</a></p>
<h3 id="controller的繼承"><a class="header" href="#controller的繼承">Controller的繼承</a></h3>
<p>Spring Controller的 @ 標記 (Annotation) ，其實支援繼承的。經Spring 生成的 api docs，也有如何效果。例如以下程式碼</p>
<pre><code class="language-java">public class ParentController {
    @GetMapping("/postfix")
    public String postfix(){
        return "this is postfix";
    }
}

@RestController
@RequestMapping("/api")
public class ChildController extends ParentController {
    @GetMapping("/direct")
    public String directCall() {
        return "direct result";
    }
}
</code></pre>
<p>在ChildController的實例中，它會有兩個API，分別是</p>
<ul>
<li>/api/direct</li>
<li>/api/prefix</li>
</ul>
<p>它支援Java Function Overwrite（覆寫），但不能改 @ 標記，以下就是一個錯的例子</p>
<pre><code class="language-java">@RestController
@RequestMapping("/api")
public class ChildController extends ParentController {
    @GetMapping("/Overwrite") // 把這個 @ 行刪了才能正常執行
    public String postfix(){
        return "this is Overwrite";
    }
}
</code></pre>
<h2 id="source-code-5"><a class="header" href="#source-code-5">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-doc">spring boot web api doc</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-07---spring-boot-web-加入限制"><a class="header" href="#spring-boot-07---spring-boot-web-加入限制">Spring Boot 07 - Spring Boot Web 加入限制</a></h1>
<p>我們在實作伺服器的Web API時，有時候會假設某些值必需要存在。但作為伺服器，其實並不保證你的客戶端會好好地填入所有參數。不想每次在寫 API 時，都自己檢查一遍每個參數是否有空值，就試用一下 validation-api 吧</p>
<h2 id="在pomxml中加入依賴"><a class="header" href="#在pomxml中加入依賴">在pom.xml中加入依賴</a></h2>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;jakarta.validation&lt;/groupId&gt;
    &lt;artifactId&gt;jakarta.validation-api&lt;/artifactId&gt;
    &lt;version&gt;3.1.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>然後就可以在必要的欄位加入標記 (@Annotation) ，例如我們定義 FirstLevel 中某些欄位不能為空 (@NotNull, @NotEmpty)。 FirstLevel 中的 secondLevel 則層遞去做檢查 (@Valid)。</p>
<pre><code class="language-java">import jakarta.validation.Valid;
import jakarta.validation.constraints.NotEmpty;
import jakarta.validation.constraints.NotNull;

public class FirstLevel {
    @NotNull
    @NotEmpty
    private String nonNullString;
    @Valid
    private SecondLevel secondLevel;
}
</code></pre>
<pre><code class="language-java">import jakarta.validation.constraints.NotEmpty;
import jakarta.validation.constraints.NotNull;
public class SecondLevel {
    @NotNull
    @NotEmpty
    private String nonNullString;
}
</code></pre>
<p>定義好後，在每個接觸到 First Level, Second Level 參數的地方，都加入 @Valid 字眼。</p>
<pre><code class="language-java">@RestController
public class RequestController {
    @PostMapping("/api/postSomething")
    public Map&lt;String, Object&gt; postMethodName(
            @RequestBody @Valid FirstLevel entity) {
        return Map.of("ret", entity, "date", new Date());
    }
}
</code></pre>
<p>我們直接經 unit test 測試</p>
<pre><code class="language-java">    @Test
    void testMultiLevelValidation() throws Exception {
        // secondLevel can be all null
        String request = """
                {"nonNullString":"did you get it?"}
                    """;
        RequestBuilder requestBuilder = MockMvcRequestBuilders.post("/api/postSomething")
                .contentType(MediaType.APPLICATION_JSON)
                .content(request);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().isOk())
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret.nonNullString")
                        .value("did you get it?"))
                .andDo(MockMvcResultHandlers.print());
        // if secondLevel is existed, secondLevel.nonNullString cannot be null or blank
        request = """
                {
                    "nonNullString":"did you get it?",
                    "secondLevel":{}
                }
                """;
        requestBuilder = MockMvcRequestBuilders.post("/api/postSomething")
                .contentType(MediaType.APPLICATION_JSON)
                .content(request);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().is4xxClientError())
                .andDo(MockMvcResultHandlers.print());

        request = """
                {
                    "nonNullString":"did you get it?",
                    "secondLevel":{
                        "nonNullString":"got it"
                    }
                }
                """;
        requestBuilder = MockMvcRequestBuilders.post("/api/postSomething")
                .contentType(MediaType.APPLICATION_JSON)
                .content(request);
        this.mockMvc.perform(requestBuilder)
                .andExpect(MockMvcResultMatchers.status().isOk())
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret.nonNullString")
                        .value("did you get it?"))
                .andExpect(MockMvcResultMatchers.jsonPath("$.ret.secondLevel.nonNullString")
                        .value("got it"))
                .andDo(MockMvcResultHandlers.print());
    }
</code></pre>
<h2 id="補充"><a class="header" href="#補充">補充</a></h2>
<p>在 pom.xml 加入 validation-api，就可以 mvn compile，但要真的正在動態中加入自己檢查，就要開啟 spring-boot-starter-validation 。</p>
<h2 id="source-code-6"><a class="header" href="#source-code-6">Source Code</a></h2>
<p><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-validate">spring boot web api validate</a></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-web-api-異常處理"><a class="header" href="#spring-boot-web-api-異常處理">Spring boot web api 異常處理</a></h1>
<p>我們在編寫程式時，經常會遇到一些極端的情況，不會經過 function 的方式回傳結果。例如一個 function 原本是提供讀檔功能，但用戶傳入的並不是一個有效的檔案路徑，又或是誰路徑權限不足，無法讀取。這些不正常的結果，並不是原本 function 所協定的回傳值。那麼，我們會拋出異常 Exception ，中斷所有被呼叫中的 function ，讓上層用戶去考慮怎樣處理這個問題。</p>
<p>在 Web API 中，這些 Exception 就更常見。要求用戶傳入的參數，用戶就是有時候少了幾個。覆寫資料的時候，原本的資料已被刪除。但我們現在是經過 Web Api，不能像過去一直向上拋出異常就能通知用戶。我們需要的，是把異常轉成對應的 Http Status Code，讓用戶端可以快速識別異常的類型。</p>
<h2 id="java-異常對應-http-response-code"><a class="header" href="#java-異常對應-http-response-code">java 異常對應 Http Response Code</a></h2>
<p>其實在 spring boot web 中，要做轉譯，是很簡單的。在定義 java <code>Exception</code>的時候，若有<code>@ResponseStatus</code>，spring boot web 就會自動回應對應的 http error code。</p>
<pre><code class="language-java">@ResponseStatus(HttpStatus.FORBIDDEN)
public class CustomAuthenticationException extends RuntimeException {
    public CustomAuthenticationException() {
    }

    public CustomAuthenticationException(String message) {
        super(message);
    }
}
</code></pre>
<p>以後，任何一個地方拋出 <code>CustomAuthenticationException</code> （假設上層沒有人攔截）都會把該 Controller 的結果改為 http 403。Spring boot 也很聰明的，把異常中的 <code>message</code> 隱藏 ，免得有網安的問題。</p>
<p>若我們定義 Exception 時，沒有<code>@ResponseStatus</code>，Controller 就會變成 http 500，例如我在 controller 中拋個常見的 <code>IOException</code>，這次的結果就會變成 http 500。</p>
<pre><code class="language-java">    @GetMapping("/api/ioError")
    public String forceIOException() throws IOException {
        throw new IOException("force io error");
    }
</code></pre>
<p>如果某些時候，我們想使用 java <code>Exception</code> 中的 message 欄位作為報錯信息，讓 http 客戶端，可以通過固定的 message 檔位找到問題訊息，我們可以在<code>application.properties</code>中，加入<code>server.error.include-message=always</code>。(有些特殊情況，在開發模式時 <code>mvn spring-boot:run</code> ，已經可以見到有 Exception message，但在投産後<code>java -jar</code>又看不到。主要因為開發模式中， pom 有 optional spring-boot-devtools，會自動加入了<code>server.error.include-message=always</code>，但 mvn package 後就沒有，因為 runtime 沒有 spring-boot-devtools 的覆蓋。)</p>
<h2 id="額外處理"><a class="header" href="#額外處理">額外處理</a></h2>
<p>異常處理除了想控制 http status code 外，有時還需要做一些額外處理，例如發出通知郵件等。若想做額外處理，需要另做一個 <code>@RestControllerAdvice</code> 的類，在接到指定的 exception 時，可以轉換不同的 http code ，而且還可以執行額外 java code ，改變 http ResponseBody 。</p>
<pre><code class="language-java">@RestControllerAdvice
public class GlobalExceptionHandler {
    @ExceptionHandler(value = RuntimeException.class)
    @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)
    public Map&lt;String, Object&gt; handleRuntimeException(Exception ex) {
        return Map.of("ret", false, "anyfields", ex.getMessage());
    }
}
</code></pre>
<p>但要注意，一旦使用<code>@RestControllerAdvice</code> 後，就要考慮有沒有改變了某些預設的行為。例如上述的<code>@ExceptionHandler(value = RuntimeException.class)</code>，代表所有<code>RuntimException.class</code>的子類，都會歸由該 function 所處理。當然，你也可以多加幾個 function 來處理不同的子類。</p>
<h1 id="reference-4"><a class="header" href="#reference-4">Reference</a></h1>
<ul>
<li><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-validate">spring-boot-web-api-validate</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-08---多情境設置-maven-profile-與-applicationproperties"><a class="header" href="#spring-boot-08---多情境設置-maven-profile-與-applicationproperties">Spring Boot 08 - 多情境設置 maven profile 與 application.properties</a></h1>
<h2 id="為何要有不同的建構-profile"><a class="header" href="#為何要有不同的建構-profile">為何要有不同的建構 Profile</a></h2>
<p>Profile這一字，很難在IT技術文章中翻譯，它在Spring boot中的語意大概就是一個設定一個固定的運行環境參數合。例如我們做開發時，有些只想在開發環境中出現的設定，諸如測試用的資料庫、細緻一點的LOG層級，都寫在dev profile中。當換成正式環境時，我們也有一套全新的配置，而且會集中寫在prod profile中。把這些參數設定從程式碼邏輯中抽離，可以讓你的程式碼簡潔很多，也方便對比不同環境的設定。</p>
<h3 id="applicationproperties"><a class="header" href="#applicationproperties">application.properties</a></h3>
<p>Spring Boot (Spring Boot Starter) 就提供了 Profile 管理。我們可以為一個Spring Boot 模組設定多個不同的 application.properties</p>
<ul>
<li>src/main/resources/application.properties 為預設 (default profile)</li>
<li>src/main/resources/application-uat.properties 為驗收環境專用</li>
<li>src/main/resources/application-prod.properties 為投產環境專用</li>
<li>src/main/resources/application-test.properties 為自動測試專用</li>
</ul>
<p>在執行程式時，我們只要動改變啟動的參數<code>spring.profiles.active</code>，例如</p>
<pre><code>mvn spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=uat"
# or
mvn package &amp;&amp; java -jar target/YOUR_JAR_NAME --spring.profiles.active=uat
</code></pre>
<p>Spring Boot 就會指定載入 application-uat.properties 的內容，如果有些值沒有定義，它會再追溯到預設的 application.properties中。</p>
<p>在運行中改變啟動參數的情況可能不多，筆者更常用的情況是在編譯期間產生多個 Jar 檔，不同 Jar 檔指定不同的環境，方便系統管理員取用測試。想做到這個效果，我們需要在 application.properties 中，我們還需要加入一句<code>spring.profiles.active=@active.profile@</code>，並在編譯工具中加入這個變量，例如筆者常用的 maven pom.xml 中，就會有這一串設定</p>
<pre><code>    &lt;profiles&gt;
		&lt;profile&gt;
			&lt;id&gt;dev&lt;/id&gt;
			&lt;properties&gt;
				&lt;active.profile&gt;dev&lt;/active.profile&gt;
			&lt;/properties&gt;
			&lt;activation&gt;
				&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
			&lt;/activation&gt;
		&lt;/profile&gt;
		&lt;profile&gt;
			&lt;id&gt;uat&lt;/id&gt;
			&lt;properties&gt;
				&lt;active.profile&gt;uat&lt;/active.profile&gt;
			&lt;/properties&gt;
		&lt;/profile&gt;
	&lt;/profiles&gt;
</code></pre>
<p>它在 maven clean compile package 時，就已經可以在JAR中填入固定spring.profiles.active。那麼每次執行時，都會是指定的profile。</p>
<pre><code>mvn package -Puat
java -jar target/YOUR_JAR_NAME
</code></pre>
<p>在這個例子中，JAR 中的 spring.profiles.active 就會固定是uat，我們不需要在啟動參數中加入字眼。</p>
<p>如果大家不會碰到混合Profile的話，其實上述的資訊已經足夠大家應付很多情境。</p>
<p>但當大家有追求，需要寫自動測試，有機會不同自動測試需要啟用不同的 Profile ，更有可能出現混合Profile的情況，這件事就變得很複雜。我們需要繼續深入了解一下 Spring Boot 的覆蓋機制，下面將會以測試方式導出結論。</p>
<p>如果真的對混合 Profile 沒有太多信心，我們也可以用單一 Profile 重組不同 properties 的方式，自行去模擬混合 Profile ，例如除了dev, uat, test之外，我們可以加入 dev-test, uat-test, default-test 作為驅分。這樣應該可以簡化測試的複雜度，不過 properties 檔案就可能會成幾何級成長。</p>
<p>但在某情特殊情況下，我們不可能簡單地重組 properties 等型式去做測試，例如針對部份uat-test的測試，只有部份可以執行，部份不可以，那麼我們還是需要用到混合 Profile ，限定某些測試需要執個某個 profile ，但其餘部份可以動態切換。接下來，就試試看混合 Profile 的使用效果吧。</p>
<h2 id="混合-profile"><a class="header" href="#混合-profile">混合 Profile</a></h2>
<p>在開始之前，筆者總結一下前述的 Profile 的要點。</p>
<ul>
<li>Spring boot 是經過 <code>spring.profiles.active</code> 去選擇什麼 (spring boot) Profile 生效</li>
<li><code>spring.profiles.active</code> 它可以在runtime(運行時)動態更改</li>
<li>maven 是經過 xml 去選擇編譯時的 (maven) profile</li>
<li>maven 編譯時為 <code>spring.profiles.active</code> 填入一個固定值</li>
</ul>
<p>另外，筆者亦在測試途中，發現一個現像。 maven 並不提供混合 profile，即使下指令同時觸發兩個 profile ，最後亦只有一個 maven profile 生效。但這個部份筆者未在官方文件中找到，大家如果有任何發現，可以幫忙修正。</p>
<h3 id="spring-boot-混合-profile"><a class="header" href="#spring-boot-混合-profile">Spring boot 混合 Profile</a></h3>
<p>當我們經IDE編譯時，可以為 <code>spring.profiles.active</code> 填入多個值，各值之間用逗號分隔，就可以觸發多個 profile 。</p>
<ul>
<li><code>spring.profiles.active=dev,uat</code></li>
<li>程式碼中的<code>application.properties</code>, <code>application-dev.properties</code>, <code>application-uat.properties</code> 都會生效</li>
<li>Spring boot會先後載入上述三個檔案，如果有重複值，後面出現的會覆蓋前面的值。</li>
</ul>
<p><code>spring.profiles.active</code>如果填入的值與現在的application-xxx.properties不匹配，該部份不生效，例如</p>
<ul>
<li><code>spring.profiles.active=dev,uat</code></li>
<li>程式碼中只有<code>application.properties</code>, <code>application-dev.properties</code>，但沒有<code>application-uat.properties</code></li>
<li>Spring boot會先後載入上述兩個檔案</li>
</ul>
<p>上述的都好理解，當大家都接受上面的結論後，再來看這個現像。</p>
<ul>
<li><code>spring.profiles.active</code> 是啟動spring boot時，作為選擇profile的依據。</li>
<li><code>application.properties</code>可以有一個預設的<code>spring.profiles.active</code>，正常跑spring boot就會看它。</li>
<li>正常跑spring boot時，還可以通過傳入參數<code>--spring.profiles.active=xx</code>，改變那個值。</li>
<li>Spring boot test 因為結構特殊，它只會看到 <code>application.properties</code> 中的那個<code>spring.profiles.active</code>值。</li>
<li>Spring boot test 暫時沒有方法傳入參數<code>spring.profiles.active</code>，但可以經程式碼 @ActiveProfiles 硬改運行中的 profile 。<code>spring.profiles.active</code>亦只會顯示 <code>application.properties</code>中的那個值。</li>
</ul>
<h3 id="spring-boot-混合-profile-例子"><a class="header" href="#spring-boot-混合-profile-例子">Spring boot 混合 Profile 例子</a></h3>
<p>大家看完概念之後，可以來看看實際例子。</p>
<p>當什麼都不加，就是根據<code>application.properties</code>的<code>spring.profiles.active</code>來啟動profile。</p>
<pre><code class="language-bash">mvn clean compile spring-boot:run
# or
mvn clean compile package
java -jar target/spring-boot-profile-0.0.1-SNAPSHOT.jar
</code></pre>
<p>正常spring-boot:run的情況下，可以經的 <code>--spring.profiles.active</code> 覆蓋過<code>application.properties</code>內的值。</p>
<pre><code class="language-bash">mvn clean compile spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=dev --spring.profiles.active=uat"
mvn clean compile spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=dev,uat"
# or
mvn clean compile package
java -jar target/spring-boot-profile-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev --spring.profiles.active=uat
java -jar target/spring-boot-profile-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev,uat
</code></pre>
<p>上述例子，若dev，uat內的值沒有衝突，沒有覆蓋問題。但如果有衝突，最後會是uat內定義的值。</p>
<h3 id="spring-boot-test-profile-例子"><a class="header" href="#spring-boot-test-profile-例子">Spring boot test Profile 例子</a></h3>
<p>因為不是正常spring-boot:run，所以那些參數都沒有用，具體只會看<code>application.properties</code>內預設<code>spring.profiles.active</code></p>
<pre><code class="language-bash">mvn clean compile test -Dspring-boot.run.arguments="--spring.profiles.active=dev,uat"
# arguments will be ignored, same as
mvn clean compile test
</code></pre>
<h3 id="maven-profile-例子"><a class="header" href="#maven-profile-例子">Maven Profile 例子</a></h3>
<p>加入Maven之後，就可以修改<code>application.properties</code>內的預設<code>spring.profiles.active</code>。但要注意，maven只會有單profile</p>
<p>假設pom.xml如下</p>
<pre><code class="language-xml">	&lt;profiles&gt;
		&lt;profile&gt;
			&lt;id&gt;dev&lt;/id&gt;
			&lt;properties&gt;
				&lt;active.profile&gt;dev&lt;/active.profile&gt;
			&lt;/properties&gt;
			&lt;activation&gt;
				&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
			&lt;/activation&gt;
		&lt;/profile&gt;
		&lt;profile&gt;
			&lt;id&gt;uat&lt;/id&gt;
			&lt;properties&gt;
				&lt;active.profile&gt;uat&lt;/active.profile&gt;
			&lt;/properties&gt;
			&lt;activation&gt;
				&lt;property&gt;
					&lt;name&gt;ci&lt;/name&gt;
					&lt;value&gt;true&lt;/value&gt;
				&lt;/property&gt;
			&lt;/activation&gt;
		&lt;/profile&gt;
	&lt;/profiles&gt;
</code></pre>
<p>application.properties如下</p>
<pre><code>spring.profiles.active=@active.profile@
</code></pre>
<p>下述三組例子，有且只有uat生效。因為maven的uat生效後，會修改</p>
<pre><code class="language-bash">mvn clean compile spring-boot:run -Puat
# or
mvn clean compile package -Pdev -Dci=true
java -jar target/spring-boot-profile-0.0.1-SNAPSHOT.jar
# or
mvn clean compile test -Puat
</code></pre>
<p>當然，你想要弄一個maven mix profile 也可以</p>
<pre><code class="language-xml">	&lt;profile&gt;
		&lt;id&gt;mix&lt;/id&gt;
		&lt;properties&gt;
			&lt;active.profile&gt;dev,uat&lt;/active.profile&gt;
		&lt;/properties&gt;
	&lt;/profile&gt;
</code></pre>
<p>以下例子可以令 dev, uat 同時出現在<code>spring.profiles.active</code></p>
<pre><code class="language-bash">mvn clean compile spring-boot:run -Pmix
# or
mvn clean compile package -Pmix
java -jar target/spring-boot-profile-0.0.1-SNAPSHOT.jar
# or
mvn clean compile test -Pmix
</code></pre>
<h3 id="maven-profile-spring-boot-test例子"><a class="header" href="#maven-profile-spring-boot-test例子">Maven Profile Spring boot test例子</a></h3>
<p>上述例子都了解後，最後就來看看全部混合的情況</p>
<p>當Test case中沒有硬改 profile 定義，<code>application.properties</code>中的<code>spring.profiles.active</code>就直接作用。以下情況就是同時運行dev,uat</p>
<pre><code>// java
@SpringBootTest
class ProfileTests {
}

// bash
mvn clean compile test -Pmix
</code></pre>
<p>當Test case中有定義@ActiveProfiles ，<code>application.properties</code>中的<code>spring.profiles.active</code>的值會保留，但不在該test case中生效。以下情況就是同時運行uat,dev，但讀取spring.profiles.active的值會是dev,uat。</p>
<pre><code>// java
@SpringBootTest
@ActiveProfiles(value = { "uat", "dev" })
class MultipleProfileUatDevTests {
}

// bash
mvn clean compile test -Pmix
</code></pre>
<p>如果我們把maven 指令中的加入package，預期 test 執行的是 uat,dev 。而 jar 的打包結果會是 dev,uat。</p>
<pre><code>// java
@SpringBootTest
@ActiveProfiles(value = { "uat", "dev" })
class MultipleProfileUatDevTests {
}

// bash
mvn clean compile test package -Pmix
</code></pre>
<p>但請盡量不要這些做，因為會越來越混亂，特別是打包 prod 環境。為減少出錯的機會，例如test污染了prod的環境，筆者在package時，通常都會跳過test。</p>
<pre><code>mvn clean compile package -Pprod -Dmaven.test.skip=true
</code></pre>
<h1 id="reference-5"><a class="header" href="#reference-5">Reference</a></h1>
<ul>
<li><a href="https://docs.spring.io/spring-boot/reference/features/profiles.html">官方文件</a></li>
<li><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-profile">混合Profile Source code</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-09---多情境設置-maven-profile-與-applicationproperties"><a class="header" href="#spring-boot-09---多情境設置-maven-profile-與-applicationproperties">Spring Boot 09 - 多情境設置 maven profile 與 application.properties</a></h1>
<p>前述我們介紹了很多profile是如何運作的<a href="#spring-boot-08---多情境設置-maven-profile-與-applicationproperties">08-spring-boot-properties-profile</a>。這篇，就因應實際的運行環境，討論不同的存儲及配置方向。</p>
<p>我們先重溫一下，maven profile與spring profile的差異。</p>
<ul>
<li>Spring boot 是程式框架。Spring boot 是經過 <code>spring.profiles.active</code> 去選擇什麼 (spring boot) Profile 生效</li>
<li><code>spring.profiles.active</code> 它可以在runtime(運行時)動態更改</li>
<li>maven 是經過 xml 去選擇編譯時的 (maven) profile</li>
<li>maven 編譯時為 <code>spring.profiles.active</code> 填入一個固定值</li>
<li>Spring boot 必需經過編譯才能使用。亦即編譯時，可以填入一個值，不填即使是用預設值。</li>
</ul>
<h2 id="maven-profile-的不足"><a class="header" href="#maven-profile-的不足">maven profile 的不足</a></h2>
<p>雖然 maven 會在編譯期間填入值，但編譯出來的結果(jar或war檔），其實一切後期都被可以改動。那麼我們該使用 maven profile 來做什麼呢？</p>
<p>一般來講，筆者會期待編譯的結果，預設是可以運行的。所以早期筆者預編譯時，都會包含對應環境的所有設定，這樣用戶就不需要考慮自己如何填入設定值。這樣做特別有效的是，你的設定表是一個相對大的檔案（例如要入100行的設定），又或是你對目前的發佈平台不熟悉，難以做覆蓋值的改動。例如傳統的tomcat，筆者既不是管理員，也不熟悉它的插入機制。</p>
<p>這時 maven 在編譯時，就直接或簡接指定好 spring profile。在運行時，就不用煩惱。我們的 uat prod profile ，不需要放入 Source code Repository 中，只要 CI Server 看得到，可以在打包過程將入就好。然後就靠 CD Server 送到特定的伺服器運行。</p>
<p>但在 container 的世代來看，只使用 maven profile 是不夠的。什至是在古早的賣實體軟件的時代，也是不夠的。你的執行檔，應該有條件進行動態配置的。因為你也無法預知不同的環境的實際參數，你也不想每次更新設定都要全部編譯流程重跑一次。如果你允許動態配置，那麼在前期 CI Server 編譯中亦可以簡化一些流程，它只包含程式碼的編譯就好。在動態設定上，要麼就交給 CD Server，要麼就人手更新。</p>
<p>Spring boot 提供了自己的動態修改機制，比起傳統的純 java 程式要自己讀寫不同的檔案要來得簡單。下面的章節，我們就來介紹一下spring boot 是怎樣提供動態配置的方式。</p>
<h2 id="spring-boot-動態配置"><a class="header" href="#spring-boot-動態配置">spring boot 動態配置</a></h2>
<p>前述 <a href="#spring-boot-08---多情境設置-maven-profile-與-applicationproperties">08-spring-boot-properties-profile</a> 教學中，已有很多動態改變profile的例子，當時就假設所有的profile都放入了 jar 中。而 spring boot 其實更強大，它還可以讀到 jar 以外的 properties 檔。</p>
<p>假設 spring boot 寫程式，已經有一個打包好的 <code>web.jar</code> 檔，執行方式將會是 <code>java -jar web.jar</code>。  不論 jar 裏面的 <code>application.properties</code> 定義了什麼 <code>spring.profiles.active</code>，我們都可以在下jar指令時覆寫它。只要當前指令的工作目錄下，有那個新的 application-NEWPROFILE.properties 就好，例如</p>
<pre><code>$ tree /tmp/demo
/tmp/demo
|-- application-container.properties
`-- web.jar

$ cd /tmp/demo
$ java -jar web.jar --spring.profiles.active=container
</code></pre>
<p>只要 jar 檔裏面，沒有 <code>application-container.properties</code> 的存在就好，不然筆者也不確定是哪一個properties在作用。</p>
<p>有了這些載入方式，即使經 container 動態 bind mount, configs / secrets 也可以達到動態配置的效果。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-10---openapi自動生成-api-客戶端的步驟"><a class="header" href="#spring-boot-10---openapi自動生成-api-客戶端的步驟">Spring Boot 10 - OpenAPI自動生成 API 客戶端的步驟</a></h1>
<p>之前我們在介紹<a href="#spring-boot-06---spring-boot-web-調試工具">Spring Boot Web 調試工具</a> ，就試安裝 openapi 相關的元件。其實 openapi 並不單是為了提供 swagger 測試介面，它主要是提供一個描述的方式，讓我們針對一個特定 openapi 文件，生成對應的 api server 或 api client 接口。也就是，如果 server 方有提供該文件，道理上可以經 openapi 的工具，生成一個可以直接訪問 server 的 client library。本節，可以沿用之前的 <a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-doc">spring boot web api doc</a> ，為它產生一個client library 作為實驗。</p>
<p>在生成 client library 之前，我們還需要一個工具 openapi-generator-cli 。最簡單的取得方式，就是經過 npm ， 在你需要生成 client library 的專案中，安裝你需要的 openapi-generator-cli 版本。</p>
<pre><code class="language-bash">npm install @openapitools/openapi-generator-cli
</code></pre>
<p>那怕你不是使用 nodejs 作為開發，也可以經過這個方法安裝。它只提供使用 cmd 指令的捷徑。</p>
<h1 id="生成-java-client-library"><a class="header" href="#生成-java-client-library">生成 Java Client Library</a></h1>
<p>我們先把 backend server 起好 <code>cd somewhere &amp;&amp; mvn spring-boot:run</code>，然後使用 openapi-generator-cli 去生成以 java spring boot 3 為底的 client library 。</p>
<pre><code class="language-bash">npx openapi-generator-cli generate \
  -i http://localhost:8080/v3/api-docs \
  --api-package io.github.macauyeah.springboot.tutorial.openapiclient.api \
  --model-package io.github.macauyeah.springboot.tutorial.openapiclient.model \
  --invoker-package io.github.macauyeah.springboot.tutorial.openapiclient.invoker \
  --group-id io.github.macauyeah.springboot.tutorial \
  --artifact-id spring-boot-web-api-open-api-client \
  --artifact-version 0.0.1-SNAPSHOT \
  -g java \
  -p useJakartaEe=true \
  -p useSpringBoot3=true \
  --library webclient \
  -o spring-boot-web-api-open-api-client
</code></pre>
<p>生成的 source code 就像是 <a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-open-api-client">spring-boot-web-api-open-api-client</a> ，具體的使用方式，可以看看測試用例 <a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-open-api-client/src/test/java/io/github/macauyeah/springboot/tutorial/openapiclient/api/ApiControllerApiTest.java">ApiControllerApiTest.java</a></p>
<pre><code class="language-java">    private final ApiControllerApi api = new ApiControllerApi();
    @Test
    public void postDateQueryTest() {
        // default call
        ApiDateRequest apiDateRequest = new ApiDateRequest();
        apiDateRequest.setInputDate(OffsetDateTime.now());
        LOG.debug("default web client postDateQuery:{}", api.postDateQuery(apiDateRequest).block());

        // replace webClient in ApiClient if you have special auth config on
        // webClient, you can also change basePath during new obj creation
        ObjectMapper mapper = new ObjectMapper();
        mapper.setDateFormat(new SimpleDateFormat());
        mapper.registerModule(new JavaTimeModule());
        WebClient webClient = WebClient.builder()
                .codecs(configurer -&gt; {
                    configurer.defaultCodecs().jackson2JsonDecoder(new Jackson2JsonDecoder(mapper));
                    configurer.defaultCodecs().jackson2JsonEncoder(new Jackson2JsonEncoder(mapper));
                })
                .build();

        ApiControllerApi api2 = new ApiControllerApi(
                new ApiClient(webClient)
                        .setBasePath("http://localhost:8080/"));
        LOG.debug("create api2 by local web client postDateQuery:{}", api2.postDateQuery(apiDateRequest).block());

        // use webClient directly
        String response = webClient.post().uri("http://localhost:8080/api/record").bodyValue(apiDateRequest).retrieve()
                .bodyToMono(String.class).block();
        LOG.debug("request by local web client postDateQuery:{}", response);
    }
</code></pre>
<p>上述例子中，如果大家沒有任何特殊要求，其實經過 <code>api.postDateQuery(apiDateRequest).block()</code> 就完成了。有需要改 api endpoint 的，只要生成新的 ApiClient 並設定 basePath <code>new ApiClient().setBasePath("XXXXXX")</code> 就好。真的要加入更多權限設定，就需要生成新的 ApiClient 並設定 webClient <code>new ApiClient(webClient)</code></p>
<p>這個生成的 Java Client Library 道理上還是要經過 maven 等打包，變成 jar 檔，才能被其他 Java 專案所引用。筆者就建議大家直接把成生的視為獨立的 module (sub module) 存放，其他專案就以 maven dependency 的方式引用。想要混合現有專案，動態生成專案內某些 java package，暫時不太可行。因為它也有大量的 dependency ，交由 openapi-generator-cli 自己管理會比較好，它們升級時，你也可以完整升級。</p>
<h1 id="reference-6"><a class="header" href="#reference-6">Reference</a></h1>
<ul>
<li><a href="https://github.com/OpenAPITools/openapi-generator-cli">openapi-generator-cli https://github.com/OpenAPITools/openapi-generator-cli</a></li>
<li><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-web-api-open-api-client">spring-boot-web-api-open-api-client</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="web-app-更新期間的維護模式從唯讀到全鎖的解決方案"><a class="header" href="#web-app-更新期間的維護模式從唯讀到全鎖的解決方案">Web App 更新期間的維護模式：從唯讀到全鎖的解決方案</a></h1>
<p>在營運 Web App 的時候，雖然我們有 Docker / K8s 可以滾動更新，但難保用戶在更新的過程中，有一半訪問去到了舊版，另一半去了新版。如果可以，Web App 本身自帶維護模式，可以自我判斷什麼時候應該忽略新的訪問，當然最好。但要做到這一點，前期需要很多規劃。狠心一點，可以直接關掉對外的服務，讓用戶無法訪問。</p>
<p>但在另一些情況下，例如升級/搬遷的情況，下線時間比較長，完全關掉服務並不是一個很好的方向，我們至少還可以提供唯讀的選擇。而且這個可以從資料庫出發，讓 Web App 少處理一點邏輯。</p>
<p>如果 Web App 背後的資料庫是 MSSQL 或 MySQL，唯讀這件事應該是簡單的，只要你把 service account 的權限改變就好。但如果你用Oracle，就要想想辦法。</p>
<p>筆者想到的方法，暫時有兩個。第一個就需要大家寫寫 Script ，一口氣把所有 Table 給鎖起來。例如:</p>
<pre><code class="language-sql">-- to read only
BEGIN
  FOR t IN (SELECT table_name FROM user_tables) LOOP
    EXECUTE IMMEDIATE 'ALTER TABLE ' || t.table_name || ' READ ONLY';
    DBMS_OUTPUT.PUT_LINE('Table ' || t.table_name || ' set to READ ONLY.');
  END LOOP;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('Error: ' || SQLERRM);
END;

-- to read write
BEGIN
  FOR t IN (SELECT table_name FROM user_tables) LOOP
    EXECUTE IMMEDIATE 'ALTER TABLE ' || t.table_name || ' READ WRITE';
    DBMS_OUTPUT.PUT_LINE('Table ' || t.table_name || ' set to READ WRITE.');
  END LOOP;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('Error: ' || SQLERRM);
END;
</code></pre>
<p>第二個，就是生成一個新的唯讀 User schema，給他所有Select的權限。然後更新 Web App 使用那個唯讀 User schema存取資料。</p>
<pre><code class="language-sql">-- grant select
BEGIN
  FOR t IN (SELECT table_name FROM user_tables) LOOP
    EXECUTE IMMEDIATE 'grant select on ' || t.table_name || ' to READ_ONLY_USER';
  END LOOP;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('Error: ' || SQLERRM);
END;

-- revoke select
BEGIN
  FOR t IN (SELECT table_name FROM user_tables) LOOP
    EXECUTE IMMEDIATE 'revoke select on ' || t.table_name || ' to READ_ONLY_USER';
  END LOOP;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('Error: ' || SQLERRM);
END;
</code></pre>
<p>兩個方法有什麼差異呢？ 前者就全部鎖起來，沒有任何一個資料庫用戶可以改寫資料。如果你的業務沒有差異性，全部一起封起來就完事。但如果你只想 Web App 轉成唯讀，但其他背景程式還可以執行更新。那你就只能用後者了。但後著也不是百分百的完全無痛，至少你 Web App 要支援登入與操作的 Schema分離。</p>
<p>例如用Spring boot JPA的話，可以在 application.properties 可以讓登入及操作的Schema不一樣。</p>
<pre><code>spring.datasource.username=READ_ONLY_USER
spring.jpa.properties.hibernate.default_schema=ORIGINAL_SCHEMA
</code></pre>
<p>又或者在 java 層面指定。</p>
<pre><code class="language-java">@Table(schema = "ORIGINAL_SCHEMA")
</code></pre>
<p>這看上去，是很有彈性的。但其實也是有些局限。如果你本來的JPA有寫特制的 JPQL 或 Raw Query，又或者你在Java層面加了 <code>@Subselect</code>，由於這些都是程式原作者所 hard code 的，JPA沒法幫你改寫。改來改去，可能還是前述寫Script的方法，一口氣把所有 Table 給鎖起來實際一些。</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-data-關聯型態-一對多-多對一"><a class="header" href="#spring-data-關聯型態-一對多-多對一">Spring Data 關聯型態 一對多 多對一</a></h1>
<p>筆者身邊的朋友，首次接觸 ORM 的關聯型態時都會覺得很難，筆者自己也是。但在好好地理順它的設計時，就會覺得其實很簡單。</p>
<h2 id="雙向存取"><a class="header" href="#雙向存取">雙向存取</a></h2>
<p>這節，我們先以Code First的角度，先體驗一下程式部份的設計意向。</p>
<p>例如一個Parent，有好幾個Child</p>
<pre><code class="language-java">@Entity
public class Parent {
    // ... Parent Primay Key
    @OneToMany(mappedBy="parent")
    List&lt;Child&gt; children = new ArrayList&lt;&gt;();
    // TODO add remove
}

@Entity
public class Child {
    // ... Child Primay Key
    @ManyToOne
    Parent parent;
}

</code></pre>
<p>上述的寫法很簡潔，ORM會為你自動加入join column，處理關聯的載入。在讀取Parent時，它的所有Children就可以直接在Java層面讀取，在讀取Child時，它的Parent也隨時取得。也就是，開發人員只要經SQL準備其中一方的資料，另一方並不需要手動準備，它就可以自動按需載入。</p>
<h2 id="restful-api-坑-雙向存取"><a class="header" href="#restful-api-坑-雙向存取">RESTFul API 坑-雙向存取</a></h2>
<p>Spring Data在Java層面的雙向存取，已經做到很方便。但經常坑到我們的是Spring Data與RESTFul API的混合應用。當我們嘗試經API回傳我們的Parent Json時，API會很聰明地把關聯的Children也變成Json回傳。但他也會把child中的parent不斷重複變成json，變成無限輪迴。</p>
<p>坊間有兩種不同的解決方案，可以防止無限輪迴。</p>
<ul>
<li>讓Json可以認得已經序列化的元素。@JsonIdentityInfo</li>
<li>讓Json只可以單向序列化(serialization)。@JsonManagedReference, @JsonBackReference, @JsonIgnore</li>
</ul>
<p>筆者兩個方向都試過，但首個方法並不通用，至少它不能算是一般常見的無腦Json結構。它需要伺服器、客戶端都懂這如何經IdentityInfo認得重複出現的元素。</p>
<p>而單向序列化，是筆者現時的通用解。在設計RESTFul READ API時，筆者就會決定到底是Parent自動回傳Child，還是Child自動回傳Parent。決策的考慮因素，主要在於是否可以簡化Client的API調用次數。通常從Parent出發，自動回傳Child，可以節省API調用。但如果是選項性的結果(List of Value)，就倒過來。有時候，遇著API需要雙向設計，就只好自己設計DTO資料傳輸對象 (Data transfer object, DTO)。</p>
<p>例如Parent API，就原封不動回傳原本的元素</p>
<pre><code class="language-java">@Entity
public class Parent {
    // ... Parent Primay Key
    @OneToMany(mappedBy="parent")
    List&lt;Child&gt; children = new ArrayList&lt;&gt;();
}

@Entity
public class Child {
    // ... Child Primay Key
    @ManyToOne
    @JsonIgnore
    Parent parent;
}

</code></pre>
<p>Child API，就反過來引用。</p>
<pre><code class="language-java">public class ParentDTO {
    // ... Parent Other fields except children
}

public class ChildDTO {
    ParentDTO parent;
    // ... Child Other fields
}

</code></pre>
<p>這種DTO，看起來很麻煩。但其實Spring有提供一個簡便的複制DTO功能，它可以把自動複制兩個class中有同一名稱、同一型別的欄位到另一個class上，不需要逐個欄位明文寫出來。</p>
<pre><code class="language-java">BeanUtils.copy(child, childDTO);
BeanUtils.copy(parent, parentDTO);
childDTO.setParent(parentDTO)
// 因為child、childDTO中的parent欄位型別不同，BeanUtils.copy會自動忽略，其他欄位就會自動複制。
</code></pre>
<p>註: 其實古早的網頁系統設計，DTO的概念一直存取。只是現在RESTFul API的流行，很多框架已經提向便捷的Json轉換。若然平時只需Json單向存取，筆者還是省略DTO的建立。</p>
<h2 id="presist-and-casecade"><a class="header" href="#presist-and-casecade">Presist and Casecade</a></h2>
<p>前述講了一些最基本的關聯概念，但當要正式儲存或刪除，就有些考慮完整性問題。平常我們在處理資料庫的關聯表格時，也需要面Foreign Key的正確性問題。同樣地，Spring Data也有這方面的考量，但它有提份一個很方便的CascadeType選項，可以簡化一些流程。</p>
<p>假設你只能存取Parent Repo，那你需要在Parent中，加入CascadeType.All。當repo.save(parent)時，它就會順多把所有child的也一併進行Save，你也不需要有Child Repo的存在。</p>
<pre><code class="language-java">@OneToMany(mappedBy="parent", cascade = CascadeType.All)
List&lt;Child&gt; children = new ArrayList&lt;&gt;();
</code></pre>
<p>但在複雜的狀況下，例如你不想在更新parent的情況下，不小心弄到child，特別是經過public web下的API操作，你對web client的資料正確性有存疑，就不要使用CascadeType了。這也是筆者認為在大多數情況下，我們都會把Parent和Child的CRUD分開操作，然後根據需要使用各自的repo save。</p>
<p>如果你一定要用CascadeType.ALL (CascadeType.REMOVE)，就要再留意刪除的問題。為什麼？因為刪除 parent，其實指的是某個parent不再存在，但不代表child也要一起刪除，child的parent連結可以變為null，也有重新連結其他parent的可能。</p>
<p>如果大家確定需要共同刪除，就可以用CascadeType.ALL 或 CascadeType.REMOVE。</p>
<p>還有一個新的選擇，orphanRemoval = true，也有類似效果。</p>
<pre><code class="language-java">@OneToMany(mappedBy="parent", cascade = CascadeType.REMOVE)
List&lt;Child&gt; children = new ArrayList&lt;&gt;();
// or
@OneToMany(mappedBy="parent", orphanRemoval = true)
List&lt;Child&gt; children = new ArrayList&lt;&gt;();
// or
@OneToMany(mappedBy="parent", cascade = CascadeType.REMOVE, orphanRemoval = true)
List&lt;Child&gt; children = new ArrayList&lt;&gt;();
</code></pre>
<p>筆者測試過，混著用也是可以的。若大家看過其他教程，可能會覺得orphanRemoval = true 和 CascadeType 總是一起出現，但它們其實是分別操作的。單獨使用orphanRemoval = true，有時候則是為了不會出現無主的child，但這不代表parent和child的想要同步更新。</p>
<h1 id="jpa-entity-的生命週期"><a class="header" href="#jpa-entity-的生命週期">JPA Entity 的生命週期</a></h1>
<p>Spring Data跟傳統的資料庫Selete，Create，Update，Delete SQL 語句有所不同。也就是這個不同，它的CascadeType比資料庫的Cascade Update和Cascade Delete更強大。</p>
<p>Spring Data 預設其實是使用 jakarta.persistence.EntityManager，每個Entity主要分為四個狀態</p>
<ul>
<li>Transient / New - 不在EntityManager的掌控中</li>
<li>Managed - 在EntityManager的掌控中，將會在下次flush時，變成sql create或update statement</li>
<li>Detached - 脫離EntityManager的掌控，不受flush影響</li>
<li>Removed - 在EntityManager的掌控中，將會在下次flush時，變成sql delete statement</li>
</ul>
<p>在Spring Data / Jpa 以前，我們若要直接操作Hibernate，經常見到persist, remove的寫法</p>
<pre><code class="language-java">entityManager.persist(entity);
entityManager.remove(entity);

entityManager.detach(entity);
entityManager.merge(entity);
</code></pre>
<p>其實persist就是把處於Transient、Removed的entity，改為Managed。而remove就是把Managed改為Removed。detach，merge也類似，就是Managed，Detached之間互換。</p>
<p>EntityManager最強大的是，它可以讓程序員不需要再為Managed狀態下的entity操心，它會自動判別下次flush，應該create還是update，如果完全沒有改動的，連update也不會執行。</p>
<p>(註，flush和commit也有不同，flush就是從java寫到資料庫中，在資料庫commit前，還可以使用rollback放棄。)</p>
<p>而Spring Data，則是進一步簡化，它把persist改為save，remove改為delete，然後自動選擇flush的時機。</p>
<h2 id="cascadetype"><a class="header" href="#cascadetype">CascadeType</a></h2>
<p>在解釋完Entity 的生命週期後，終於可以回到CascadeType了。這裏的CascadeType不是資料庫的Cascade操作，其實它是指EntityManager的狀態操作是否有傳遞關係。亦即是，persist(parent)時，要不要連同child也一起操作?</p>
<p>我們查看 CasecadeType 的原始碼，就可以發現可以被傳遞的操作共有以下這些</p>
<ul>
<li>PERSIST</li>
<li>MERGE</li>
<li>REMOVE</li>
<li>REFRESH</li>
<li>DETACH</li>
<li>ALL (以上全部)</li>
</ul>
<p>這裏的 CasecadeType.PERSIST ，跟資料庫的 Cascade Update 是不一樣的。資料庫裏的 Cascade Update，是指當 Parent 的 Primary Key 有變，對應child的 Foreign Key也一起變。但因為 JPA Entity 的機制， Parent 的 Primary Key 不可以改變，理論上不會發生類似資料庫的 Cascade Update，頂多有 Cascade Delete。 CasecadeType.PERSIST 就像之前述的生命週期解說一樣， 把 parent和 child 一起拉到受管理的狀態。</p>
<p>CascadeType.REMOVE 也類似，但在使用時要更加留意。因為有時 parent, child 做關聯時，會偷懶只在child 更新。這樣若在同一個 transaction 內進行 delete，就會出事。</p>
<pre><code class="language-java">@Entity
public class Author {
    // other attribute
    // ...

    @OneToMany(mappedBy = "author", cascade = CascadeType.REMOVE)
    private List&lt;Book&gt; books = new ArrayList&lt;&gt;();

    public void addBook(Book book){
        this.books.add(book);
        book.setAuthor(this);
    }

    public void removeBook(Book book){
        this.books.remove(book);
        book.setAuthor(null);
    }
}

@Entity
public class Book {
    // other attribute
    // ...

    @ManyToOne
    private Author author;

    // auther getter setter
    // ...
}

@Test
void testdelete() {
    Author author = new Author();
    Book book = new Book();
    book.setAuthor(author);

    // save author and book
    assertThrows(org.springframework.dao.InvalidDataAccessApiUsageException.class, () -&gt; {
        authorRepo.delete(author);
    });
    
    author.addBook(book);
    authorRepo.delete(author);
}
</code></pre>
<p><code>@OneToMany</code> 需要配合 collection add remove 一起使用（<code>this.books.add(book);</code>），不能只做一邊(<code>book.setAuthor(author);</code>)，不然就會出現<code>InvalidDataAccessApiUsageException</code>。這似乎和 hiberate 的狀態有關，只有經過 collection add remove ，hibernate proxy 才會正確反映未來的 db 狀況。特別在某些時候，例如是記有 <code>@Transactional</code> 時，hibernate 似乎不會每次都會真的訪問 db ，如果要準確關聯狀態，就要經過 collection add remove 去更新 proxy。 <code>CascadeType.REMOVE</code>, <code>orphanRemoval = true</code> 在 collection add remove 都有相同效果。</p>
<h1 id="reference-7"><a class="header" href="#reference-7">Reference</a></h1>
<ul>
<li><a href="https://thorben-janssen.com/entity-lifecycle-model/">entity-lifecycle-model</a></li>
<li><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-data-deletion">demo repo: spring boot data deletion</a></li>
<li><a href="https://github.com/macauyeah/spring-boot-demo/tree/main/spring-boot-tutorial/spring-boot-data-advance/src/test/java/io/github/macauyeah/springboot/tutorial/spring_boot_data_advance/OneToManyRefreshStatusTests.java">demo code: OneToManyRefreshStatusTests</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="你開始寫-spring-boot-測試案例了嗎"><a class="header" href="#你開始寫-spring-boot-測試案例了嗎">你開始寫 Spring Boot 測試案例了嗎？</a></h1>
<p>雖然筆者過往做 spring boot framework 教學中，都有滲入一些測試用例。筆者也曾經困惑了很長一段時間，所以就獨立開一個主題，聊一下筆者在實務上對spring boot test 的理解。</p>
<h2 id="測試案例究竟測試什麼"><a class="header" href="#測試案例究竟測試什麼">測試案例究竟測試什麼？</a></h2>
<p>測試用例 (test case) 是確保你的程式碼正確性與穩定性的重要步驟，但在 framework 下，並不是所有功能都很容易寫成測試。所以在討論 framework 測試之前，釐清測試的本質。</p>
<p>我們正常編寫的程式，基本流程可以概括為：</p>
<pre><code>function input → business logic → function output
</code></pre>
<p>這意味著我們輸入某些資料（input），然後經過業務邏輯（business logic）的處理，最後產生結果輸出（output）。</p>
<p>我們的測試目標，其實就是確保業務邏輯正確。而我們的手段就是經檢查概定的輸入資料，核對輸出結果。</p>
<p>那麼只要我們可以生成輸入資料，就一定可以檢查輸出結果了吧？其實不是的，因為實務上的輸入和輸出沒有這麼簡單。筆者常接觸到的輸入輸出如下</p>
<p>輸入</p>
<ol>
<li>function 輸入參數</li>
<li>系統狀態資料，例如：資料庫狀態、外部API結果。</li>
</ol>
<p>輸出</p>
<ol>
<li>function 輸出參數</li>
<li>寫入系統（影響到）的資料，例如：資料庫狀態、使用外部API時的輸入參數。</li>
</ol>
<p>總之就是考慮了狀態機 (state machine) 的問題，每個狀態+外部輸入都是一個測試用例，然後核對狀態機去了下一個什麼狀態。</p>
<p>言下之意，我們就是暴力地生成輸入參數和模擬狀態資料，道理上就是可以進行測試。</p>
<h2 id="spring-boot-web-framework-中我們又會測試什麼"><a class="header" href="#spring-boot-web-framework-中我們又會測試什麼">Spring boot web framework 中，我們又會測試什麼？</a></h2>
<p>𠩤本我們工作流程如下</p>
<pre><code>function input → business logic → function output
</code></pre>
<p>在Spring boot web就變成如下</p>
<pre><code>controller request → business logic → controller response
</code></pre>
<p>在 Spring Boot test 中，我們可以用模擬的 MVC (<code>MockMvc</code>) 測試來驗證 controller 的行為。不過，其實進入 controller 前經過很多系統轉換，而這些道理上跟Framework的技術大相關，與業務邏輯小相關。所以為免折磨自己，可以將業務邏輯單獨封裝成服務（service）。之後直接測試服務 ，易寫也易讀。</p>
<pre><code>controller request → service input → business logic → service output → controller response
</code></pre>
<p>道理上 controller 能做的業務邏輯，服務 (service) 都可以無腦重現。這樣還可以重用服務，減少測試的數量。</p>
<h3 id="如何實現輸入"><a class="header" href="#如何實現輸入">如何實現輸入？</a></h3>
<ol>
<li><strong>直接 new Object</strong>。大部份的情況下，因為業務是自己編寫的，應該都可以直接 new 出來。</li>
<li><strong>經 json 檔讀入</strong>。如果輸入的參數量太多，逐個經 java new 是很耗時的，我們可以經 json 反序列化變成 Object。但這亦只限於自己可以操作/改寫的類。</li>
<li><strong>Mockito 模擬那些無法簡易經 new 或 json 反序列化的 Object</strong>。例如：spring security authentication object 我們在使用時，其實只看到 interface。我們難似自己實現一個可以反序列化的類，那麼我們可以使用 Mockito 來模擬這些資料。一些外部API的結果，我們也可以用使 Mockito 來模擬。</li>
</ol>
<h2 id="什麼情況下不進行測試"><a class="header" href="#什麼情況下不進行測試">什麼情況下不進行測試？</a></h2>
<p>有些情況下，我們可能選擇不對某些功能進行測試，原因可能包括對功能的了解不足或是單純的懶惰。以下是一些例子：</p>
<ol>
<li>
<p><strong>僅進行配置的Function</strong>：如果你的 Function 只是在 Framework 中填寫配置，而且你並不太了解它的運作原理，可能就不需要進行測試了。例如，Spring boot web 中，需要大家配置一個<code>SecurityFilterChain</code> Object，它要求大家將 <code>HttpSecurity</code> 轉換為 <code>SecurityFilterChain</code> 。因為輸入的 <code>HttpSecurity</code> 是系統固定的參數，我們亦沒有檢查它的狀態。這種情況下，它的輸入及輸出，其實我們都沒有真正理解。我們硬測試的話，測試功能可能只流於表面。若我們真的要做測試，也是經過<code>MockMvc</code>進行端到端測試（end-to-end testing），測試它在事後的影響範圍。</p>
</li>
<li>
<p><strong>單純的框架功能</strong>：例如資料庫的儲存庫介面（repository interface），雖然是在框架下生成的，對於自己手動調整的部份功能，筆者通常亦不會進行單獨測試，通常都會搭配業務邏輯一起進行。它可以使用 Mockito 進行模擬測試，或用測試環境的真實資料庫進行測試。</p>
</li>
</ol>
<h2 id="面對的挑戰"><a class="header" href="#面對的挑戰">面對的挑戰</a></h2>
<p>總括來講，筆者盡可能地把測試用例限定在業務邏輯中，就可以大大地降低寫測試的技術難度。但筆者還是有些問題並未完美解決。</p>
<ol>
<li>測試用例的數量可能很多，因此共用與維護變得相當困難。逐個用例獨立編寫輸入也是很累的。</li>
<li>對於 Mockito 的使用，筆者還是可免則免。因為要逐個功能模擬，編寫量就指數提高，這亦難似配合外部變化。一般來說，能優先使用測試環境或者 Docker 來模擬環境的，就盡量用。</li>
<li>離線開發、離線測試。系統依懶的外部功能越多，想做單機開發的難度就越高。即使前述有 Docker 測試，對於持續整合（CI）來講也是有一定難度。那麼這時，Mockito 就是一個可取的選擇。但這又回到編寫量及難以偵測外部變化問題。</li>
</ol>
<p>希望這篇文章能幫助你更好地理解測試案例的編寫方向，並在Spring boot web開發中加入你自己的測試！</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-web-異步-api"><a class="header" href="#spring-boot-web-異步-api">Spring Boot Web 異步 Api</a></h1>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-email"><a class="header" href="#spring-boot-email">Spring boot email</a></h1>
<p>使用 Spring boot 對接 SMTP gateway 發 email ，相對是容易的。</p>
<p>基本上，它就是會使用自建的 <code>org.springframework.mail.javamail.*</code> , 對接 <code>javax.mail.*</code> / <code>jakarta.mail.*</code></p>
<p>以前的所有設定值 ，都可以經 <code>spring.mail.properties.*</code> 傳入</p>
<p>例如</p>
<pre><code>spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.ssl.enable=true
spring.mail.properties.mail.smtp.socketFactory.port=465
</code></pre>
<p>就等於過去</p>
<pre><code>java.util.Properties props = new java.util.Properties();
props.put("mail.smtp.auth", "true");
props.put("mail.smtp.ssl.enable", "true");
props.put("mail.smtp.socketFactory.port", "465");
</code></pre>
<p>一個最簡單可以連去 google smtp 的簡易 code 如下</p>
<pre><code>### application.properties
spring.mail.host=smtp.gmail.com
spring.mail.port=587
spring.mail.username=&lt;Login User to SMTP server&gt;
spring.mail.password=&lt;Login password to SMTP server&gt;
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
</code></pre>
<pre><code class="language-java">// SpringBootEmailApplicationTests.java
@SpringBootTest
class SpringBootEmailApplicationTests {
    @Autowired
    private JavaMailSender javaMailSender;
    @Value("${spring.mail.username}")
    private String fromAddress;
    private static final Logger LOG = LoggerFactory.getLogger(SpringBootEmailApplicationTests.class);

    @Test
    void contextLoads() {
        try {
            SimpleMailMessage mailMessage = new SimpleMailMessage();
            mailMessage.setFrom(fromAddress);
            mailMessage.setTo("XXXXXXXX");
            mailMessage.setText("this is backend email trigger for spring boot");
            mailMessage.setSubject("spring boot test mail");

            javaMailSender.send(mailMessage);
        } catch (Exception e) {
            LOG.error("Error while Sending Mail");
            throw new RuntimeException(e);
        }
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="spring-boot-06---回顧-spring-web--spring-data-架構"><a class="header" href="#spring-boot-06---回顧-spring-web--spring-data-架構">Spring Boot 06 - 回顧 Spring Web + Spring Data 架構</a></h1>
<p>前述幾章，一直跟著範例來寫，道理上都不難。在繼續講解其他功能之前，我們還是保險地把過去的資訊整理好，方便大家在此基礎上開支散葉。</p>
<h2 id="最簡流程圖"><a class="header" href="#最簡流程圖">最簡流程圖</a></h2>
<pre class="mermaid">graph TD;
    application[一個有main function，而且有@SpringBootApplication 附註的class];
    controller[所有@Controller附註的class會被轉成Http Servlet];
    repository["所有繼承 CurdRepositry 或 JpaRepository 的Interface"];
    repoInstance["CurdRepositry 或 JpaRepository 的實例"];
    entity["含有@Entity附註的class"];
    businessLogic["程序員根據業務需求，以某個方式生成、更新、刪除Entity的實例，並經過 JpaRepository 寫到資料庫中"];
    dbTable["資料庫Table(表)"];
    SpringBootServletInitializer[一個繼承SpringBootServletInitializer的class];
    application--&gt;|自動偵測|SpringBootServletInitializer;
    SpringBootServletInitializer--&gt;|自動設定|controller;
    application--&gt;|自動偵測|repository;
    controller--&gt;|引用實列|repoInstance;
    repository--&gt;|"一對一操作 (Save, Delete, Find)"|entity;
    repository--&gt;|自動設定|repoInstance;
    businessLogic&lt;--&gt;|讀寫|dbTable;
    controller--&gt;businessLogic;
    repoInstance--&gt;businessLogic;
    entity--&gt;businessLogic;
</pre>

<p>@Controller會自動生成http endpoint，@Entity則會對應生成資料庫的表。我們可以在任何Class中，包括Controller，經過自動註冊，叫Repository去記錄@Entity。</p>
<p>在Spring中，@Service，@Bean都被。</p>
<p>controller, service, test what,</p>
<h1 id="inheritance"><a class="header" href="#inheritance">inheritance?</a></h1>
<p>no test if inheritance?</p>
<div style="break-before: page; page-break-before: always;"></div>
<p>install vue3</p>
<pre><code class="language-bash">npm create vue@latest
cd &lt;your-project-name&gt;
npm install
npm run dev
</code></pre>
<p>update vite.config.ts</p>
<pre><code class="language-js">import { fileURLToPath, URL } from 'node:url'
import type { UserConfig, ConfigEnv } from 'vite' // add
import { defineConfig, loadEnv } from 'vite' // modify
import vue from '@vitejs/plugin-vue'
import VueDevTools from 'vite-plugin-vue-devtools'

export default defineConfig(({ mode }: ConfigEnv): UserConfig =&gt; { // modify
  const env = loadEnv(mode, process.cwd()) // add
  return { // add return statement, properties build, server, base
    plugins: [
      vue(),
      VueDevTools()
    ],
    resolve: {
      alias: {
        '@': fileURLToPath(new URL('./src', import.meta.url))
      }
    },
    build: {
      outDir: 'somewhere',
      emptyOutDir: true
    },
    server: {
      host: '0.0.0.0',
      proxy: {
        '^/api': {
          target: 'http://localhost:8080/', // assume backend-api is running on localhost:8080
          ws: true,
          changeOrigin: true,
          autoRewrite: true,
          cookieDomainRewrite: {
            '*': '127.0.0.1'
          }
        }
      }
    },
    base: env.VITE_WEB_ROOT
  }
})
</code></pre>
<p>udpate vitest.config.ts</p>
<pre><code class="language-js">export default defineConfig(env =&gt; mergeConfig( // update
  viteConfig(env), // add
  defineConfig({
    test: {
      environment: 'jsdom',
      exclude: [...configDefaults.exclude, 'e2e/**'],
      root: fileURLToPath(new URL('./', import.meta.url)),
    },
  }),
)) // update
</code></pre>
<p>add .env for dev variable, context path, disable auth</p>
<pre><code>VITE_WEB_ROOT=""
HTTP_AUTH_ENABLED=false
</code></pre>
<p>add .env.production for production variable</p>
<pre><code>VITE_WEB_ROOT="/production-context-path"
HTTP_AUTH_ENABLED=true
</code></pre>
<p>// config frontend backend route
update src/router/index.ts</p>
<pre><code class="language-diff">-path: '/about',
+path: '/ui/about',
</code></pre>
<p>if you go back to Hash Mode, confirm that you are not using backend routing</p>
<p>test producion build</p>
<pre><code class="language-bash">npm run lint
npm run format
npm run build
</code></pre>
<p>config openapi generator</p>
<pre><code class="language-bash">npm install --save-dev @openapitools/openapi-generator-cli
npx openapi-generator-cli version-manager set 7.11.0
</code></pre>
<p>revise package.json add openapi command</p>
<pre><code class="language-json">{
  "scripts": {
    "openapi": "openapi-generator-cli generate -i http://localhost:8080/v3/api-docs -g typescript-axios --additional-properties=withSeparateModelsAndApi=true,modelPackage=model,apiPackage=api -o src/openapi/"
  }
}
</code></pre>
<p>npm install axios
npm install vue-i18n</p>
<pre><code class="language-diff"># src/main.ts
import './assets/main.css'

import { createApp } from 'vue'
import { createPinia } from 'pinia'

+import i18n from "./i18n/"
import App from './App.vue'
import router from './router'

const app = createApp(App)

app.use(createPinia())
app.use(router)
+app.use(i18n)

app.mount('#app')


# src/i18n/index.ts
+import { createI18n } from 'vue-i18n'
+import zhTwJson from "./locales/zh-tw.json"
+
+const i18n = createI18n({
+  locale: 'zh-tw',
+  globalInjection: true,
+  messages: {
+    'zh-tw': zhTwJson
+  }
+})
+
+export default i18n

# src/i18n/locales/zh-tw.json
+{
+  "app": {
+    "name": "YOUR APP NAME"
+  }
+}
</code></pre>
<p>npm install element-plus –save</p>
<pre><code class="language-diff"># src/main.ts
import './assets/main.css'

import { createApp } from 'vue'
import { createPinia } from 'pinia'

import i18n from "./i18n/"

+import ElementPlus from 'element-plus'
+import 'element-plus/dist/index.css'
+import { zhTw } from 'element-plus/es/locales.mjs'

import App from './App.vue'
import router from './router'

const app = createApp(App)

app.use(createPinia())
app.use(router)
app.use(i18n)
+app.use(ElementPlus, { locale: zhTw })

app.mount('#app')
</code></pre>
<h1 id="draft-3"><a class="header" href="#draft-3">draft</a></h1>
<p>config vue router (route guard)
config vue axios interceptor
config vue i18n
config vue pinia
config vue element-plus
config openapi generator
config vue validator (vuelidate)</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid-a19b8af3.min.js"></script>
        <script src="mermaid-init-4533fb11.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
